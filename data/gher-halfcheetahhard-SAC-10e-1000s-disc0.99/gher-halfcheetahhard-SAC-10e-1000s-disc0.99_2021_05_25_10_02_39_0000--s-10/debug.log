2021-05-25 10:03:07.954203 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 0 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  4000
trainer/QF1 Loss                                      16.6802
trainer/QF2 Loss                                      16.5885
trainer/Policy Loss                                   -4.03334
trainer/Q1 Predictions Mean                           -0.00737131
trainer/Q1 Predictions Std                             0.00557663
trainer/Q1 Predictions Max                             0.00463407
trainer/Q1 Predictions Min                            -0.0336251
trainer/Q2 Predictions Mean                            0.00415807
trainer/Q2 Predictions Std                             0.0048979
trainer/Q2 Predictions Max                             0.0203202
trainer/Q2 Predictions Min                            -0.00775022
trainer/Q Targets Mean                                 3.92335
trainer/Q Targets Std                                  1.10908
trainer/Q Targets Max                                  7.1054
trainer/Q Targets Min                                  1.18374
trainer/Log Pis Mean                                  -4.04084
trainer/Log Pis Std                                    0.508067
trainer/Log Pis Max                                   -2.36323
trainer/Log Pis Min                                   -5.48163
trainer/Policy mu Mean                                -0.000934237
trainer/Policy mu Std                                  0.002431
trainer/Policy mu Max                                  0.00722954
trainer/Policy mu Min                                 -0.00893305
trainer/Policy log std Mean                           -0.00130592
trainer/Policy log std Std                             0.00165964
trainer/Policy log std Max                             0.00340147
trainer/Policy log std Min                            -0.00757277
trainer/Alpha                                          0.997005
trainer/Alpha Loss                                    -0
exploration/num steps total                         2000
exploration/num paths total                            2
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.136377
exploration/Rewards Std                                0.476496
exploration/Rewards Max                                1.4954
exploration/Rewards Min                               -1.58775
exploration/Returns Mean                            -136.377
exploration/Returns Std                                0
exploration/Returns Max                             -136.377
exploration/Returns Min                             -136.377
exploration/Actions Mean                               0.00119015
exploration/Actions Std                                0.62711
exploration/Actions Max                                0.9991
exploration/Actions Min                               -0.999803
exploration/Num Paths                                  1
exploration/Average Returns                         -136.377
exploration/env_infos/final/reward_run Mean           -1.17973
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max            -1.17973
exploration/env_infos/final/reward_run Min            -1.17973
exploration/env_infos/initial/reward_run Mean         -0.374905
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max          -0.374905
exploration/env_infos/initial/reward_run Min          -0.374905
exploration/env_infos/reward_run Mean                 -0.166443
exploration/env_infos/reward_run Std                   0.640606
exploration/env_infos/reward_run Max                   1.61939
exploration/env_infos/reward_run Min                  -2.0604
exploration/env_infos/final/reward_ctrl Mean          -0.112643
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.112643
exploration/env_infos/final/reward_ctrl Min           -0.112643
exploration/env_infos/initial/reward_ctrl Mean        -0.14458
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.14458
exploration/env_infos/initial/reward_ctrl Min         -0.14458
exploration/env_infos/reward_ctrl Mean                -0.235961
exploration/env_infos/reward_ctrl Std                  0.0750451
exploration/env_infos/reward_ctrl Max                 -0.018194
exploration/env_infos/reward_ctrl Min                 -0.475831
exploration/env_infos/final/height Mean                0.0706641
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                 0.0706641
exploration/env_infos/final/height Min                 0.0706641
exploration/env_infos/initial/height Mean             -0.0710219
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max              -0.0710219
exploration/env_infos/initial/height Min              -0.0710219
exploration/env_infos/height Mean                     -0.063873
exploration/env_infos/height Std                       0.0876588
exploration/env_infos/height Max                       0.20319
exploration/env_infos/height Min                      -0.360702
exploration/env_infos/final/reward_angular Mean       -2.15328
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max        -2.15328
exploration/env_infos/final/reward_angular Min        -2.15328
exploration/env_infos/initial/reward_angular Mean     -0.122531
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max      -0.122531
exploration/env_infos/initial/reward_angular Min      -0.122531
exploration/env_infos/reward_angular Mean              0.0139977
exploration/env_infos/reward_angular Std               1.69039
exploration/env_infos/reward_angular Max               7.79906
exploration/env_infos/reward_angular Min              -5.07586
evaluation/num steps total                         25000
evaluation/num paths total                            25
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.0615483
evaluation/Rewards Std                                 0.0463997
evaluation/Rewards Max                                 1.32204
evaluation/Rewards Min                                -1.09337
evaluation/Returns Mean                              -61.5483
evaluation/Returns Std                                38.1997
evaluation/Returns Max                                -1.6116
evaluation/Returns Min                              -127.487
evaluation/Actions Mean                               -0.00032298
evaluation/Actions Std                                 0.00121843
evaluation/Actions Max                                 0.00337558
evaluation/Actions Min                                -0.0036283
evaluation/Num Paths                                  25
evaluation/Average Returns                           -61.5483
evaluation/env_infos/final/reward_run Mean             2.26598e-18
evaluation/env_infos/final/reward_run Std              2.22662e-16
evaluation/env_infos/final/reward_run Max              8.32667e-16
evaluation/env_infos/final/reward_run Min             -5.55112e-16
evaluation/env_infos/initial/reward_run Mean           0.0173362
evaluation/env_infos/initial/reward_run Std            0.108441
evaluation/env_infos/initial/reward_run Max            0.244668
evaluation/env_infos/initial/reward_run Min           -0.173308
evaluation/env_infos/reward_run Mean                  -0.000210638
evaluation/env_infos/reward_run Std                    0.0146511
evaluation/env_infos/reward_run Max                    0.400855
evaluation/env_infos/reward_run Min                   -0.377249
evaluation/env_infos/final/reward_ctrl Mean           -9.52177e-07
evaluation/env_infos/final/reward_ctrl Std             9.0322e-08
evaluation/env_infos/final/reward_ctrl Max            -8.07404e-07
evaluation/env_infos/final/reward_ctrl Min            -1.10654e-06
evaluation/env_infos/initial/reward_ctrl Mean         -1.00256e-06
evaluation/env_infos/initial/reward_ctrl Std           1.05861e-07
evaluation/env_infos/initial/reward_ctrl Max          -8.13546e-07
evaluation/env_infos/initial/reward_ctrl Min          -1.20276e-06
evaluation/env_infos/reward_ctrl Mean                 -9.53335e-07
evaluation/env_infos/reward_ctrl Std                   9.70461e-08
evaluation/env_infos/reward_ctrl Max                  -6.32376e-07
evaluation/env_infos/reward_ctrl Min                  -3.2053e-06
evaluation/env_infos/final/height Mean                -0.132891
evaluation/env_infos/final/height Std                  3.5865e-05
evaluation/env_infos/final/height Max                 -0.132829
evaluation/env_infos/final/height Min                 -0.132952
evaluation/env_infos/initial/height Mean              -0.00512014
evaluation/env_infos/initial/height Std                0.0600862
evaluation/env_infos/initial/height Max                0.0882252
evaluation/env_infos/initial/height Min               -0.0959662
evaluation/env_infos/height Mean                      -0.132401
evaluation/env_infos/height Std                        0.00616916
evaluation/env_infos/height Max                        0.0882252
evaluation/env_infos/height Min                       -0.141504
evaluation/env_infos/final/reward_angular Mean        -6.84683e-18
evaluation/env_infos/final/reward_angular Std          1.55547e-15
evaluation/env_infos/final/reward_angular Max          3.28736e-15
evaluation/env_infos/final/reward_angular Min         -2.5144e-15
evaluation/env_infos/initial/reward_angular Mean       0.074782
evaluation/env_infos/initial/reward_angular Std        0.354898
evaluation/env_infos/initial/reward_angular Max        1.18051
evaluation/env_infos/initial/reward_angular Min       -0.50039
evaluation/env_infos/reward_angular Mean               0.00114103
evaluation/env_infos/reward_angular Std                0.0450042
evaluation/env_infos/reward_angular Max                2.18753
evaluation/env_infos/reward_angular Min               -1.38548
time/data storing (s)                                  0.0689242
time/evaluation sampling (s)                          22.2747
time/exploration sampling (s)                          1.08234
time/logging (s)                                       0.24479
time/saving (s)                                        0.471237
time/training (s)                                      3.47003
time/epoch (s)                                        27.612
time/total (s)                                        32.0328
Epoch                                                  0
-------------------------------------------------  ---------------
2021-05-25 10:03:34.848560 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 1 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  6000
trainer/QF1 Loss                                       0.743806
trainer/QF2 Loss                                       0.766513
trainer/Policy Loss                                   -7.38367
trainer/Q1 Predictions Mean                            3.34326
trainer/Q1 Predictions Std                             0.614642
trainer/Q1 Predictions Max                             5.34839
trainer/Q1 Predictions Min                             1.35027
trainer/Q2 Predictions Mean                            3.34056
trainer/Q2 Predictions Std                             0.607186
trainer/Q2 Predictions Max                             5.23391
trainer/Q2 Predictions Min                             1.43813
trainer/Q Targets Mean                                 3.38564
trainer/Q Targets Std                                  0.951928
trainer/Q Targets Max                                  6.50674
trainer/Q Targets Min                                 -0.0394452
trainer/Log Pis Mean                                  -4.02402
trainer/Log Pis Std                                    0.532243
trainer/Log Pis Max                                   -2.63937
trainer/Log Pis Min                                   -6.76312
trainer/Policy mu Mean                                -0.130934
trainer/Policy mu Std                                  0.0964565
trainer/Policy mu Max                                 -0.000436069
trainer/Policy mu Min                                 -0.474782
trainer/Policy log std Mean                           -0.119606
trainer/Policy log std Std                             0.0234164
trainer/Policy log std Max                            -0.0809322
trainer/Policy log std Min                            -0.23082
trainer/Alpha                                          0.738881
trainer/Alpha Loss                                    -3.00347
exploration/num steps total                         3000
exploration/num paths total                            3
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.228972
exploration/Rewards Std                                0.192434
exploration/Rewards Max                                0.352685
exploration/Rewards Min                               -0.946785
exploration/Returns Mean                            -228.972
exploration/Returns Std                                0
exploration/Returns Max                             -228.972
exploration/Returns Min                             -228.972
exploration/Actions Mean                              -0.0861007
exploration/Actions Std                                0.59439
exploration/Actions Max                                0.993912
exploration/Actions Min                               -0.998908
exploration/Num Paths                                  1
exploration/Average Returns                         -228.972
exploration/env_infos/final/reward_run Mean            0.710108
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max             0.710108
exploration/env_infos/final/reward_run Min             0.710108
exploration/env_infos/initial/reward_run Mean         -0.201483
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max          -0.201483
exploration/env_infos/initial/reward_run Min          -0.201483
exploration/env_infos/reward_run Mean                 -0.149074
exploration/env_infos/reward_run Std                   0.654058
exploration/env_infos/reward_run Max                   1.89179
exploration/env_infos/reward_run Min                  -2.44908
exploration/env_infos/final/reward_ctrl Mean          -0.204652
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.204652
exploration/env_infos/final/reward_ctrl Min           -0.204652
exploration/env_infos/initial/reward_ctrl Mean        -0.230986
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.230986
exploration/env_infos/initial/reward_ctrl Min         -0.230986
exploration/env_infos/reward_ctrl Mean                -0.216427
exploration/env_infos/reward_ctrl Std                  0.0720325
exploration/env_infos/reward_ctrl Max                 -0.0160272
exploration/env_infos/reward_ctrl Min                 -0.500249
exploration/env_infos/final/height Mean               -0.0224901
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                -0.0224901
exploration/env_infos/final/height Min                -0.0224901
exploration/env_infos/initial/height Mean              0.0289295
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max               0.0289295
exploration/env_infos/initial/height Min               0.0289295
exploration/env_infos/height Mean                     -0.0837714
exploration/env_infos/height Std                       0.0781987
exploration/env_infos/height Max                       0.265628
exploration/env_infos/height Min                      -0.299167
exploration/env_infos/final/reward_angular Mean       -0.0517604
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max        -0.0517604
exploration/env_infos/final/reward_angular Min        -0.0517604
exploration/env_infos/initial/reward_angular Mean      1.03437
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max       1.03437
exploration/env_infos/initial/reward_angular Min       1.03437
exploration/env_infos/reward_angular Mean             -0.0153459
exploration/env_infos/reward_angular Std               1.63607
exploration/env_infos/reward_angular Max               4.59191
exploration/env_infos/reward_angular Min              -5.2682
evaluation/num steps total                         50000
evaluation/num paths total                            50
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.0632997
evaluation/Rewards Std                                 0.0534852
evaluation/Rewards Max                                 1.22113
evaluation/Rewards Min                                -2.18749
evaluation/Returns Mean                              -63.2997
evaluation/Returns Std                                36.9538
evaluation/Returns Max                                -3.96147
evaluation/Returns Min                              -125.662
evaluation/Actions Mean                               -0.0916443
evaluation/Actions Std                                 0.0650338
evaluation/Actions Max                                -0.00698582
evaluation/Actions Min                                -0.281051
evaluation/Num Paths                                  25
evaluation/Average Returns                           -63.2997
evaluation/env_infos/final/reward_run Mean             1.02067e-16
evaluation/env_infos/final/reward_run Std              2.54846e-16
evaluation/env_infos/final/reward_run Max              8.32667e-16
evaluation/env_infos/final/reward_run Min             -5.55112e-16
evaluation/env_infos/initial/reward_run Mean          -0.0405053
evaluation/env_infos/initial/reward_run Std            0.172324
evaluation/env_infos/initial/reward_run Max            0.330372
evaluation/env_infos/initial/reward_run Min           -0.418189
evaluation/env_infos/reward_run Mean                  -0.000100539
evaluation/env_infos/reward_run Std                    0.0190179
evaluation/env_infos/reward_run Max                    0.330372
evaluation/env_infos/reward_run Min                   -0.536875
evaluation/env_infos/final/reward_ctrl Mean           -0.00756925
evaluation/env_infos/final/reward_ctrl Std             0.00116305
evaluation/env_infos/final/reward_ctrl Max            -0.00562747
evaluation/env_infos/final/reward_ctrl Min            -0.00919956
evaluation/env_infos/initial/reward_ctrl Mean         -0.00746772
evaluation/env_infos/initial/reward_ctrl Std           0.00121161
evaluation/env_infos/initial/reward_ctrl Max          -0.00530501
evaluation/env_infos/initial/reward_ctrl Min          -0.00918547
evaluation/env_infos/reward_ctrl Mean                 -0.00757684
evaluation/env_infos/reward_ctrl Std                   0.00116853
evaluation/env_infos/reward_ctrl Max                  -0.00511199
evaluation/env_infos/reward_ctrl Min                  -0.0143009
evaluation/env_infos/final/height Mean                -0.130147
evaluation/env_infos/final/height Std                  0.000177086
evaluation/env_infos/final/height Max                 -0.129879
evaluation/env_infos/final/height Min                 -0.130414
evaluation/env_infos/initial/height Mean              -0.00180861
evaluation/env_infos/initial/height Std                0.0540812
evaluation/env_infos/initial/height Max                0.0830823
evaluation/env_infos/initial/height Min               -0.093423
evaluation/env_infos/height Mean                      -0.129737
evaluation/env_infos/height Std                        0.00598333
evaluation/env_infos/height Max                        0.0830823
evaluation/env_infos/height Min                       -0.154083
evaluation/env_infos/final/reward_angular Mean         1.2895e-16
evaluation/env_infos/final/reward_angular Std          1.535e-15
evaluation/env_infos/final/reward_angular Max          3.16185e-15
evaluation/env_infos/final/reward_angular Min         -2.82832e-15
evaluation/env_infos/initial/reward_angular Mean       0.511987
evaluation/env_infos/initial/reward_angular Std        0.32327
evaluation/env_infos/initial/reward_angular Max        1.23924
evaluation/env_infos/initial/reward_angular Min        0.00330403
evaluation/env_infos/reward_angular Mean               0.00221283
evaluation/env_infos/reward_angular Std                0.0584708
evaluation/env_infos/reward_angular Max                2.27082
evaluation/env_infos/reward_angular Min               -0.925278
time/data storing (s)                                  0.0683762
time/evaluation sampling (s)                          21.7468
time/exploration sampling (s)                          1.01421
time/logging (s)                                       0.237878
time/saving (s)                                        0.332789
time/training (s)                                      3.25012
time/epoch (s)                                        26.6502
time/total (s)                                        58.9197
Epoch                                                  1
-------------------------------------------------  ---------------
2021-05-25 10:04:02.687435 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 2 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  8000
trainer/QF1 Loss                                       0.852367
trainer/QF2 Loss                                       0.85493
trainer/Policy Loss                                   -7.31409
trainer/Q1 Predictions Mean                            3.28253
trainer/Q1 Predictions Std                             0.732813
trainer/Q1 Predictions Max                             5.62163
trainer/Q1 Predictions Min                             1.45355
trainer/Q2 Predictions Mean                            3.31075
trainer/Q2 Predictions Std                             0.723922
trainer/Q2 Predictions Max                             5.6136
trainer/Q2 Predictions Min                             1.51262
trainer/Q Targets Mean                                 3.1993
trainer/Q Targets Std                                  1.13343
trainer/Q Targets Max                                  6.97577
trainer/Q Targets Min                                 -2.35241
trainer/Log Pis Mean                                  -3.9342
trainer/Log Pis Std                                    0.613627
trainer/Log Pis Max                                   -1.95606
trainer/Log Pis Min                                   -6.07042
trainer/Policy mu Mean                                -0.12736
trainer/Policy mu Std                                  0.142507
trainer/Policy mu Max                                  0.171919
trainer/Policy mu Min                                 -0.766841
trainer/Policy log std Mean                           -0.132104
trainer/Policy log std Std                             0.0325939
trainer/Policy log std Max                            -0.0732969
trainer/Policy log std Min                            -0.280719
trainer/Alpha                                          0.548086
trainer/Alpha Loss                                    -5.94407
exploration/num steps total                         4000
exploration/num paths total                            4
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.0801393
exploration/Rewards Std                                0.546897
exploration/Rewards Max                                1.60755
exploration/Rewards Min                               -2.11331
exploration/Returns Mean                             -80.1393
exploration/Returns Std                                0
exploration/Returns Max                              -80.1393
exploration/Returns Min                              -80.1393
exploration/Actions Mean                              -0.104866
exploration/Actions Std                                0.590479
exploration/Actions Max                                0.997102
exploration/Actions Min                               -0.997529
exploration/Num Paths                                  1
exploration/Average Returns                          -80.1393
exploration/env_infos/final/reward_run Mean           -0.248803
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max            -0.248803
exploration/env_infos/final/reward_run Min            -0.248803
exploration/env_infos/initial/reward_run Mean         -0.102436
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max          -0.102436
exploration/env_infos/initial/reward_run Min          -0.102436
exploration/env_infos/reward_run Mean                 -0.0261349
exploration/env_infos/reward_run Std                   0.666405
exploration/env_infos/reward_run Max                   1.82474
exploration/env_infos/reward_run Min                  -2.26154
exploration/env_infos/final/reward_ctrl Mean          -0.147797
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.147797
exploration/env_infos/final/reward_ctrl Min           -0.147797
exploration/env_infos/initial/reward_ctrl Mean        -0.215675
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.215675
exploration/env_infos/initial/reward_ctrl Min         -0.215675
exploration/env_infos/reward_ctrl Mean                -0.215797
exploration/env_infos/reward_ctrl Std                  0.07424
exploration/env_infos/reward_ctrl Max                 -0.0218283
exploration/env_infos/reward_ctrl Min                 -0.454896
exploration/env_infos/final/height Mean               -0.0500108
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                -0.0500108
exploration/env_infos/final/height Min                -0.0500108
exploration/env_infos/initial/height Mean             -0.0549325
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max              -0.0549325
exploration/env_infos/initial/height Min              -0.0549325
exploration/env_infos/height Mean                     -0.0752075
exploration/env_infos/height Std                       0.0825511
exploration/env_infos/height Max                       0.207062
exploration/env_infos/height Min                      -0.324674
exploration/env_infos/final/reward_angular Mean        0.204123
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max         0.204123
exploration/env_infos/final/reward_angular Min         0.204123
exploration/env_infos/initial/reward_angular Mean      1.27606
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max       1.27606
exploration/env_infos/initial/reward_angular Min       1.27606
exploration/env_infos/reward_angular Mean              0.00102233
exploration/env_infos/reward_angular Std               1.59487
exploration/env_infos/reward_angular Max               4.42326
exploration/env_infos/reward_angular Min              -5.02551
evaluation/num steps total                         75000
evaluation/num paths total                            75
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.0649087
evaluation/Rewards Std                                 0.0486764
evaluation/Rewards Max                                 1.36335
evaluation/Rewards Min                                -1.08438
evaluation/Returns Mean                              -64.9087
evaluation/Returns Std                                36.98
evaluation/Returns Max                                -5.70788
evaluation/Returns Min                              -129.322
evaluation/Actions Mean                               -0.102002
evaluation/Actions Std                                 0.111392
evaluation/Actions Max                                 0.076981
evaluation/Actions Min                                -0.489476
evaluation/Num Paths                                  25
evaluation/Average Returns                           -64.9087
evaluation/env_infos/final/reward_run Mean             2.89282e-09
evaluation/env_infos/final/reward_run Std              9.43671e-09
evaluation/env_infos/final/reward_run Max              3.94696e-08
evaluation/env_infos/final/reward_run Min             -1.08345e-08
evaluation/env_infos/initial/reward_run Mean          -0.120389
evaluation/env_infos/initial/reward_run Std            0.124892
evaluation/env_infos/initial/reward_run Max            0.104161
evaluation/env_infos/initial/reward_run Min           -0.371461
evaluation/env_infos/reward_run Mean                  -0.000263023
evaluation/env_infos/reward_run Std                    0.019027
evaluation/env_infos/reward_run Max                    0.280509
evaluation/env_infos/reward_run Min                   -0.608039
evaluation/env_infos/final/reward_ctrl Mean           -0.0136845
evaluation/env_infos/final/reward_ctrl Std             0.00765167
evaluation/env_infos/final/reward_ctrl Max            -0.00615294
evaluation/env_infos/final/reward_ctrl Min            -0.0293803
evaluation/env_infos/initial/reward_ctrl Mean         -0.0149953
evaluation/env_infos/initial/reward_ctrl Std           0.0091306
evaluation/env_infos/initial/reward_ctrl Max          -0.00613883
evaluation/env_infos/initial/reward_ctrl Min          -0.0325018
evaluation/env_infos/reward_ctrl Mean                 -0.0136876
evaluation/env_infos/reward_ctrl Std                   0.00765388
evaluation/env_infos/reward_ctrl Max                  -0.00565734
evaluation/env_infos/reward_ctrl Min                  -0.0347089
evaluation/env_infos/final/height Mean                -0.130372
evaluation/env_infos/final/height Std                  0.00656969
evaluation/env_infos/final/height Max                 -0.120567
evaluation/env_infos/final/height Min                 -0.138482
evaluation/env_infos/initial/height Mean              -0.0141268
evaluation/env_infos/initial/height Std                0.0488786
evaluation/env_infos/initial/height Max                0.0687628
evaluation/env_infos/initial/height Min               -0.0990248
evaluation/env_infos/height Mean                      -0.129999
evaluation/env_infos/height Std                        0.00848659
evaluation/env_infos/height Max                        0.0687628
evaluation/env_infos/height Min                       -0.159155
evaluation/env_infos/final/reward_angular Mean        -8.26656e-10
evaluation/env_infos/final/reward_angular Std          7.99463e-09
evaluation/env_infos/final/reward_angular Max          2.42775e-08
evaluation/env_infos/final/reward_angular Min         -2.27891e-08
evaluation/env_infos/initial/reward_angular Mean       0.532027
evaluation/env_infos/initial/reward_angular Std        0.403996
evaluation/env_infos/initial/reward_angular Max        1.62279
evaluation/env_infos/initial/reward_angular Min       -0.373245
evaluation/env_infos/reward_angular Mean               0.00199084
evaluation/env_infos/reward_angular Std                0.0545126
evaluation/env_infos/reward_angular Max                1.64456
evaluation/env_infos/reward_angular Min               -1.41155
time/data storing (s)                                  0.0778783
time/evaluation sampling (s)                          22.4327
time/exploration sampling (s)                          1.0882
time/logging (s)                                       0.247095
time/saving (s)                                        0.439839
time/training (s)                                      3.43749
time/epoch (s)                                        27.7232
time/total (s)                                        86.7668
Epoch                                                  2
-------------------------------------------------  ---------------
2021-05-25 10:04:31.755705 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 3 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  10000
trainer/QF1 Loss                                        0.778313
trainer/QF2 Loss                                        0.760984
trainer/Policy Loss                                    -6.93587
trainer/Q1 Predictions Mean                             3.04099
trainer/Q1 Predictions Std                              0.789674
trainer/Q1 Predictions Max                              8.35476
trainer/Q1 Predictions Min                              0.999759
trainer/Q2 Predictions Mean                             3.05199
trainer/Q2 Predictions Std                              0.790416
trainer/Q2 Predictions Max                              8.16598
trainer/Q2 Predictions Min                              1.00307
trainer/Q Targets Mean                                  3.33167
trainer/Q Targets Std                                   1.17311
trainer/Q Targets Max                                   9.92709
trainer/Q Targets Min                                   0.522334
trainer/Log Pis Mean                                   -3.82663
trainer/Log Pis Std                                     0.830307
trainer/Log Pis Max                                    -1.08163
trainer/Log Pis Min                                    -5.8566
trainer/Policy mu Mean                                 -0.184225
trainer/Policy mu Std                                   0.192251
trainer/Policy mu Max                                   0.186793
trainer/Policy mu Min                                  -1.05845
trainer/Policy log std Mean                            -0.11142
trainer/Policy log std Std                              0.0382386
trainer/Policy log std Max                             -0.0342935
trainer/Policy log std Min                             -0.288679
trainer/Alpha                                           0.407457
trainer/Alpha Loss                                     -8.79344
exploration/num steps total                          5000
exploration/num paths total                             5
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.102629
exploration/Rewards Std                                 0.590485
exploration/Rewards Max                                 2.20847
exploration/Rewards Min                                -2.26132
exploration/Returns Mean                             -102.629
exploration/Returns Std                                 0
exploration/Returns Max                              -102.629
exploration/Returns Min                              -102.629
exploration/Actions Mean                               -0.0837937
exploration/Actions Std                                 0.594991
exploration/Actions Max                                 0.997352
exploration/Actions Min                                -0.998424
exploration/Num Paths                                   1
exploration/Average Returns                          -102.629
exploration/env_infos/final/reward_run Mean             0.615216
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.615216
exploration/env_infos/final/reward_run Min              0.615216
exploration/env_infos/initial/reward_run Mean          -0.0133224
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max           -0.0133224
exploration/env_infos/initial/reward_run Min           -0.0133224
exploration/env_infos/reward_run Mean                  -0.00839036
exploration/env_infos/reward_run Std                    0.60468
exploration/env_infos/reward_run Max                    1.72013
exploration/env_infos/reward_run Min                   -2.03022
exploration/env_infos/final/reward_ctrl Mean           -0.227419
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.227419
exploration/env_infos/final/reward_ctrl Min            -0.227419
exploration/env_infos/initial/reward_ctrl Mean         -0.181719
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.181719
exploration/env_infos/initial/reward_ctrl Min          -0.181719
exploration/env_infos/reward_ctrl Mean                 -0.216621
exploration/env_infos/reward_ctrl Std                   0.0714614
exploration/env_infos/reward_ctrl Max                  -0.0108772
exploration/env_infos/reward_ctrl Min                  -0.436711
exploration/env_infos/final/height Mean                -0.534543
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.534543
exploration/env_infos/final/height Min                 -0.534543
exploration/env_infos/initial/height Mean              -0.00383065
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.00383065
exploration/env_infos/initial/height Min               -0.00383065
exploration/env_infos/height Mean                      -0.309813
exploration/env_infos/height Std                        0.244704
exploration/env_infos/height Max                        0.176417
exploration/env_infos/height Min                       -0.58278
exploration/env_infos/final/reward_angular Mean        -1.42156
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -1.42156
exploration/env_infos/final/reward_angular Min         -1.42156
exploration/env_infos/initial/reward_angular Mean      -0.313818
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.313818
exploration/env_infos/initial/reward_angular Min       -0.313818
exploration/env_infos/reward_angular Mean               0.0720715
exploration/env_infos/reward_angular Std                1.4892
exploration/env_infos/reward_angular Max                6.00799
exploration/env_infos/reward_angular Min               -5.35569
evaluation/num steps total                         100000
evaluation/num paths total                            100
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0758176
evaluation/Rewards Std                                  0.0564992
evaluation/Rewards Max                                  1.14766
evaluation/Rewards Min                                 -1.55094
evaluation/Returns Mean                               -75.8176
evaluation/Returns Std                                 38.3501
evaluation/Returns Max                                 -7.83325
evaluation/Returns Min                               -139.723
evaluation/Actions Mean                                -0.150163
evaluation/Actions Std                                  0.15254
evaluation/Actions Max                                  0.0988208
evaluation/Actions Min                                 -0.634796
evaluation/Num Paths                                   25
evaluation/Average Returns                            -75.8176
evaluation/env_infos/final/reward_run Mean             -2.47033e-09
evaluation/env_infos/final/reward_run Std               1.11121e-08
evaluation/env_infos/final/reward_run Max               9.94568e-09
evaluation/env_infos/final/reward_run Min              -5.52985e-08
evaluation/env_infos/initial/reward_run Mean           -0.227
evaluation/env_infos/initial/reward_run Std             0.128943
evaluation/env_infos/initial/reward_run Max            -0.0422307
evaluation/env_infos/initial/reward_run Min            -0.54181
evaluation/env_infos/reward_run Mean                   -0.000230916
evaluation/env_infos/reward_run Std                     0.0240615
evaluation/env_infos/reward_run Max                     0.391164
evaluation/env_infos/reward_run Min                    -0.587887
evaluation/env_infos/final/reward_ctrl Mean            -0.0274744
evaluation/env_infos/final/reward_ctrl Std              0.0183572
evaluation/env_infos/final/reward_ctrl Max             -0.0082239
evaluation/env_infos/final/reward_ctrl Min             -0.0621299
evaluation/env_infos/initial/reward_ctrl Mean          -0.0339703
evaluation/env_infos/initial/reward_ctrl Std            0.0252369
evaluation/env_infos/initial/reward_ctrl Max           -0.00830893
evaluation/env_infos/initial/reward_ctrl Min           -0.0853256
evaluation/env_infos/reward_ctrl Mean                  -0.0274906
evaluation/env_infos/reward_ctrl Std                    0.0183674
evaluation/env_infos/reward_ctrl Max                   -0.00761193
evaluation/env_infos/reward_ctrl Min                   -0.0853256
evaluation/env_infos/final/height Mean                 -0.143229
evaluation/env_infos/final/height Std                   0.00805394
evaluation/env_infos/final/height Max                  -0.133051
evaluation/env_infos/final/height Min                  -0.159195
evaluation/env_infos/initial/height Mean               -0.01234
evaluation/env_infos/initial/height Std                 0.0524668
evaluation/env_infos/initial/height Max                 0.0849976
evaluation/env_infos/initial/height Min                -0.104949
evaluation/env_infos/height Mean                       -0.142897
evaluation/env_infos/height Std                         0.010141
evaluation/env_infos/height Max                         0.0849976
evaluation/env_infos/height Min                        -0.187085
evaluation/env_infos/final/reward_angular Mean         -7.96698e-09
evaluation/env_infos/final/reward_angular Std           1.77785e-08
evaluation/env_infos/final/reward_angular Max           1.32364e-15
evaluation/env_infos/final/reward_angular Min          -6.37256e-08
evaluation/env_infos/initial/reward_angular Mean        0.720935
evaluation/env_infos/initial/reward_angular Std         0.454819
evaluation/env_infos/initial/reward_angular Max         2.21294
evaluation/env_infos/initial/reward_angular Min        -0.11833
evaluation/env_infos/reward_angular Mean                0.002755
evaluation/env_infos/reward_angular Std                 0.0728537
evaluation/env_infos/reward_angular Max                 2.21294
evaluation/env_infos/reward_angular Min                -1.09192
time/data storing (s)                                   0.0730403
time/evaluation sampling (s)                           23.381
time/exploration sampling (s)                           1.0919
time/logging (s)                                        0.233982
time/saving (s)                                         0.554816
time/training (s)                                       3.59043
time/epoch (s)                                         28.9251
time/total (s)                                        115.821
Epoch                                                   3
-------------------------------------------------  ----------------
2021-05-25 10:04:59.313552 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 4 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  12000
trainer/QF1 Loss                                        0.674375
trainer/QF2 Loss                                        0.671835
trainer/Policy Loss                                    -6.75074
trainer/Q1 Predictions Mean                             3.12413
trainer/Q1 Predictions Std                              0.799901
trainer/Q1 Predictions Max                              6.99621
trainer/Q1 Predictions Min                              1.21742
trainer/Q2 Predictions Mean                             3.11529
trainer/Q2 Predictions Std                              0.821791
trainer/Q2 Predictions Max                              6.97004
trainer/Q2 Predictions Min                              1.05253
trainer/Q Targets Mean                                  3.0546
trainer/Q Targets Std                                   1.20782
trainer/Q Targets Max                                   7.13414
trainer/Q Targets Min                                  -1.46664
trainer/Log Pis Mean                                   -3.46471
trainer/Log Pis Std                                     1.31914
trainer/Log Pis Max                                     1.65658
trainer/Log Pis Min                                    -9.03913
trainer/Policy mu Mean                                 -0.150721
trainer/Policy mu Std                                   0.351773
trainer/Policy mu Max                                   1.01379
trainer/Policy mu Min                                  -1.66898
trainer/Policy log std Mean                            -0.120015
trainer/Policy log std Std                              0.0489382
trainer/Policy log std Max                             -0.0380612
trainer/Policy log std Min                             -0.377566
trainer/Alpha                                           0.303563
trainer/Alpha Loss                                    -11.256
exploration/num steps total                          6000
exploration/num paths total                             6
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.116997
exploration/Rewards Std                                 1.03355
exploration/Rewards Max                                 3.46695
exploration/Rewards Min                                -3.52064
exploration/Returns Mean                             -116.997
exploration/Returns Std                                 0
exploration/Returns Max                              -116.997
exploration/Returns Min                              -116.997
exploration/Actions Mean                               -0.136584
exploration/Actions Std                                 0.597409
exploration/Actions Max                                 0.995703
exploration/Actions Min                                -0.997237
exploration/Num Paths                                   1
exploration/Average Returns                          -116.997
exploration/env_infos/final/reward_run Mean            -0.314251
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.314251
exploration/env_infos/final/reward_run Min             -0.314251
exploration/env_infos/initial/reward_run Mean           0.646271
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.646271
exploration/env_infos/initial/reward_run Min            0.646271
exploration/env_infos/reward_run Mean                  -0.0633345
exploration/env_infos/reward_run Std                    0.658297
exploration/env_infos/reward_run Max                    1.96981
exploration/env_infos/reward_run Min                   -2.41861
exploration/env_infos/final/reward_ctrl Mean           -0.26821
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.26821
exploration/env_infos/final/reward_ctrl Min            -0.26821
exploration/env_infos/initial/reward_ctrl Mean         -0.17788
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.17788
exploration/env_infos/initial/reward_ctrl Min          -0.17788
exploration/env_infos/reward_ctrl Mean                 -0.225332
exploration/env_infos/reward_ctrl Std                   0.0759711
exploration/env_infos/reward_ctrl Max                  -0.0180479
exploration/env_infos/reward_ctrl Min                  -0.530547
exploration/env_infos/final/height Mean                -0.571479
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.571479
exploration/env_infos/final/height Min                 -0.571479
exploration/env_infos/initial/height Mean               0.0074968
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max                0.0074968
exploration/env_infos/initial/height Min                0.0074968
exploration/env_infos/height Mean                      -0.135353
exploration/env_infos/height Std                        0.199154
exploration/env_infos/height Max                        0.222859
exploration/env_infos/height Min                       -0.582419
exploration/env_infos/final/reward_angular Mean         0.16824
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          0.16824
exploration/env_infos/final/reward_angular Min          0.16824
exploration/env_infos/initial/reward_angular Mean      -0.381488
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.381488
exploration/env_infos/initial/reward_angular Min       -0.381488
exploration/env_infos/reward_angular Mean               0.0657009
exploration/env_infos/reward_angular Std                1.61063
exploration/env_infos/reward_angular Max                5.24682
exploration/env_infos/reward_angular Min               -5.48474
evaluation/num steps total                         125000
evaluation/num paths total                            125
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0712745
evaluation/Rewards Std                                  0.0536755
evaluation/Rewards Max                                  2.1386
evaluation/Rewards Min                                 -1.36382
evaluation/Returns Mean                               -71.2745
evaluation/Returns Std                                 31.796
evaluation/Returns Max                                 -9.18686
evaluation/Returns Min                               -126.691
evaluation/Actions Mean                                -0.0195462
evaluation/Actions Std                                  0.23112
evaluation/Actions Max                                  0.691919
evaluation/Actions Min                                 -0.831722
evaluation/Num Paths                                   25
evaluation/Average Returns                            -71.2745
evaluation/env_infos/final/reward_run Mean              3.10784e-09
evaluation/env_infos/final/reward_run Std               6.72129e-08
evaluation/env_infos/final/reward_run Max               2.24093e-07
evaluation/env_infos/final/reward_run Min              -1.29983e-07
evaluation/env_infos/initial/reward_run Mean            0.0131249
evaluation/env_infos/initial/reward_run Std             0.294852
evaluation/env_infos/initial/reward_run Max             0.65123
evaluation/env_infos/initial/reward_run Min            -0.584092
evaluation/env_infos/reward_run Mean                   -0.000125465
evaluation/env_infos/reward_run Std                     0.0287302
evaluation/env_infos/reward_run Max                     0.803087
evaluation/env_infos/reward_run Min                    -0.802472
evaluation/env_infos/final/reward_ctrl Mean            -0.0322688
evaluation/env_infos/final/reward_ctrl Std              0.0297504
evaluation/env_infos/final/reward_ctrl Max             -0.000632729
evaluation/env_infos/final/reward_ctrl Min             -0.105465
evaluation/env_infos/initial/reward_ctrl Mean          -0.0519604
evaluation/env_infos/initial/reward_ctrl Std            0.0467257
evaluation/env_infos/initial/reward_ctrl Max           -0.00206093
evaluation/env_infos/initial/reward_ctrl Min           -0.161321
evaluation/env_infos/reward_ctrl Mean                  -0.032279
evaluation/env_infos/reward_ctrl Std                    0.0297898
evaluation/env_infos/reward_ctrl Max                   -0.000632302
evaluation/env_infos/reward_ctrl Min                   -0.161321
evaluation/env_infos/final/height Mean                 -0.131105
evaluation/env_infos/final/height Std                   0.00888431
evaluation/env_infos/final/height Max                  -0.110869
evaluation/env_infos/final/height Min                  -0.148264
evaluation/env_infos/initial/height Mean               -0.0205242
evaluation/env_infos/initial/height Std                 0.0520697
evaluation/env_infos/initial/height Max                 0.0489552
evaluation/env_infos/initial/height Min                -0.106885
evaluation/env_infos/height Mean                       -0.13078
evaluation/env_infos/height Std                         0.010258
evaluation/env_infos/height Max                         0.0489552
evaluation/env_infos/height Min                        -0.185319
evaluation/env_infos/final/reward_angular Mean         -8.7849e-09
evaluation/env_infos/final/reward_angular Std           1.05412e-07
evaluation/env_infos/final/reward_angular Max           1.5347e-07
evaluation/env_infos/final/reward_angular Min          -4.32852e-07
evaluation/env_infos/initial/reward_angular Mean        0.214308
evaluation/env_infos/initial/reward_angular Std         1.01444
evaluation/env_infos/initial/reward_angular Max         2.36575
evaluation/env_infos/initial/reward_angular Min        -1.17393
evaluation/env_infos/reward_angular Mean                0.00109111
evaluation/env_infos/reward_angular Std                 0.0660697
evaluation/env_infos/reward_angular Max                 2.48436
evaluation/env_infos/reward_angular Min                -1.17393
time/data storing (s)                                   0.073322
time/evaluation sampling (s)                           22.1009
time/exploration sampling (s)                           1.03337
time/logging (s)                                        0.227637
time/saving (s)                                         0.642549
time/training (s)                                       3.33425
time/epoch (s)                                         27.412
time/total (s)                                        143.372
Epoch                                                   4
-------------------------------------------------  ----------------
2021-05-25 10:05:27.314605 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 5 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  14000
trainer/QF1 Loss                                        0.651759
trainer/QF2 Loss                                        0.662258
trainer/Policy Loss                                    -6.77202
trainer/Q1 Predictions Mean                             3.15381
trainer/Q1 Predictions Std                              0.869619
trainer/Q1 Predictions Max                              5.94279
trainer/Q1 Predictions Min                              0.943441
trainer/Q2 Predictions Mean                             3.14131
trainer/Q2 Predictions Std                              0.827561
trainer/Q2 Predictions Max                              5.61035
trainer/Q2 Predictions Min                              0.73231
trainer/Q Targets Mean                                  2.98923
trainer/Q Targets Std                                   1.17215
trainer/Q Targets Max                                   7.09112
trainer/Q Targets Min                                  -1.35734
trainer/Log Pis Mean                                   -3.30114
trainer/Log Pis Std                                     1.47916
trainer/Log Pis Max                                     1.51592
trainer/Log Pis Min                                    -6.67839
trainer/Policy mu Mean                                 -0.068392
trainer/Policy mu Std                                   0.442745
trainer/Policy mu Max                                   1.47981
trainer/Policy mu Min                                  -1.23143
trainer/Policy log std Mean                            -0.175039
trainer/Policy log std Std                              0.0645908
trainer/Policy log std Max                             -0.0541848
trainer/Policy log std Min                             -0.458117
trainer/Alpha                                           0.227438
trainer/Alpha Loss                                    -13.7473
exploration/num steps total                          7000
exploration/num paths total                             7
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.164032
exploration/Rewards Std                                 0.590066
exploration/Rewards Max                                 1.61774
exploration/Rewards Min                                -1.71077
exploration/Returns Mean                             -164.032
exploration/Returns Std                                 0
exploration/Returns Max                              -164.032
exploration/Returns Min                              -164.032
exploration/Actions Mean                               -0.110917
exploration/Actions Std                                 0.587054
exploration/Actions Max                                 0.995321
exploration/Actions Min                                -0.998651
exploration/Num Paths                                   1
exploration/Average Returns                          -164.032
exploration/env_infos/final/reward_run Mean            -0.144207
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.144207
exploration/env_infos/final/reward_run Min             -0.144207
exploration/env_infos/initial/reward_run Mean          -0.550808
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max           -0.550808
exploration/env_infos/initial/reward_run Min           -0.550808
exploration/env_infos/reward_run Mean                  -0.028723
exploration/env_infos/reward_run Std                    0.75675
exploration/env_infos/reward_run Max                    2.48399
exploration/env_infos/reward_run Min                   -2.59109
exploration/env_infos/final/reward_ctrl Mean           -0.335947
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.335947
exploration/env_infos/final/reward_ctrl Min            -0.335947
exploration/env_infos/initial/reward_ctrl Mean         -0.252651
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.252651
exploration/env_infos/initial/reward_ctrl Min          -0.252651
exploration/env_infos/reward_ctrl Mean                 -0.214161
exploration/env_infos/reward_ctrl Std                   0.0745579
exploration/env_infos/reward_ctrl Max                  -0.0287584
exploration/env_infos/reward_ctrl Min                  -0.441293
exploration/env_infos/final/height Mean                -0.529189
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.529189
exploration/env_infos/final/height Min                 -0.529189
exploration/env_infos/initial/height Mean              -0.0654903
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0654903
exploration/env_infos/initial/height Min               -0.0654903
exploration/env_infos/height Mean                      -0.0998852
exploration/env_infos/height Std                        0.127984
exploration/env_infos/height Max                        0.31034
exploration/env_infos/height Min                       -0.576657
exploration/env_infos/final/reward_angular Mean        -1.2046
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -1.2046
exploration/env_infos/final/reward_angular Min         -1.2046
exploration/env_infos/initial/reward_angular Mean       3.12939
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max        3.12939
exploration/env_infos/initial/reward_angular Min        3.12939
exploration/env_infos/reward_angular Mean               0.0612807
exploration/env_infos/reward_angular Std                1.59545
exploration/env_infos/reward_angular Max                5.04262
exploration/env_infos/reward_angular Min               -4.68497
evaluation/num steps total                         150000
evaluation/num paths total                            150
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0916381
evaluation/Rewards Std                                  0.0664807
evaluation/Rewards Max                                  1.93555
evaluation/Rewards Min                                 -1.36627
evaluation/Returns Mean                               -91.6381
evaluation/Returns Std                                 32.2965
evaluation/Returns Max                                -18.9686
evaluation/Returns Min                               -146.275
evaluation/Actions Mean                                 0.0292535
evaluation/Actions Std                                  0.337004
evaluation/Actions Max                                  0.765868
evaluation/Actions Min                                 -0.735235
evaluation/Num Paths                                   25
evaluation/Average Returns                            -91.6381
evaluation/env_infos/final/reward_run Mean              0.0109908
evaluation/env_infos/final/reward_run Std               0.0571776
evaluation/env_infos/final/reward_run Max               0.210627
evaluation/env_infos/final/reward_run Min              -0.138002
evaluation/env_infos/initial/reward_run Mean            0.0481963
evaluation/env_infos/initial/reward_run Std             0.451353
evaluation/env_infos/initial/reward_run Max             0.84208
evaluation/env_infos/initial/reward_run Min            -0.674938
evaluation/env_infos/reward_run Mean                    0.00107276
evaluation/env_infos/reward_run Std                     0.0807572
evaluation/env_infos/reward_run Max                     0.919628
evaluation/env_infos/reward_run Min                    -1.00974
evaluation/env_infos/final/reward_ctrl Mean            -0.0687449
evaluation/env_infos/final/reward_ctrl Std              0.0430863
evaluation/env_infos/final/reward_ctrl Max             -0.00237116
evaluation/env_infos/final/reward_ctrl Min             -0.142022
evaluation/env_infos/initial/reward_ctrl Mean          -0.0881701
evaluation/env_infos/initial/reward_ctrl Std            0.0530392
evaluation/env_infos/initial/reward_ctrl Max           -0.00732899
evaluation/env_infos/initial/reward_ctrl Min           -0.184165
evaluation/env_infos/reward_ctrl Mean                  -0.0686565
evaluation/env_infos/reward_ctrl Std                    0.0433308
evaluation/env_infos/reward_ctrl Max                   -0.000442921
evaluation/env_infos/reward_ctrl Min                   -0.185637
evaluation/env_infos/final/height Mean                 -0.152548
evaluation/env_infos/final/height Std                   0.0406522
evaluation/env_infos/final/height Max                  -0.123248
evaluation/env_infos/final/height Min                  -0.346168
evaluation/env_infos/initial/height Mean               -0.032351
evaluation/env_infos/initial/height Std                 0.0534567
evaluation/env_infos/initial/height Max                 0.0758293
evaluation/env_infos/initial/height Min                -0.100578
evaluation/env_infos/height Mean                       -0.152248
evaluation/env_infos/height Std                         0.0407788
evaluation/env_infos/height Max                         0.0758293
evaluation/env_infos/height Min                        -0.408201
evaluation/env_infos/final/reward_angular Mean         -0.00269545
evaluation/env_infos/final/reward_angular Std           0.0674287
evaluation/env_infos/final/reward_angular Max           0.202125
evaluation/env_infos/final/reward_angular Min          -0.198602
evaluation/env_infos/initial/reward_angular Mean       -0.17657
evaluation/env_infos/initial/reward_angular Std         1.23553
evaluation/env_infos/initial/reward_angular Max         1.79277
evaluation/env_infos/initial/reward_angular Min        -1.9926
evaluation/env_infos/reward_angular Mean                0.00127673
evaluation/env_infos/reward_angular Std                 0.0939898
evaluation/env_infos/reward_angular Max                 1.79277
evaluation/env_infos/reward_angular Min                -1.9926
time/data storing (s)                                   0.0773512
time/evaluation sampling (s)                           22.3021
time/exploration sampling (s)                           1.10174
time/logging (s)                                        0.232948
time/saving (s)                                         0.745022
time/training (s)                                       3.40747
time/epoch (s)                                         27.8667
time/total (s)                                        171.377
Epoch                                                   5
-------------------------------------------------  ----------------
2021-05-25 10:05:56.358958 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 6 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  16000
trainer/QF1 Loss                                        0.53774
trainer/QF2 Loss                                        0.519711
trainer/Policy Loss                                    -6.5484
trainer/Q1 Predictions Mean                             3.2432
trainer/Q1 Predictions Std                              1.09611
trainer/Q1 Predictions Max                              6.94537
trainer/Q1 Predictions Min                              0.704928
trainer/Q2 Predictions Mean                             3.22139
trainer/Q2 Predictions Std                              1.10234
trainer/Q2 Predictions Max                              6.78165
trainer/Q2 Predictions Min                              0.603459
trainer/Q Targets Mean                                  3.3539
trainer/Q Targets Std                                   1.38338
trainer/Q Targets Max                                   7.29192
trainer/Q Targets Min                                  -1.10934
trainer/Log Pis Mean                                   -2.87473
trainer/Log Pis Std                                     1.75447
trainer/Log Pis Max                                     3.92382
trainer/Log Pis Min                                    -6.30094
trainer/Policy mu Mean                                  0.000794585
trainer/Policy mu Std                                   0.55741
trainer/Policy mu Max                                   1.4723
trainer/Policy mu Min                                  -1.44608
trainer/Policy log std Mean                            -0.206259
trainer/Policy log std Std                              0.0899399
trainer/Policy log std Max                             -0.00900124
trainer/Policy log std Min                             -0.510564
trainer/Alpha                                           0.172206
trainer/Alpha Loss                                    -15.5867
exploration/num steps total                          8000
exploration/num paths total                             8
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.238908
exploration/Rewards Std                                 0.467425
exploration/Rewards Max                                 1.49505
exploration/Rewards Min                                -2.12385
exploration/Returns Mean                             -238.908
exploration/Returns Std                                 0
exploration/Returns Max                              -238.908
exploration/Returns Min                              -238.908
exploration/Actions Mean                                0.398323
exploration/Actions Std                                 0.546327
exploration/Actions Max                                 0.998484
exploration/Actions Min                                -0.990649
exploration/Num Paths                                   1
exploration/Average Returns                          -238.908
exploration/env_infos/final/reward_run Mean            -0.451255
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.451255
exploration/env_infos/final/reward_run Min             -0.451255
exploration/env_infos/initial/reward_run Mean           0.461022
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.461022
exploration/env_infos/initial/reward_run Min            0.461022
exploration/env_infos/reward_run Mean                   0.0337076
exploration/env_infos/reward_run Std                    0.379002
exploration/env_infos/reward_run Max                    1.32655
exploration/env_infos/reward_run Min                   -1.9239
exploration/env_infos/final/reward_ctrl Mean           -0.319314
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.319314
exploration/env_infos/final/reward_ctrl Min            -0.319314
exploration/env_infos/initial/reward_ctrl Mean         -0.166665
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.166665
exploration/env_infos/initial/reward_ctrl Min          -0.166665
exploration/env_infos/reward_ctrl Mean                 -0.27428
exploration/env_infos/reward_ctrl Std                   0.0758771
exploration/env_infos/reward_ctrl Max                  -0.0625168
exploration/env_infos/reward_ctrl Min                  -0.471729
exploration/env_infos/final/height Mean                -0.179001
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.179001
exploration/env_infos/final/height Min                 -0.179001
exploration/env_infos/initial/height Mean               0.0199911
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max                0.0199911
exploration/env_infos/initial/height Min                0.0199911
exploration/env_infos/height Mean                      -0.282136
exploration/env_infos/height Std                        0.0867378
exploration/env_infos/height Max                        0.0199911
exploration/env_infos/height Min                       -0.458
exploration/env_infos/final/reward_angular Mean        -2.01344
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -2.01344
exploration/env_infos/final/reward_angular Min         -2.01344
exploration/env_infos/initial/reward_angular Mean      -1.27795
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -1.27795
exploration/env_infos/initial/reward_angular Min       -1.27795
exploration/env_infos/reward_angular Mean              -0.00946082
exploration/env_infos/reward_angular Std                1.10644
exploration/env_infos/reward_angular Max                3.63024
exploration/env_infos/reward_angular Min               -3.66443
evaluation/num steps total                         175000
evaluation/num paths total                            175
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.14341
evaluation/Rewards Std                                  0.110074
evaluation/Rewards Max                                  2.29713
evaluation/Rewards Min                                 -1.54264
evaluation/Returns Mean                              -143.41
evaluation/Returns Std                                 68.2814
evaluation/Returns Max                                -37.3812
evaluation/Returns Min                               -341.28
evaluation/Actions Mean                                 0.0619582
evaluation/Actions Std                                  0.492557
evaluation/Actions Max                                  0.915968
evaluation/Actions Min                                 -0.83224
evaluation/Num Paths                                   25
evaluation/Average Returns                           -143.41
evaluation/env_infos/final/reward_run Mean             -2.27837e-07
evaluation/env_infos/final/reward_run Std               1.45173e-05
evaluation/env_infos/final/reward_run Max               5.04589e-05
evaluation/env_infos/final/reward_run Min              -5.2021e-05
evaluation/env_infos/initial/reward_run Mean            0.125073
evaluation/env_infos/initial/reward_run Std             0.442776
evaluation/env_infos/initial/reward_run Max             0.812923
evaluation/env_infos/initial/reward_run Min            -0.646771
evaluation/env_infos/reward_run Mean                    0.00268457
evaluation/env_infos/reward_run Std                     0.0484625
evaluation/env_infos/reward_run Max                     1.05579
evaluation/env_infos/reward_run Min                    -0.794698
evaluation/env_infos/final/reward_ctrl Mean            -0.147776
evaluation/env_infos/final/reward_ctrl Std              0.0919223
evaluation/env_infos/final/reward_ctrl Max             -0.00259264
evaluation/env_infos/final/reward_ctrl Min             -0.316875
evaluation/env_infos/initial/reward_ctrl Mean          -0.146799
evaluation/env_infos/initial/reward_ctrl Std            0.0890917
evaluation/env_infos/initial/reward_ctrl Max           -0.00567927
evaluation/env_infos/initial/reward_ctrl Min           -0.304213
evaluation/env_infos/reward_ctrl Mean                  -0.147871
evaluation/env_infos/reward_ctrl Std                    0.0920284
evaluation/env_infos/reward_ctrl Max                   -0.00160692
evaluation/env_infos/reward_ctrl Min                   -0.335263
evaluation/env_infos/final/height Mean                 -0.220356
evaluation/env_infos/final/height Std                   0.100983
evaluation/env_infos/final/height Max                  -0.133223
evaluation/env_infos/final/height Min                  -0.413262
evaluation/env_infos/initial/height Mean               -0.0205031
evaluation/env_infos/initial/height Std                 0.0432817
evaluation/env_infos/initial/height Max                 0.0715924
evaluation/env_infos/initial/height Min                -0.0787673
evaluation/env_infos/height Mean                       -0.219445
evaluation/env_infos/height Std                         0.10094
evaluation/env_infos/height Max                         0.0715924
evaluation/env_infos/height Min                        -0.44813
evaluation/env_infos/final/reward_angular Mean          1.34068e-06
evaluation/env_infos/final/reward_angular Std           6.32924e-05
evaluation/env_infos/final/reward_angular Max           0.000258055
evaluation/env_infos/final/reward_angular Min          -0.00017691
evaluation/env_infos/initial/reward_angular Mean       -0.194017
evaluation/env_infos/initial/reward_angular Std         1.60251
evaluation/env_infos/initial/reward_angular Max         2.73446
evaluation/env_infos/initial/reward_angular Min        -2.25737
evaluation/env_infos/reward_angular Mean                0.00477842
evaluation/env_infos/reward_angular Std                 0.117707
evaluation/env_infos/reward_angular Max                 2.73446
evaluation/env_infos/reward_angular Min                -2.25737
time/data storing (s)                                   0.0770135
time/evaluation sampling (s)                           23.2264
time/exploration sampling (s)                           1.04948
time/logging (s)                                        0.233979
time/saving (s)                                         0.857612
time/training (s)                                       3.43736
time/epoch (s)                                         28.8818
time/total (s)                                        200.422
Epoch                                                   6
-------------------------------------------------  ----------------
2021-05-25 10:06:25.139789 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 7 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  18000
trainer/QF1 Loss                                        0.536057
trainer/QF2 Loss                                        0.547271
trainer/Policy Loss                                    -6.65946
trainer/Q1 Predictions Mean                             3.49932
trainer/Q1 Predictions Std                              1.23845
trainer/Q1 Predictions Max                              7.39008
trainer/Q1 Predictions Min                              1.05298
trainer/Q2 Predictions Mean                             3.50949
trainer/Q2 Predictions Std                              1.26555
trainer/Q2 Predictions Max                              7.71064
trainer/Q2 Predictions Min                              1.04071
trainer/Q Targets Mean                                  3.4322
trainer/Q Targets Std                                   1.41254
trainer/Q Targets Max                                   9.73416
trainer/Q Targets Min                                   0.0921724
trainer/Log Pis Mean                                   -2.76409
trainer/Log Pis Std                                     1.8866
trainer/Log Pis Max                                     3.74837
trainer/Log Pis Min                                    -8.07718
trainer/Policy mu Mean                                 -0.128029
trainer/Policy mu Std                                   0.588057
trainer/Policy mu Max                                   1.39576
trainer/Policy mu Min                                  -1.87157
trainer/Policy log std Mean                            -0.209316
trainer/Policy log std Std                              0.0956104
trainer/Policy log std Max                              0.026254
trainer/Policy log std Min                             -0.617633
trainer/Alpha                                           0.131228
trainer/Alpha Loss                                    -17.7743
exploration/num steps total                          9000
exploration/num paths total                             9
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.343902
exploration/Rewards Std                                 0.452104
exploration/Rewards Max                                 1.50625
exploration/Rewards Min                                -1.59101
exploration/Returns Mean                             -343.902
exploration/Returns Std                                 0
exploration/Returns Max                              -343.902
exploration/Returns Min                              -343.902
exploration/Actions Mean                                0.109786
exploration/Actions Std                                 0.587916
exploration/Actions Max                                 0.998084
exploration/Actions Min                                -0.997428
exploration/Num Paths                                   1
exploration/Average Returns                          -343.902
exploration/env_infos/final/reward_run Mean             0.256421
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.256421
exploration/env_infos/final/reward_run Min              0.256421
exploration/env_infos/initial/reward_run Mean           0.0816649
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.0816649
exploration/env_infos/initial/reward_run Min            0.0816649
exploration/env_infos/reward_run Mean                  -0.00480965
exploration/env_infos/reward_run Std                    0.5378
exploration/env_infos/reward_run Max                    1.80573
exploration/env_infos/reward_run Min                   -1.69407
exploration/env_infos/final/reward_ctrl Mean           -0.323406
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.323406
exploration/env_infos/final/reward_ctrl Min            -0.323406
exploration/env_infos/initial/reward_ctrl Mean         -0.33974
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.33974
exploration/env_infos/initial/reward_ctrl Min          -0.33974
exploration/env_infos/reward_ctrl Mean                 -0.214619
exploration/env_infos/reward_ctrl Std                   0.0749774
exploration/env_infos/reward_ctrl Max                  -0.0138508
exploration/env_infos/reward_ctrl Min                  -0.416817
exploration/env_infos/final/height Mean                -0.56875
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.56875
exploration/env_infos/final/height Min                 -0.56875
exploration/env_infos/initial/height Mean              -0.06569
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.06569
exploration/env_infos/initial/height Min               -0.06569
exploration/env_infos/height Mean                      -0.441476
exploration/env_infos/height Std                        0.196663
exploration/env_infos/height Max                        0.0857534
exploration/env_infos/height Min                       -0.582974
exploration/env_infos/final/reward_angular Mean         1.51335
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          1.51335
exploration/env_infos/final/reward_angular Min          1.51335
exploration/env_infos/initial/reward_angular Mean      -2.50022
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -2.50022
exploration/env_infos/initial/reward_angular Min       -2.50022
exploration/env_infos/reward_angular Mean               0.0818563
exploration/env_infos/reward_angular Std                1.21202
exploration/env_infos/reward_angular Max                5.21187
exploration/env_infos/reward_angular Min               -4.06055
evaluation/num steps total                         200000
evaluation/num paths total                            200
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.136461
evaluation/Rewards Std                                  0.0750717
evaluation/Rewards Max                                  2.28525
evaluation/Rewards Min                                 -0.989143
evaluation/Returns Mean                              -136.461
evaluation/Returns Std                                 45.8616
evaluation/Returns Max                                -29.3389
evaluation/Returns Min                               -203.285
evaluation/Actions Mean                                -0.0303068
evaluation/Actions Std                                  0.530843
evaluation/Actions Max                                  0.930464
evaluation/Actions Min                                 -0.955206
evaluation/Num Paths                                   25
evaluation/Average Returns                           -136.461
evaluation/env_infos/final/reward_run Mean             -0.0023943
evaluation/env_infos/final/reward_run Std               0.011729
evaluation/env_infos/final/reward_run Max               2.49364e-08
evaluation/env_infos/final/reward_run Min              -0.0598545
evaluation/env_infos/initial/reward_run Mean           -0.0801644
evaluation/env_infos/initial/reward_run Std             0.46083
evaluation/env_infos/initial/reward_run Max             0.747209
evaluation/env_infos/initial/reward_run Min            -0.914167
evaluation/env_infos/reward_run Mean                    0.000159404
evaluation/env_infos/reward_run Std                     0.0508896
evaluation/env_infos/reward_run Max                     0.797002
evaluation/env_infos/reward_run Min                    -1.10477
evaluation/env_infos/final/reward_ctrl Mean            -0.169597
evaluation/env_infos/final/reward_ctrl Std              0.0949974
evaluation/env_infos/final/reward_ctrl Max             -0.00160869
evaluation/env_infos/final/reward_ctrl Min             -0.320799
evaluation/env_infos/initial/reward_ctrl Mean          -0.159377
evaluation/env_infos/initial/reward_ctrl Std            0.09133
evaluation/env_infos/initial/reward_ctrl Max           -0.0018364
evaluation/env_infos/initial/reward_ctrl Min           -0.30743
evaluation/env_infos/reward_ctrl Mean                  -0.169628
evaluation/env_infos/reward_ctrl Std                    0.0947788
evaluation/env_infos/reward_ctrl Max                   -0.00151312
evaluation/env_infos/reward_ctrl Min                   -0.339947
evaluation/env_infos/final/height Mean                 -0.167677
evaluation/env_infos/final/height Std                   0.0228407
evaluation/env_infos/final/height Max                  -0.120856
evaluation/env_infos/final/height Min                  -0.205444
evaluation/env_infos/initial/height Mean               -0.0111441
evaluation/env_infos/initial/height Std                 0.0553455
evaluation/env_infos/initial/height Max                 0.0894902
evaluation/env_infos/initial/height Min                -0.0893722
evaluation/env_infos/height Mean                       -0.16784
evaluation/env_infos/height Std                         0.0237723
evaluation/env_infos/height Max                         0.0894902
evaluation/env_infos/height Min                        -0.262471
evaluation/env_infos/final/reward_angular Mean          0.00726219
evaluation/env_infos/final/reward_angular Std           0.035576
evaluation/env_infos/final/reward_angular Max           0.181548
evaluation/env_infos/final/reward_angular Min          -5.03473e-08
evaluation/env_infos/initial/reward_angular Mean        0.077248
evaluation/env_infos/initial/reward_angular Std         1.65549
evaluation/env_infos/initial/reward_angular Max         2.69811
evaluation/env_infos/initial/reward_angular Min        -2.07162
evaluation/env_infos/reward_angular Mean                0.000972604
evaluation/env_infos/reward_angular Std                 0.0956772
evaluation/env_infos/reward_angular Max                 2.69811
evaluation/env_infos/reward_angular Min                -2.07162
time/data storing (s)                                   0.0857664
time/evaluation sampling (s)                           22.2095
time/exploration sampling (s)                           1.02558
time/logging (s)                                        0.232476
time/saving (s)                                         0.951306
time/training (s)                                       4.11402
time/epoch (s)                                         28.6187
time/total (s)                                        229.2
Epoch                                                   7
-------------------------------------------------  ----------------
2021-05-25 10:06:54.448476 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 8 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  20000
trainer/QF1 Loss                                        0.661419
trainer/QF2 Loss                                        0.700122
trainer/Policy Loss                                    -5.7838
trainer/Q1 Predictions Mean                             3.46513
trainer/Q1 Predictions Std                              1.41852
trainer/Q1 Predictions Max                              7.74684
trainer/Q1 Predictions Min                              0.910088
trainer/Q2 Predictions Mean                             3.44127
trainer/Q2 Predictions Std                              1.48484
trainer/Q2 Predictions Max                              8.39418
trainer/Q2 Predictions Min                              0.871825
trainer/Q Targets Mean                                  3.5316
trainer/Q Targets Std                                   1.62855
trainer/Q Targets Max                                  10.4788
trainer/Q Targets Min                                   0.409878
trainer/Log Pis Mean                                   -1.87042
trainer/Log Pis Std                                     2.32169
trainer/Log Pis Max                                     7.73329
trainer/Log Pis Min                                    -6.54005
trainer/Policy mu Mean                                 -0.119085
trainer/Policy mu Std                                   0.734781
trainer/Policy mu Max                                   2.34556
trainer/Policy mu Min                                  -2.4014
trainer/Policy log std Mean                            -0.257732
trainer/Policy log std Std                              0.105327
trainer/Policy log std Max                              0.0993097
trainer/Policy log std Min                             -0.826296
trainer/Alpha                                           0.100439
trainer/Alpha Loss                                    -18.0673
exploration/num steps total                         10000
exploration/num paths total                            10
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.303205
exploration/Rewards Std                                 0.713587
exploration/Rewards Max                                 1.96056
exploration/Rewards Min                                -3.33432
exploration/Returns Mean                             -303.205
exploration/Returns Std                                 0
exploration/Returns Max                              -303.205
exploration/Returns Min                              -303.205
exploration/Actions Mean                                0.280853
exploration/Actions Std                                 0.581423
exploration/Actions Max                                 0.998244
exploration/Actions Min                                -0.996993
exploration/Num Paths                                   1
exploration/Average Returns                          -303.205
exploration/env_infos/final/reward_run Mean            -0.978531
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.978531
exploration/env_infos/final/reward_run Min             -0.978531
exploration/env_infos/initial/reward_run Mean           0.629955
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.629955
exploration/env_infos/initial/reward_run Min            0.629955
exploration/env_infos/reward_run Mean                  -0.0825263
exploration/env_infos/reward_run Std                    0.528906
exploration/env_infos/reward_run Max                    1.89241
exploration/env_infos/reward_run Min                   -1.78536
exploration/env_infos/final/reward_ctrl Mean           -0.268267
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.268267
exploration/env_infos/final/reward_ctrl Min            -0.268267
exploration/env_infos/initial/reward_ctrl Mean         -0.278636
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.278636
exploration/env_infos/initial/reward_ctrl Min          -0.278636
exploration/env_infos/reward_ctrl Mean                 -0.250158
exploration/env_infos/reward_ctrl Std                   0.0768456
exploration/env_infos/reward_ctrl Max                  -0.0450924
exploration/env_infos/reward_ctrl Min                  -0.4823
exploration/env_infos/final/height Mean                -0.427615
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.427615
exploration/env_infos/final/height Min                 -0.427615
exploration/env_infos/initial/height Mean              -0.0117363
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0117363
exploration/env_infos/initial/height Min               -0.0117363
exploration/env_infos/height Mean                      -0.39116
exploration/env_infos/height Std                        0.210832
exploration/env_infos/height Max                        0.120124
exploration/env_infos/height Min                       -0.589287
exploration/env_infos/final/reward_angular Mean        -0.281127
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -0.281127
exploration/env_infos/final/reward_angular Min         -0.281127
exploration/env_infos/initial/reward_angular Mean      -1.69013
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -1.69013
exploration/env_infos/initial/reward_angular Min       -1.69013
exploration/env_infos/reward_angular Mean               0.0440453
exploration/env_infos/reward_angular Std                0.914901
exploration/env_infos/reward_angular Max                3.53999
exploration/env_infos/reward_angular Min               -2.77252
evaluation/num steps total                         225000
evaluation/num paths total                            225
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.144563
evaluation/Rewards Std                                  0.16347
evaluation/Rewards Max                                  2.63674
evaluation/Rewards Min                                 -2.35602
evaluation/Returns Mean                              -144.563
evaluation/Returns Std                                 57.6285
evaluation/Returns Max                                -22.6227
evaluation/Returns Min                               -287.428
evaluation/Actions Mean                                -0.0335912
evaluation/Actions Std                                  0.552833
evaluation/Actions Max                                  0.953046
evaluation/Actions Min                                 -0.966266
evaluation/Num Paths                                   25
evaluation/Average Returns                           -144.563
evaluation/env_infos/final/reward_run Mean             -0.0655568
evaluation/env_infos/final/reward_run Std               0.342873
evaluation/env_infos/final/reward_run Max               0.118883
evaluation/env_infos/final/reward_run Min              -1.74129
evaluation/env_infos/initial/reward_run Mean           -0.0655334
evaluation/env_infos/initial/reward_run Std             0.475504
evaluation/env_infos/initial/reward_run Max             0.628644
evaluation/env_infos/initial/reward_run Min            -0.999795
evaluation/env_infos/reward_run Mean                   -0.0234246
evaluation/env_infos/reward_run Std                     0.203347
evaluation/env_infos/reward_run Max                     1.45572
evaluation/env_infos/reward_run Min                    -2.64649
evaluation/env_infos/final/reward_ctrl Mean            -0.182852
evaluation/env_infos/final/reward_ctrl Std              0.105363
evaluation/env_infos/final/reward_ctrl Max             -0.00739416
evaluation/env_infos/final/reward_ctrl Min             -0.374041
evaluation/env_infos/initial/reward_ctrl Mean          -0.200051
evaluation/env_infos/initial/reward_ctrl Std            0.0963705
evaluation/env_infos/initial/reward_ctrl Max           -0.0221631
evaluation/env_infos/initial/reward_ctrl Min           -0.38056
evaluation/env_infos/reward_ctrl Mean                  -0.184052
evaluation/env_infos/reward_ctrl Std                    0.105953
evaluation/env_infos/reward_ctrl Max                   -0.00321175
evaluation/env_infos/reward_ctrl Min                   -0.38814
evaluation/env_infos/final/height Mean                 -0.170643
evaluation/env_infos/final/height Std                   0.0852619
evaluation/env_infos/final/height Max                  -0.119283
evaluation/env_infos/final/height Min                  -0.576958
evaluation/env_infos/initial/height Mean               -0.00571162
evaluation/env_infos/initial/height Std                 0.0444284
evaluation/env_infos/initial/height Max                 0.071524
evaluation/env_infos/initial/height Min                -0.0734475
evaluation/env_infos/height Mean                       -0.164436
evaluation/env_infos/height Std                         0.0803764
evaluation/env_infos/height Max                         0.23259
evaluation/env_infos/height Min                        -0.577998
evaluation/env_infos/final/reward_angular Mean          0.00804076
evaluation/env_infos/final/reward_angular Std           0.037297
evaluation/env_infos/final/reward_angular Max           0.190429
evaluation/env_infos/final/reward_angular Min          -0.000780546
evaluation/env_infos/initial/reward_angular Mean        0.262605
evaluation/env_infos/initial/reward_angular Std         1.71248
evaluation/env_infos/initial/reward_angular Max         3.5908
evaluation/env_infos/initial/reward_angular Min        -2.08018
evaluation/env_infos/reward_angular Mean                0.00631828
evaluation/env_infos/reward_angular Std                 0.232983
evaluation/env_infos/reward_angular Max                 3.5908
evaluation/env_infos/reward_angular Min                -3.14439
time/data storing (s)                                   0.0831256
time/evaluation sampling (s)                           22.7112
time/exploration sampling (s)                           1.03722
time/logging (s)                                        0.24029
time/saving (s)                                         1.04292
time/training (s)                                       4.02429
time/epoch (s)                                         29.139
time/total (s)                                        258.516
Epoch                                                   8
-------------------------------------------------  ----------------
2021-05-25 10:07:24.015288 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_10_02_39_0000--s-10] Epoch 9 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  22000
trainer/QF1 Loss                                        0.775429
trainer/QF2 Loss                                        0.778427
trainer/Policy Loss                                    -5.13137
trainer/Q1 Predictions Mean                             3.65603
trainer/Q1 Predictions Std                              1.76639
trainer/Q1 Predictions Max                             10.0465
trainer/Q1 Predictions Min                              0.406873
trainer/Q2 Predictions Mean                             3.6162
trainer/Q2 Predictions Std                              1.75922
trainer/Q2 Predictions Max                              9.7219
trainer/Q2 Predictions Min                              0.539754
trainer/Q Targets Mean                                  3.4601
trainer/Q Targets Std                                   1.9258
trainer/Q Targets Max                                  13.4437
trainer/Q Targets Min                                  -1.51123
trainer/Log Pis Mean                                   -1.01917
trainer/Log Pis Std                                     2.87467
trainer/Log Pis Max                                    11.7716
trainer/Log Pis Min                                    -6.75501
trainer/Policy mu Mean                                  0.04203
trainer/Policy mu Std                                   0.851622
trainer/Policy mu Max                                   3.60823
trainer/Policy mu Min                                  -2.47888
trainer/Policy log std Mean                            -0.329258
trainer/Policy log std Std                              0.127039
trainer/Policy log std Max                             -0.0309145
trainer/Policy log std Min                             -0.951365
trainer/Alpha                                           0.0777538
trainer/Alpha Loss                                    -17.911
exploration/num steps total                         11000
exploration/num paths total                            11
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.243743
exploration/Rewards Std                                 0.210418
exploration/Rewards Max                                 0.395651
exploration/Rewards Min                                -0.98224
exploration/Returns Mean                             -243.743
exploration/Returns Std                                 0
exploration/Returns Max                              -243.743
exploration/Returns Min                              -243.743
exploration/Actions Mean                                0.133087
exploration/Actions Std                                 0.602217
exploration/Actions Max                                 0.998106
exploration/Actions Min                                -0.995637
exploration/Num Paths                                   1
exploration/Average Returns                          -243.743
exploration/env_infos/final/reward_run Mean             0.236723
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.236723
exploration/env_infos/final/reward_run Min              0.236723
exploration/env_infos/initial/reward_run Mean           0.0381664
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.0381664
exploration/env_infos/initial/reward_run Min            0.0381664
exploration/env_infos/reward_run Mean                  -0.281319
exploration/env_infos/reward_run Std                    0.772228
exploration/env_infos/reward_run Max                    2.81636
exploration/env_infos/reward_run Min                   -3.14586
exploration/env_infos/final/reward_ctrl Mean           -0.258316
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.258316
exploration/env_infos/final/reward_ctrl Min            -0.258316
exploration/env_infos/initial/reward_ctrl Mean         -0.21028
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.21028
exploration/env_infos/initial/reward_ctrl Min          -0.21028
exploration/env_infos/reward_ctrl Mean                 -0.228227
exploration/env_infos/reward_ctrl Std                   0.0765333
exploration/env_infos/reward_ctrl Max                  -0.042218
exploration/env_infos/reward_ctrl Min                  -0.438333
exploration/env_infos/final/height Mean                -0.532294
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.532294
exploration/env_infos/final/height Min                 -0.532294
exploration/env_infos/initial/height Mean              -0.0483574
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0483574
exploration/env_infos/initial/height Min               -0.0483574
exploration/env_infos/height Mean                      -0.270712
exploration/env_infos/height Std                        0.242374
exploration/env_infos/height Max                        0.374183
exploration/env_infos/height Min                       -0.583402
exploration/env_infos/final/reward_angular Mean         0.961622
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          0.961622
exploration/env_infos/final/reward_angular Min          0.961622
exploration/env_infos/initial/reward_angular Mean      -0.982564
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.982564
exploration/env_infos/initial/reward_angular Min       -0.982564
exploration/env_infos/reward_angular Mean               0.0759825
exploration/env_infos/reward_angular Std                1.72256
exploration/env_infos/reward_angular Max                5.19944
exploration/env_infos/reward_angular Min               -6.45871
evaluation/num steps total                         250000
evaluation/num paths total                            250
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.140842
evaluation/Rewards Std                                  0.379187
evaluation/Rewards Max                                  4.41835
evaluation/Rewards Min                                 -4.87396
evaluation/Returns Mean                              -140.842
evaluation/Returns Std                                 79.9805
evaluation/Returns Max                                  3.58227
evaluation/Returns Min                               -306.43
evaluation/Actions Mean                                 0.131355
evaluation/Actions Std                                  0.552458
evaluation/Actions Max                                  0.997598
evaluation/Actions Min                                 -0.995037
evaluation/Num Paths                                   25
evaluation/Average Returns                           -140.842
evaluation/env_infos/final/reward_run Mean             -0.0451105
evaluation/env_infos/final/reward_run Std               0.460756
evaluation/env_infos/final/reward_run Max               0.851442
evaluation/env_infos/final/reward_run Min              -2.00938
evaluation/env_infos/initial/reward_run Mean            0.0401896
evaluation/env_infos/initial/reward_run Std             0.428524
evaluation/env_infos/initial/reward_run Max             0.87399
evaluation/env_infos/initial/reward_run Min            -0.881654
evaluation/env_infos/reward_run Mean                   -0.130989
evaluation/env_infos/reward_run Std                     0.465091
evaluation/env_infos/reward_run Max                     2.38364
evaluation/env_infos/reward_run Min                    -3.67676
evaluation/env_infos/final/reward_ctrl Mean            -0.194801
evaluation/env_infos/final/reward_ctrl Std              0.0852579
evaluation/env_infos/final/reward_ctrl Max             -0.0740378
evaluation/env_infos/final/reward_ctrl Min             -0.437289
evaluation/env_infos/initial/reward_ctrl Mean          -0.229299
evaluation/env_infos/initial/reward_ctrl Std            0.111237
evaluation/env_infos/initial/reward_ctrl Max           -0.0280743
evaluation/env_infos/initial/reward_ctrl Min           -0.437197
evaluation/env_infos/reward_ctrl Mean                  -0.193478
evaluation/env_infos/reward_ctrl Std                    0.0942611
evaluation/env_infos/reward_ctrl Max                   -0.0041485
evaluation/env_infos/reward_ctrl Min                   -0.499926
evaluation/env_infos/final/height Mean                 -0.243667
evaluation/env_infos/final/height Std                   0.147684
evaluation/env_infos/final/height Max                  -0.0294396
evaluation/env_infos/final/height Min                  -0.579704
evaluation/env_infos/initial/height Mean               -0.00834717
evaluation/env_infos/initial/height Std                 0.0546907
evaluation/env_infos/initial/height Max                 0.084783
evaluation/env_infos/initial/height Min                -0.0943825
evaluation/env_infos/height Mean                       -0.222084
evaluation/env_infos/height Std                         0.147175
evaluation/env_infos/height Max                         0.527375
evaluation/env_infos/height Min                        -0.585116
evaluation/env_infos/final/reward_angular Mean          0.0975331
evaluation/env_infos/final/reward_angular Std           0.702602
evaluation/env_infos/final/reward_angular Max           2.78736
evaluation/env_infos/final/reward_angular Min          -1.69172
evaluation/env_infos/initial/reward_angular Mean        0.00284597
evaluation/env_infos/initial/reward_angular Std         1.50687
evaluation/env_infos/initial/reward_angular Max         2.8137
evaluation/env_infos/initial/reward_angular Min        -2.5953
evaluation/env_infos/reward_angular Mean                0.0187198
evaluation/env_infos/reward_angular Std                 0.658179
evaluation/env_infos/reward_angular Max                 5.66183
evaluation/env_infos/reward_angular Min                -8.55481
time/data storing (s)                                   0.0832649
time/evaluation sampling (s)                           21.9055
time/exploration sampling (s)                           1.02547
time/logging (s)                                        0.236323
time/saving (s)                                         2.27075
time/training (s)                                       3.85751
time/epoch (s)                                         29.3788
time/total (s)                                        288.078
Epoch                                                   9
-------------------------------------------------  ---------------
