2021-05-25 09:48:48.777790 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 0 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  2000
trainer/QF1 Loss                                      15.308
trainer/QF2 Loss                                      15.2173
trainer/Policy Loss                                   -4.03244
trainer/Q1 Predictions Mean                           -0.00837021
trainer/Q1 Predictions Std                             0.00539224
trainer/Q1 Predictions Max                             0.00351438
trainer/Q1 Predictions Min                            -0.0247585
trainer/Q2 Predictions Mean                            0.00373413
trainer/Q2 Predictions Std                             0.00425307
trainer/Q2 Predictions Max                             0.0150093
trainer/Q2 Predictions Min                            -0.00635403
trainer/Q Targets Mean                                 3.6897
trainer/Q Targets Std                                  1.27715
trainer/Q Targets Max                                  7.91628
trainer/Q Targets Min                                  0.538645
trainer/Log Pis Mean                                  -4.04089
trainer/Log Pis Std                                    0.507264
trainer/Log Pis Max                                   -2.36068
trainer/Log Pis Min                                   -5.48774
trainer/Policy mu Mean                                -0.000890531
trainer/Policy mu Std                                  0.00234536
trainer/Policy mu Max                                  0.0068469
trainer/Policy mu Min                                 -0.00728334
trainer/Policy log std Mean                           -0.001294
trainer/Policy log std Std                             0.00167964
trainer/Policy log std Max                             0.00386344
trainer/Policy log std Min                            -0.00808519
trainer/Alpha                                          0.997005
trainer/Alpha Loss                                    -0
exploration/num steps total                         2000
exploration/num paths total                            2
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.242739
exploration/Rewards Std                                0.602001
exploration/Rewards Max                                1.86132
exploration/Rewards Min                               -1.97314
exploration/Returns Mean                            -242.739
exploration/Returns Std                                0
exploration/Returns Max                             -242.739
exploration/Returns Min                             -242.739
exploration/Actions Mean                               0.00115652
exploration/Actions Std                                0.627109
exploration/Actions Max                                0.999101
exploration/Actions Min                               -0.999804
exploration/Num Paths                                  1
exploration/Average Returns                         -242.739
exploration/env_infos/final/reward_run Mean            0.852688
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max             0.852688
exploration/env_infos/final/reward_run Min             0.852688
exploration/env_infos/initial/reward_run Mean         -0.428326
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max          -0.428326
exploration/env_infos/initial/reward_run Min          -0.428326
exploration/env_infos/reward_run Mean                 -0.144494
exploration/env_infos/reward_run Std                   0.741901
exploration/env_infos/reward_run Max                   2.56896
exploration/env_infos/reward_run Min                  -2.15828
exploration/env_infos/final/reward_ctrl Mean          -0.112538
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.112538
exploration/env_infos/final/reward_ctrl Min           -0.112538
exploration/env_infos/initial/reward_ctrl Mean        -0.144606
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.144606
exploration/env_infos/initial/reward_ctrl Min         -0.144606
exploration/env_infos/reward_ctrl Mean                -0.235961
exploration/env_infos/reward_ctrl Std                  0.0750452
exploration/env_infos/reward_ctrl Max                 -0.0181969
exploration/env_infos/reward_ctrl Min                 -0.476064
exploration/env_infos/final/height Mean               -0.113253
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                -0.113253
exploration/env_infos/final/height Min                -0.113253
exploration/env_infos/initial/height Mean             -0.0106174
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max              -0.0106174
exploration/env_infos/initial/height Min              -0.0106174
exploration/env_infos/height Mean                     -0.0677779
exploration/env_infos/height Std                       0.090601
exploration/env_infos/height Max                       0.28877
exploration/env_infos/height Min                      -0.359537
exploration/env_infos/final/reward_angular Mean       -0.673099
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max        -0.673099
exploration/env_infos/final/reward_angular Min        -0.673099
exploration/env_infos/initial/reward_angular Mean      0.243925
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max       0.243925
exploration/env_infos/initial/reward_angular Min       0.243925
exploration/env_infos/reward_angular Mean             -0.0160058
exploration/env_infos/reward_angular Std               1.68347
exploration/env_infos/reward_angular Max               8.25407
exploration/env_infos/reward_angular Min              -4.79874
evaluation/num steps total                         25000
evaluation/num paths total                            25
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.0616557
evaluation/Rewards Std                                 0.0464541
evaluation/Rewards Max                                 1.03703
evaluation/Rewards Min                                -1.79084
evaluation/Returns Mean                              -61.6557
evaluation/Returns Std                                37.9567
evaluation/Returns Max                                -1.74302
evaluation/Returns Min                              -127.828
evaluation/Actions Mean                               -0.000322867
evaluation/Actions Std                                 0.00121833
evaluation/Actions Max                                 0.00337062
evaluation/Actions Min                                -0.00309706
evaluation/Num Paths                                  25
evaluation/Average Returns                           -61.6557
evaluation/env_infos/final/reward_run Mean            -1.38778e-18
evaluation/env_infos/final/reward_run Std              1.31099e-16
evaluation/env_infos/final/reward_run Max              3.46945e-16
evaluation/env_infos/final/reward_run Min             -4.85723e-16
evaluation/env_infos/initial/reward_run Mean          -0.00648149
evaluation/env_infos/initial/reward_run Std            0.128515
evaluation/env_infos/initial/reward_run Max            0.224342
evaluation/env_infos/initial/reward_run Min           -0.209714
evaluation/env_infos/reward_run Mean                  -0.000342552
evaluation/env_infos/reward_run Std                    0.0159969
evaluation/env_infos/reward_run Max                    0.331155
evaluation/env_infos/reward_run Min                   -0.596655
evaluation/env_infos/final/reward_ctrl Mean           -9.52177e-07
evaluation/env_infos/final/reward_ctrl Std             9.0322e-08
evaluation/env_infos/final/reward_ctrl Max            -8.07404e-07
evaluation/env_infos/final/reward_ctrl Min            -1.10654e-06
evaluation/env_infos/initial/reward_ctrl Mean         -1.00818e-06
evaluation/env_infos/initial/reward_ctrl Std           1.10186e-07
evaluation/env_infos/initial/reward_ctrl Max          -8.31595e-07
evaluation/env_infos/initial/reward_ctrl Min          -1.27073e-06
evaluation/env_infos/reward_ctrl Mean                 -9.53144e-07
evaluation/env_infos/reward_ctrl Std                   9.47071e-08
evaluation/env_infos/reward_ctrl Max                  -5.85402e-07
evaluation/env_infos/reward_ctrl Min                  -2.62191e-06
evaluation/env_infos/final/height Mean                -0.132891
evaluation/env_infos/final/height Std                  3.5865e-05
evaluation/env_infos/final/height Max                 -0.132829
evaluation/env_infos/final/height Min                 -0.132952
evaluation/env_infos/initial/height Mean              -0.0148674
evaluation/env_infos/initial/height Std                0.0511682
evaluation/env_infos/initial/height Max                0.0698418
evaluation/env_infos/initial/height Min               -0.0935499
evaluation/env_infos/height Mean                      -0.132446
evaluation/env_infos/height Std                        0.00548373
evaluation/env_infos/height Max                        0.0698418
evaluation/env_infos/height Min                       -0.151457
evaluation/env_infos/final/reward_angular Mean        -2.47126e-16
evaluation/env_infos/final/reward_angular Std          1.28174e-15
evaluation/env_infos/final/reward_angular Max          2.03653e-15
evaluation/env_infos/final/reward_angular Min         -2.78989e-15
evaluation/env_infos/initial/reward_angular Mean       0.0871386
evaluation/env_infos/initial/reward_angular Std        0.35347
evaluation/env_infos/initial/reward_angular Max        1.00049
evaluation/env_infos/initial/reward_angular Min       -0.69915
evaluation/env_infos/reward_angular Mean               0.000916425
evaluation/env_infos/reward_angular Std                0.0405368
evaluation/env_infos/reward_angular Max                2.00984
evaluation/env_infos/reward_angular Min               -1.11431
time/data storing (s)                                  0.0102982
time/evaluation sampling (s)                          14.2598
time/exploration sampling (s)                          0.747804
time/logging (s)                                       0.160112
time/saving (s)                                        0.119761
time/training (s)                                      3.56843
time/epoch (s)                                        18.8662
time/total (s)                                        21.4794
Epoch                                                  0
-------------------------------------------------  ---------------
2021-05-25 09:49:21.666399 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 1 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  3000
trainer/QF1 Loss                                       0.716878
trainer/QF2 Loss                                       0.715369
trainer/Policy Loss                                   -7.39095
trainer/Q1 Predictions Mean                            3.36931
trainer/Q1 Predictions Std                             0.821825
trainer/Q1 Predictions Max                             6.99106
trainer/Q1 Predictions Min                             1.67353
trainer/Q2 Predictions Mean                            3.35358
trainer/Q2 Predictions Std                             0.824303
trainer/Q2 Predictions Max                             7.01771
trainer/Q2 Predictions Min                             1.5576
trainer/Q Targets Mean                                 3.31067
trainer/Q Targets Std                                  0.885876
trainer/Q Targets Max                                  6.95489
trainer/Q Targets Min                                  0.131229
trainer/Log Pis Mean                                  -4.04014
trainer/Log Pis Std                                    0.505871
trainer/Log Pis Max                                   -2.61216
trainer/Log Pis Min                                   -7.05572
trainer/Policy mu Mean                                -0.0549241
trainer/Policy mu Std                                  0.124947
trainer/Policy mu Max                                  0.116096
trainer/Policy mu Min                                 -0.409603
trainer/Policy log std Mean                           -0.123359
trainer/Policy log std Std                             0.0235149
trainer/Policy log std Max                            -0.0794437
trainer/Policy log std Min                            -0.21424
trainer/Alpha                                          0.738873
trainer/Alpha Loss                                    -3.00836
exploration/num steps total                         3000
exploration/num paths total                            3
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.179404
exploration/Rewards Std                                0.400273
exploration/Rewards Max                                0.988786
exploration/Rewards Min                               -1.65963
exploration/Returns Mean                            -179.404
exploration/Returns Std                                0
exploration/Returns Max                             -179.404
exploration/Returns Min                             -179.404
exploration/Actions Mean                              -0.042028
exploration/Actions Std                                0.596068
exploration/Actions Max                                0.995805
exploration/Actions Min                               -0.998916
exploration/Num Paths                                  1
exploration/Average Returns                         -179.404
exploration/env_infos/final/reward_run Mean           -0.0988751
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max            -0.0988751
exploration/env_infos/final/reward_run Min            -0.0988751
exploration/env_infos/initial/reward_run Mean         -0.237643
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max          -0.237643
exploration/env_infos/initial/reward_run Min          -0.237643
exploration/env_infos/reward_run Mean                  0.00431036
exploration/env_infos/reward_run Std                   0.593761
exploration/env_infos/reward_run Max                   1.9975
exploration/env_infos/reward_run Min                  -2.25639
exploration/env_infos/final/reward_ctrl Mean          -0.20893
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.20893
exploration/env_infos/final/reward_ctrl Min           -0.20893
exploration/env_infos/initial/reward_ctrl Mean        -0.221924
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.221924
exploration/env_infos/initial/reward_ctrl Min         -0.221924
exploration/env_infos/reward_ctrl Mean                -0.214238
exploration/env_infos/reward_ctrl Std                  0.0708193
exploration/env_infos/reward_ctrl Max                 -0.025795
exploration/env_infos/reward_ctrl Min                 -0.488112
exploration/env_infos/final/height Mean               -0.539993
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                -0.539993
exploration/env_infos/final/height Min                -0.539993
exploration/env_infos/initial/height Mean              0.059951
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max               0.059951
exploration/env_infos/initial/height Min               0.059951
exploration/env_infos/height Mean                     -0.376495
exploration/env_infos/height Std                       0.249335
exploration/env_infos/height Max                       0.20668
exploration/env_infos/height Min                      -0.582894
exploration/env_infos/final/reward_angular Mean        1.41597
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max         1.41597
exploration/env_infos/final/reward_angular Min         1.41597
exploration/env_infos/initial/reward_angular Mean      0.728871
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max       0.728871
exploration/env_infos/initial/reward_angular Min       0.728871
exploration/env_infos/reward_angular Mean              0.0618126
exploration/env_infos/reward_angular Std               1.3217
exploration/env_infos/reward_angular Max               5.73625
exploration/env_infos/reward_angular Min              -5.32131
evaluation/num steps total                         50000
evaluation/num paths total                            50
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.0577114
evaluation/Rewards Std                                 0.0428513
evaluation/Rewards Max                                 1.62833
evaluation/Rewards Min                                -1.175
evaluation/Returns Mean                              -57.7114
evaluation/Returns Std                                34.2455
evaluation/Returns Max                                -2.66717
evaluation/Returns Min                              -115.229
evaluation/Actions Mean                               -0.0428304
evaluation/Actions Std                                 0.0954994
evaluation/Actions Max                                 0.0636395
evaluation/Actions Min                                -0.264937
evaluation/Num Paths                                  25
evaluation/Average Returns                           -57.7114
evaluation/env_infos/final/reward_run Mean            -3.62743e-10
evaluation/env_infos/final/reward_run Std              1.25056e-09
evaluation/env_infos/final/reward_run Max              1.38778e-16
evaluation/env_infos/final/reward_run Min             -5.33045e-09
evaluation/env_infos/initial/reward_run Mean           0.0227596
evaluation/env_infos/initial/reward_run Std            0.133401
evaluation/env_infos/initial/reward_run Max            0.316651
evaluation/env_infos/initial/reward_run Min           -0.322676
evaluation/env_infos/reward_run Mean                  -0.000231162
evaluation/env_infos/reward_run Std                    0.0154693
evaluation/env_infos/reward_run Max                    0.324633
evaluation/env_infos/reward_run Min                   -0.392668
evaluation/env_infos/final/reward_ctrl Mean           -0.00657406
evaluation/env_infos/final/reward_ctrl Std             0.00123094
evaluation/env_infos/final/reward_ctrl Max            -0.00392907
evaluation/env_infos/final/reward_ctrl Min            -0.00802268
evaluation/env_infos/initial/reward_ctrl Mean         -0.00624336
evaluation/env_infos/initial/reward_ctrl Std           0.00123292
evaluation/env_infos/initial/reward_ctrl Max          -0.00364606
evaluation/env_infos/initial/reward_ctrl Min          -0.00765538
evaluation/env_infos/reward_ctrl Mean                 -0.00657275
evaluation/env_infos/reward_ctrl Std                   0.00123213
evaluation/env_infos/reward_ctrl Max                  -0.0028219
evaluation/env_infos/reward_ctrl Min                  -0.00866068
evaluation/env_infos/final/height Mean                -0.119925
evaluation/env_infos/final/height Std                  0.0011577
evaluation/env_infos/final/height Max                 -0.118665
evaluation/env_infos/final/height Min                 -0.122642
evaluation/env_infos/initial/height Mean              -0.00357963
evaluation/env_infos/initial/height Std                0.0557488
evaluation/env_infos/initial/height Max                0.0874939
evaluation/env_infos/initial/height Min               -0.0852113
evaluation/env_infos/height Mean                      -0.119482
evaluation/env_infos/height Std                        0.00563925
evaluation/env_infos/height Max                        0.0874939
evaluation/env_infos/height Min                       -0.130895
evaluation/env_infos/final/reward_angular Mean        -1.92928e-09
evaluation/env_infos/final/reward_angular Std          7.80218e-09
evaluation/env_infos/final/reward_angular Max          3.59114e-15
evaluation/env_infos/final/reward_angular Min         -3.9145e-08
evaluation/env_infos/initial/reward_angular Mean       0.34925
evaluation/env_infos/initial/reward_angular Std        0.380702
evaluation/env_infos/initial/reward_angular Max        1.52389
evaluation/env_infos/initial/reward_angular Min       -0.565741
evaluation/env_infos/reward_angular Mean               0.00144815
evaluation/env_infos/reward_angular Std                0.0434023
evaluation/env_infos/reward_angular Max                2.06922
evaluation/env_infos/reward_angular Min               -0.748635
time/data storing (s)                                  0.0164586
time/evaluation sampling (s)                          26.9206
time/exploration sampling (s)                          1.16573
time/logging (s)                                       0.251287
time/saving (s)                                        0.0346648
time/training (s)                                      4.37341
time/epoch (s)                                        32.7621
time/total (s)                                        54.4545
Epoch                                                  1
-------------------------------------------------  ---------------
2021-05-25 09:49:51.109459 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 2 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  4000
trainer/QF1 Loss                                       0.628485
trainer/QF2 Loss                                       0.646088
trainer/Policy Loss                                   -7.02914
trainer/Q1 Predictions Mean                            2.99543
trainer/Q1 Predictions Std                             0.585404
trainer/Q1 Predictions Max                             5.79048
trainer/Q1 Predictions Min                             1.65658
trainer/Q2 Predictions Mean                            2.98037
trainer/Q2 Predictions Std                             0.590456
trainer/Q2 Predictions Max                             5.72335
trainer/Q2 Predictions Min                             1.55598
trainer/Q Targets Mean                                 3.19934
trainer/Q Targets Std                                  1.02422
trainer/Q Targets Max                                  7.15342
trainer/Q Targets Min                                 -0.106277
trainer/Log Pis Mean                                  -4.02866
trainer/Log Pis Std                                    0.436922
trainer/Log Pis Max                                   -2.74928
trainer/Log Pis Min                                   -5.57368
trainer/Policy mu Mean                                -0.0371961
trainer/Policy mu Std                                  0.104126
trainer/Policy mu Max                                  0.174134
trainer/Policy mu Min                                 -0.417336
trainer/Policy log std Mean                           -0.108691
trainer/Policy log std Std                             0.0189877
trainer/Policy log std Max                            -0.0628312
trainer/Policy log std Min                            -0.19865
trainer/Alpha                                          0.547266
trainer/Alpha Loss                                    -6.01543
exploration/num steps total                         4000
exploration/num paths total                            4
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.105386
exploration/Rewards Std                                0.651082
exploration/Rewards Max                                1.86988
exploration/Rewards Min                               -2.73208
exploration/Returns Mean                            -105.386
exploration/Returns Std                                0
exploration/Returns Max                             -105.386
exploration/Returns Min                             -105.386
exploration/Actions Mean                              -0.0353178
exploration/Actions Std                                0.598077
exploration/Actions Max                                0.997966
exploration/Actions Min                               -0.997035
exploration/Num Paths                                  1
exploration/Average Returns                         -105.386
exploration/env_infos/final/reward_run Mean           -0.565021
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max            -0.565021
exploration/env_infos/final/reward_run Min            -0.565021
exploration/env_infos/initial/reward_run Mean          0.109238
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max           0.109238
exploration/env_infos/initial/reward_run Min           0.109238
exploration/env_infos/reward_run Mean                 -0.0185825
exploration/env_infos/reward_run Std                   0.629628
exploration/env_infos/reward_run Max                   1.92974
exploration/env_infos/reward_run Min                  -2.52668
exploration/env_infos/final/reward_ctrl Mean          -0.163203
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.163203
exploration/env_infos/final/reward_ctrl Min           -0.163203
exploration/env_infos/initial/reward_ctrl Mean        -0.186445
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.186445
exploration/env_infos/initial/reward_ctrl Min         -0.186445
exploration/env_infos/reward_ctrl Mean                -0.215366
exploration/env_infos/reward_ctrl Std                  0.0746918
exploration/env_infos/reward_ctrl Max                 -0.0240411
exploration/env_infos/reward_ctrl Min                 -0.428745
exploration/env_infos/final/height Mean               -0.0314477
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                -0.0314477
exploration/env_infos/final/height Min                -0.0314477
exploration/env_infos/initial/height Mean             -0.00889424
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max              -0.00889424
exploration/env_infos/initial/height Min              -0.00889424
exploration/env_infos/height Mean                     -0.0781313
exploration/env_infos/height Std                       0.0761144
exploration/env_infos/height Max                       0.15484
exploration/env_infos/height Min                      -0.308
exploration/env_infos/final/reward_angular Mean        0.545194
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max         0.545194
exploration/env_infos/final/reward_angular Min         0.545194
exploration/env_infos/initial/reward_angular Mean      0.760772
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max       0.760772
exploration/env_infos/initial/reward_angular Min       0.760772
exploration/env_infos/reward_angular Mean             -0.0108224
exploration/env_infos/reward_angular Std               1.65618
exploration/env_infos/reward_angular Max               5.39993
exploration/env_infos/reward_angular Min              -5.43889
evaluation/num steps total                         75000
evaluation/num paths total                            75
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.060113
evaluation/Rewards Std                                 0.0470167
evaluation/Rewards Max                                 1.47429
evaluation/Rewards Min                                -1.62088
evaluation/Returns Mean                              -60.113
evaluation/Returns Std                                35.8859
evaluation/Returns Max                                -1.8989
evaluation/Returns Min                              -119.99
evaluation/Actions Mean                               -0.0338328
evaluation/Actions Std                                 0.0894766
evaluation/Actions Max                                 0.120604
evaluation/Actions Min                                -0.232423
evaluation/Num Paths                                  25
evaluation/Average Returns                           -60.113
evaluation/env_infos/final/reward_run Mean            -3.25914e-10
evaluation/env_infos/final/reward_run Std              1.05633e-09
evaluation/env_infos/final/reward_run Max              2.77556e-16
evaluation/env_infos/final/reward_run Min             -4.1994e-09
evaluation/env_infos/initial/reward_run Mean           0.0430652
evaluation/env_infos/initial/reward_run Std            0.120804
evaluation/env_infos/initial/reward_run Max            0.363721
evaluation/env_infos/initial/reward_run Min           -0.199467
evaluation/env_infos/reward_run Mean                  -0.000150933
evaluation/env_infos/reward_run Std                    0.0147823
evaluation/env_infos/reward_run Max                    0.363721
evaluation/env_infos/reward_run Min                   -0.340951
evaluation/env_infos/final/reward_ctrl Mean           -0.00548897
evaluation/env_infos/final/reward_ctrl Std             0.00180283
evaluation/env_infos/final/reward_ctrl Max            -0.0025408
evaluation/env_infos/final/reward_ctrl Min            -0.00789672
evaluation/env_infos/initial/reward_ctrl Mean         -0.00592181
evaluation/env_infos/initial/reward_ctrl Std           0.0018866
evaluation/env_infos/initial/reward_ctrl Max          -0.0026943
evaluation/env_infos/initial/reward_ctrl Min          -0.00848925
evaluation/env_infos/reward_ctrl Mean                 -0.00549043
evaluation/env_infos/reward_ctrl Std                   0.0018027
evaluation/env_infos/reward_ctrl Max                  -0.00250418
evaluation/env_infos/reward_ctrl Min                  -0.0100448
evaluation/env_infos/final/height Mean                -0.125501
evaluation/env_infos/final/height Std                  0.000633597
evaluation/env_infos/final/height Max                 -0.124702
evaluation/env_infos/final/height Min                 -0.126672
evaluation/env_infos/initial/height Mean              -0.00855331
evaluation/env_infos/initial/height Std                0.0597939
evaluation/env_infos/initial/height Max                0.0799865
evaluation/env_infos/initial/height Min               -0.0902987
evaluation/env_infos/height Mean                      -0.125038
evaluation/env_infos/height Std                        0.00578381
evaluation/env_infos/height Max                        0.0799865
evaluation/env_infos/height Min                       -0.140439
evaluation/env_infos/final/reward_angular Mean        -3.86809e-09
evaluation/env_infos/final/reward_angular Std          1.31581e-08
evaluation/env_infos/final/reward_angular Max          3.70544e-15
evaluation/env_infos/final/reward_angular Min         -5.57129e-08
evaluation/env_infos/initial/reward_angular Mean       0.35878
evaluation/env_infos/initial/reward_angular Std        0.401155
evaluation/env_infos/initial/reward_angular Max        1.58207
evaluation/env_infos/initial/reward_angular Min       -0.307276
evaluation/env_infos/reward_angular Mean               0.00191158
evaluation/env_infos/reward_angular Std                0.0512515
evaluation/env_infos/reward_angular Max                2.0699
evaluation/env_infos/reward_angular Min               -0.588602
time/data storing (s)                                  0.0154471
time/evaluation sampling (s)                          24.1673
time/exploration sampling (s)                          1.08191
time/logging (s)                                       0.242812
time/saving (s)                                        0.027651
time/training (s)                                      3.75722
time/epoch (s)                                        29.2923
time/total (s)                                        83.8878
Epoch                                                  2
-------------------------------------------------  ---------------
2021-05-25 09:50:18.610592 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 3 finished
-------------------------------------------------  ----------------
replay_buffer/size                                   5000
trainer/QF1 Loss                                        0.671078
trainer/QF2 Loss                                        0.683196
trainer/Policy Loss                                    -6.95372
trainer/Q1 Predictions Mean                             2.96541
trainer/Q1 Predictions Std                              0.834434
trainer/Q1 Predictions Max                              5.76822
trainer/Q1 Predictions Min                              0.989266
trainer/Q2 Predictions Mean                             2.9246
trainer/Q2 Predictions Std                              0.777573
trainer/Q2 Predictions Max                              5.85219
trainer/Q2 Predictions Min                              1.18994
trainer/Q Targets Mean                                  3.10784
trainer/Q Targets Std                                   0.925289
trainer/Q Targets Max                                   5.99127
trainer/Q Targets Min                                  -0.813155
trainer/Log Pis Mean                                   -3.95394
trainer/Log Pis Std                                     0.688271
trainer/Log Pis Max                                    -1.76871
trainer/Log Pis Min                                    -5.86559
trainer/Policy mu Mean                                  0.0303971
trainer/Policy mu Std                                   0.226234
trainer/Policy mu Max                                   0.763774
trainer/Policy mu Min                                  -0.951897
trainer/Policy log std Mean                            -0.0959697
trainer/Policy log std Std                              0.0333657
trainer/Policy log std Max                              0.010913
trainer/Policy log std Min                             -0.208743
trainer/Alpha                                           0.405783
trainer/Alpha Loss                                     -8.94822
exploration/num steps total                          5000
exploration/num paths total                             5
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.0742532
exploration/Rewards Std                                 0.520053
exploration/Rewards Max                                 1.72666
exploration/Rewards Min                                -1.69894
exploration/Returns Mean                              -74.2532
exploration/Returns Std                                 0
exploration/Returns Max                               -74.2532
exploration/Returns Min                               -74.2532
exploration/Actions Mean                                0.0404318
exploration/Actions Std                                 0.602795
exploration/Actions Max                                 0.99962
exploration/Actions Min                                -0.997809
exploration/Num Paths                                   1
exploration/Average Returns                           -74.2532
exploration/env_infos/final/reward_run Mean            -0.401397
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.401397
exploration/env_infos/final/reward_run Min             -0.401397
exploration/env_infos/initial/reward_run Mean           0.118905
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.118905
exploration/env_infos/initial/reward_run Min            0.118905
exploration/env_infos/reward_run Mean                  -0.0342577
exploration/env_infos/reward_run Std                    0.672666
exploration/env_infos/reward_run Max                    2.0671
exploration/env_infos/reward_run Min                   -2.15234
exploration/env_infos/final/reward_ctrl Mean           -0.185427
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.185427
exploration/env_infos/final/reward_ctrl Min            -0.185427
exploration/env_infos/initial/reward_ctrl Mean         -0.197149
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.197149
exploration/env_infos/initial/reward_ctrl Min          -0.197149
exploration/env_infos/reward_ctrl Mean                 -0.218998
exploration/env_infos/reward_ctrl Std                   0.0703604
exploration/env_infos/reward_ctrl Max                  -0.0244489
exploration/env_infos/reward_ctrl Min                  -0.471586
exploration/env_infos/final/height Mean                -0.165566
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.165566
exploration/env_infos/final/height Min                 -0.165566
exploration/env_infos/initial/height Mean              -0.0265399
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0265399
exploration/env_infos/initial/height Min               -0.0265399
exploration/env_infos/height Mean                      -0.0727836
exploration/env_infos/height Std                        0.0910712
exploration/env_infos/height Max                        0.251457
exploration/env_infos/height Min                       -0.338026
exploration/env_infos/final/reward_angular Mean         0.29055
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          0.29055
exploration/env_infos/final/reward_angular Min          0.29055
exploration/env_infos/initial/reward_angular Mean      -0.347146
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.347146
exploration/env_infos/initial/reward_angular Min       -0.347146
exploration/env_infos/reward_angular Mean              -0.0109864
exploration/env_infos/reward_angular Std                1.72942
exploration/env_infos/reward_angular Max                5.16218
exploration/env_infos/reward_angular Min               -5.49761
evaluation/num steps total                         100000
evaluation/num paths total                            100
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0658545
evaluation/Rewards Std                                  0.0467575
evaluation/Rewards Max                                  1.234
evaluation/Rewards Min                                 -1.39027
evaluation/Returns Mean                               -65.8545
evaluation/Returns Std                                 33.4986
evaluation/Returns Max                                 -5.06069
evaluation/Returns Min                               -123.527
evaluation/Actions Mean                                 0.0393426
evaluation/Actions Std                                  0.196194
evaluation/Actions Max                                  0.455392
evaluation/Actions Min                                 -0.570075
evaluation/Num Paths                                   25
evaluation/Average Returns                            -65.8545
evaluation/env_infos/final/reward_run Mean              5.162e-09
evaluation/env_infos/final/reward_run Std               1.76333e-08
evaluation/env_infos/final/reward_run Max               7.80947e-08
evaluation/env_infos/final/reward_run Min              -1.75163e-08
evaluation/env_infos/initial/reward_run Mean            0.234971
evaluation/env_infos/initial/reward_run Std             0.139012
evaluation/env_infos/initial/reward_run Max             0.476572
evaluation/env_infos/initial/reward_run Min            -0.0167746
evaluation/env_infos/reward_run Mean                   -0.00038533
evaluation/env_infos/reward_run Std                     0.0232988
evaluation/env_infos/reward_run Max                     0.6351
evaluation/env_infos/reward_run Min                    -0.527434
evaluation/env_infos/final/reward_ctrl Mean            -0.0240146
evaluation/env_infos/final/reward_ctrl Std              0.00938351
evaluation/env_infos/final/reward_ctrl Max             -0.00917052
evaluation/env_infos/final/reward_ctrl Min             -0.0379687
evaluation/env_infos/initial/reward_ctrl Mean          -0.0333956
evaluation/env_infos/initial/reward_ctrl Std            0.0123787
evaluation/env_infos/initial/reward_ctrl Max           -0.0130577
evaluation/env_infos/initial/reward_ctrl Min           -0.0534111
evaluation/env_infos/reward_ctrl Mean                  -0.0240239
evaluation/env_infos/reward_ctrl Std                    0.00940907
evaluation/env_infos/reward_ctrl Max                   -0.00505427
evaluation/env_infos/reward_ctrl Min                   -0.0596606
evaluation/env_infos/final/height Mean                 -0.126515
evaluation/env_infos/final/height Std                   0.00882562
evaluation/env_infos/final/height Max                  -0.11605
evaluation/env_infos/final/height Min                  -0.140163
evaluation/env_infos/initial/height Mean               -0.0151513
evaluation/env_infos/initial/height Std                 0.0533498
evaluation/env_infos/initial/height Max                 0.0657445
evaluation/env_infos/initial/height Min                -0.0993215
evaluation/env_infos/height Mean                       -0.126078
evaluation/env_infos/height Std                         0.0102647
evaluation/env_infos/height Max                         0.0657445
evaluation/env_infos/height Min                        -0.164496
evaluation/env_infos/final/reward_angular Mean         -1.21999e-08
evaluation/env_infos/final/reward_angular Std           5.84149e-08
evaluation/env_infos/final/reward_angular Max           1.15282e-07
evaluation/env_infos/final/reward_angular Min          -1.78484e-07
evaluation/env_infos/initial/reward_angular Mean        0.0518434
evaluation/env_infos/initial/reward_angular Std         0.76838
evaluation/env_infos/initial/reward_angular Max         1.44269
evaluation/env_infos/initial/reward_angular Min        -1.0863
evaluation/env_infos/reward_angular Mean                0.000715139
evaluation/env_infos/reward_angular Std                 0.0572684
evaluation/env_infos/reward_angular Max                 2.91354
evaluation/env_infos/reward_angular Min                -1.34701
time/data storing (s)                                   0.0150814
time/evaluation sampling (s)                           22.6648
time/exploration sampling (s)                           1.04588
time/logging (s)                                        0.229053
time/saving (s)                                         0.0273323
time/training (s)                                       3.37297
time/epoch (s)                                         27.3551
time/total (s)                                        111.374
Epoch                                                   3
-------------------------------------------------  ----------------
2021-05-25 09:50:45.668453 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 4 finished
-------------------------------------------------  ----------------
replay_buffer/size                                   6000
trainer/QF1 Loss                                        0.385456
trainer/QF2 Loss                                        0.393143
trainer/Policy Loss                                    -6.78767
trainer/Q1 Predictions Mean                             2.88639
trainer/Q1 Predictions Std                              0.70475
trainer/Q1 Predictions Max                              5.6191
trainer/Q1 Predictions Min                              1.42525
trainer/Q2 Predictions Mean                             2.88131
trainer/Q2 Predictions Std                              0.690321
trainer/Q2 Predictions Max                              5.76134
trainer/Q2 Predictions Min                              1.45344
trainer/Q Targets Mean                                  2.9628
trainer/Q Targets Std                                   0.942532
trainer/Q Targets Max                                   6.05903
trainer/Q Targets Min                                  -0.123184
trainer/Log Pis Mean                                   -3.78932
trainer/Log Pis Std                                     0.874073
trainer/Log Pis Max                                    -0.352144
trainer/Log Pis Min                                    -7.11505
trainer/Policy mu Mean                                  0.0126846
trainer/Policy mu Std                                   0.247001
trainer/Policy mu Max                                   0.52275
trainer/Policy mu Min                                  -1.14558
trainer/Policy log std Mean                            -0.102518
trainer/Policy log std Std                              0.04226
trainer/Policy log std Max                             -0.0114533
trainer/Policy log std Min                             -0.362191
trainer/Alpha                                           0.302273
trainer/Alpha Loss                                    -11.6834
exploration/num steps total                          6000
exploration/num paths total                             6
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.212309
exploration/Rewards Std                                 0.765662
exploration/Rewards Max                                 2.07652
exploration/Rewards Min                                -2.41979
exploration/Returns Mean                             -212.309
exploration/Returns Std                                 0
exploration/Returns Max                              -212.309
exploration/Returns Min                              -212.309
exploration/Actions Mean                               -0.00817141
exploration/Actions Std                                 0.600258
exploration/Actions Max                                 0.996551
exploration/Actions Min                                -0.995967
exploration/Num Paths                                   1
exploration/Average Returns                          -212.309
exploration/env_infos/final/reward_run Mean             0.626427
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.626427
exploration/env_infos/final/reward_run Min              0.626427
exploration/env_infos/initial/reward_run Mean           0.622065
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.622065
exploration/env_infos/initial/reward_run Min            0.622065
exploration/env_infos/reward_run Mean                  -0.134635
exploration/env_infos/reward_run Std                    0.707544
exploration/env_infos/reward_run Max                    1.64965
exploration/env_infos/reward_run Min                   -2.49962
exploration/env_infos/final/reward_ctrl Mean           -0.277064
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.277064
exploration/env_infos/final/reward_ctrl Min            -0.277064
exploration/env_infos/initial/reward_ctrl Mean         -0.214479
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.214479
exploration/env_infos/initial/reward_ctrl Min          -0.214479
exploration/env_infos/reward_ctrl Mean                 -0.216226
exploration/env_infos/reward_ctrl Std                   0.0733853
exploration/env_infos/reward_ctrl Max                  -0.0278889
exploration/env_infos/reward_ctrl Min                  -0.511025
exploration/env_infos/final/height Mean                -0.267516
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.267516
exploration/env_infos/final/height Min                 -0.267516
exploration/env_infos/initial/height Mean              -0.0617833
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0617833
exploration/env_infos/initial/height Min               -0.0617833
exploration/env_infos/height Mean                      -0.0683273
exploration/env_infos/height Std                        0.0834166
exploration/env_infos/height Max                        0.246211
exploration/env_infos/height Min                       -0.353116
exploration/env_infos/final/reward_angular Mean         2.10756
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          2.10756
exploration/env_infos/final/reward_angular Min          2.10756
exploration/env_infos/initial/reward_angular Mean      -1.20711
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -1.20711
exploration/env_infos/initial/reward_angular Min       -1.20711
exploration/env_infos/reward_angular Mean              -0.0234251
exploration/env_infos/reward_angular Std                1.71937
exploration/env_infos/reward_angular Max                5.71013
exploration/env_infos/reward_angular Min               -4.73031
evaluation/num steps total                         125000
evaluation/num paths total                            125
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0716465
evaluation/Rewards Std                                  0.0518966
evaluation/Rewards Max                                  2.30964
evaluation/Rewards Min                                 -1.66962
evaluation/Returns Mean                               -71.6465
evaluation/Returns Std                                 34.1158
evaluation/Returns Max                                 -4.96637
evaluation/Returns Min                               -133.756
evaluation/Actions Mean                                 0.0475803
evaluation/Actions Std                                  0.228039
evaluation/Actions Max                                  0.411667
evaluation/Actions Min                                 -0.742044
evaluation/Num Paths                                   25
evaluation/Average Returns                            -71.6465
evaluation/env_infos/final/reward_run Mean              3.43173e-09
evaluation/env_infos/final/reward_run Std               3.03084e-08
evaluation/env_infos/final/reward_run Max               8.33724e-08
evaluation/env_infos/final/reward_run Min              -6.30587e-08
evaluation/env_infos/initial/reward_run Mean            0.198217
evaluation/env_infos/initial/reward_run Std             0.223948
evaluation/env_infos/initial/reward_run Max             0.531368
evaluation/env_infos/initial/reward_run Min            -0.329508
evaluation/env_infos/reward_run Mean                   -0.000224088
evaluation/env_infos/reward_run Std                     0.0206426
evaluation/env_infos/reward_run Max                     0.572663
evaluation/env_infos/reward_run Min                    -0.409088
evaluation/env_infos/final/reward_ctrl Mean            -0.0325614
evaluation/env_infos/final/reward_ctrl Std              0.0218491
evaluation/env_infos/final/reward_ctrl Max             -0.00370944
evaluation/env_infos/final/reward_ctrl Min             -0.0833273
evaluation/env_infos/initial/reward_ctrl Mean          -0.0467012
evaluation/env_infos/initial/reward_ctrl Std            0.0307645
evaluation/env_infos/initial/reward_ctrl Max           -0.00440451
evaluation/env_infos/initial/reward_ctrl Min           -0.117166
evaluation/env_infos/reward_ctrl Mean                  -0.0325593
evaluation/env_infos/reward_ctrl Std                    0.0218711
evaluation/env_infos/reward_ctrl Max                   -0.00164071
evaluation/env_infos/reward_ctrl Min                   -0.117166
evaluation/env_infos/final/height Mean                 -0.129629
evaluation/env_infos/final/height Std                   0.0100412
evaluation/env_infos/final/height Max                  -0.114863
evaluation/env_infos/final/height Min                  -0.140776
evaluation/env_infos/initial/height Mean               -0.0156769
evaluation/env_infos/initial/height Std                 0.0578368
evaluation/env_infos/initial/height Max                 0.0668278
evaluation/env_infos/initial/height Min                -0.0966411
evaluation/env_infos/height Mean                       -0.129227
evaluation/env_infos/height Std                         0.011357
evaluation/env_infos/height Max                         0.0668278
evaluation/env_infos/height Min                        -0.152595
evaluation/env_infos/final/reward_angular Mean          2.20033e-08
evaluation/env_infos/final/reward_angular Std           8.75571e-08
evaluation/env_infos/final/reward_angular Max           3.19621e-07
evaluation/env_infos/final/reward_angular Min          -1.28905e-07
evaluation/env_infos/initial/reward_angular Mean       -0.015457
evaluation/env_infos/initial/reward_angular Std         0.962761
evaluation/env_infos/initial/reward_angular Max         2.67569
evaluation/env_infos/initial/reward_angular Min        -1.36756
evaluation/env_infos/reward_angular Mean                0.00084353
evaluation/env_infos/reward_angular Std                 0.0589676
evaluation/env_infos/reward_angular Max                 2.67569
evaluation/env_infos/reward_angular Min                -1.36756
time/data storing (s)                                   0.0161052
time/evaluation sampling (s)                           22.0808
time/exploration sampling (s)                           1.08937
time/logging (s)                                        0.239257
time/saving (s)                                         0.0279876
time/training (s)                                       3.48359
time/epoch (s)                                         26.9371
time/total (s)                                        138.442
Epoch                                                   4
-------------------------------------------------  ----------------
2021-05-25 09:51:13.153040 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 5 finished
-------------------------------------------------  ----------------
replay_buffer/size                                   7000
trainer/QF1 Loss                                        0.425588
trainer/QF2 Loss                                        0.366466
trainer/Policy Loss                                    -6.97916
trainer/Q1 Predictions Mean                             3.34195
trainer/Q1 Predictions Std                              0.952477
trainer/Q1 Predictions Max                              8.0748
trainer/Q1 Predictions Min                              1.17839
trainer/Q2 Predictions Mean                             3.29428
trainer/Q2 Predictions Std                              0.948743
trainer/Q2 Predictions Max                              8.12023
trainer/Q2 Predictions Min                              1.25744
trainer/Q Targets Mean                                  3.23236
trainer/Q Targets Std                                   1.14129
trainer/Q Targets Max                                   7.78724
trainer/Q Targets Min                                   0.119522
trainer/Log Pis Mean                                   -3.48829
trainer/Log Pis Std                                     1.28913
trainer/Log Pis Max                                     0.243087
trainer/Log Pis Min                                   -10.9918
trainer/Policy mu Mean                                  0.111512
trainer/Policy mu Std                                   0.387748
trainer/Policy mu Max                                   1.20538
trainer/Policy mu Min                                  -1.2481
trainer/Policy log std Mean                            -0.146073
trainer/Policy log std Std                              0.0417686
trainer/Policy log std Max                             -0.00548135
trainer/Policy log std Min                             -0.364147
trainer/Alpha                                           0.226114
trainer/Alpha Loss                                    -14.0791
exploration/num steps total                          7000
exploration/num paths total                             7
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.136915
exploration/Rewards Std                                 0.956433
exploration/Rewards Max                                 3.25356
exploration/Rewards Min                                -3.41189
exploration/Returns Mean                             -136.915
exploration/Returns Std                                 0
exploration/Returns Max                              -136.915
exploration/Returns Min                              -136.915
exploration/Actions Mean                                0.147399
exploration/Actions Std                                 0.58611
exploration/Actions Max                                 0.997041
exploration/Actions Min                                -0.998226
exploration/Num Paths                                   1
exploration/Average Returns                          -136.915
exploration/env_infos/final/reward_run Mean             1.16227
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              1.16227
exploration/env_infos/final/reward_run Min              1.16227
exploration/env_infos/initial/reward_run Mean           0.293609
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.293609
exploration/env_infos/initial/reward_run Min            0.293609
exploration/env_infos/reward_run Mean                   0.00577176
exploration/env_infos/reward_run Std                    0.731139
exploration/env_infos/reward_run Max                    2.16127
exploration/env_infos/reward_run Min                   -2.24386
exploration/env_infos/final/reward_ctrl Mean           -0.33817
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.33817
exploration/env_infos/final/reward_ctrl Min            -0.33817
exploration/env_infos/initial/reward_ctrl Mean         -0.147861
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.147861
exploration/env_infos/initial/reward_ctrl Min          -0.147861
exploration/env_infos/reward_ctrl Mean                 -0.219151
exploration/env_infos/reward_ctrl Std                   0.0735075
exploration/env_infos/reward_ctrl Max                  -0.0518305
exploration/env_infos/reward_ctrl Min                  -0.476198
exploration/env_infos/final/height Mean                -0.165953
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.165953
exploration/env_infos/final/height Min                 -0.165953
exploration/env_infos/initial/height Mean              -0.0197044
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0197044
exploration/env_infos/initial/height Min               -0.0197044
exploration/env_infos/height Mean                      -0.0826236
exploration/env_infos/height Std                        0.0809437
exploration/env_infos/height Max                        0.17918
exploration/env_infos/height Min                       -0.346517
exploration/env_infos/final/reward_angular Mean        -1.47622
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -1.47622
exploration/env_infos/final/reward_angular Min         -1.47622
exploration/env_infos/initial/reward_angular Mean      -0.296345
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.296345
exploration/env_infos/initial/reward_angular Min       -0.296345
exploration/env_infos/reward_angular Mean              -0.0164014
exploration/env_infos/reward_angular Std                1.52555
exploration/env_infos/reward_angular Max                5.16363
exploration/env_infos/reward_angular Min               -5.02249
evaluation/num steps total                         150000
evaluation/num paths total                            150
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0785634
evaluation/Rewards Std                                  0.0521222
evaluation/Rewards Max                                  1.6638
evaluation/Rewards Min                                 -1.20457
evaluation/Returns Mean                               -78.5634
evaluation/Returns Std                                 35.2701
evaluation/Returns Max                                -13.6429
evaluation/Returns Min                               -141.101
evaluation/Actions Mean                                 0.0963684
evaluation/Actions Std                                  0.273855
evaluation/Actions Max                                  0.701958
evaluation/Actions Min                                 -0.765591
evaluation/Num Paths                                   25
evaluation/Average Returns                            -78.5634
evaluation/env_infos/final/reward_run Mean              4.35395e-09
evaluation/env_infos/final/reward_run Std               6.22217e-08
evaluation/env_infos/final/reward_run Max               1.12188e-07
evaluation/env_infos/final/reward_run Min              -1.74762e-07
evaluation/env_infos/initial/reward_run Mean            0.311209
evaluation/env_infos/initial/reward_run Std             0.227177
evaluation/env_infos/initial/reward_run Max             0.618921
evaluation/env_infos/initial/reward_run Min            -0.195249
evaluation/env_infos/reward_run Mean                   -0.00057548
evaluation/env_infos/reward_run Std                     0.02582
evaluation/env_infos/reward_run Max                     0.659968
evaluation/env_infos/reward_run Min                    -0.455153
evaluation/env_infos/final/reward_ctrl Mean            -0.050588
evaluation/env_infos/final/reward_ctrl Std              0.0219983
evaluation/env_infos/final/reward_ctrl Max             -0.00499841
evaluation/env_infos/final/reward_ctrl Min             -0.0941293
evaluation/env_infos/initial/reward_ctrl Mean          -0.0757243
evaluation/env_infos/initial/reward_ctrl Std            0.0295331
evaluation/env_infos/initial/reward_ctrl Max           -0.014396
evaluation/env_infos/initial/reward_ctrl Min           -0.129021
evaluation/env_infos/reward_ctrl Mean                  -0.0505702
evaluation/env_infos/reward_ctrl Std                    0.0220111
evaluation/env_infos/reward_ctrl Max                   -0.00233534
evaluation/env_infos/reward_ctrl Min                   -0.129021
evaluation/env_infos/final/height Mean                 -0.131378
evaluation/env_infos/final/height Std                   0.0146127
evaluation/env_infos/final/height Max                  -0.108712
evaluation/env_infos/final/height Min                  -0.151645
evaluation/env_infos/initial/height Mean                0.0171741
evaluation/env_infos/initial/height Std                 0.0461742
evaluation/env_infos/initial/height Max                 0.0855516
evaluation/env_infos/initial/height Min                -0.0746675
evaluation/env_infos/height Mean                       -0.130903
evaluation/env_infos/height Std                         0.0159609
evaluation/env_infos/height Max                         0.0855516
evaluation/env_infos/height Min                        -0.164193
evaluation/env_infos/final/reward_angular Mean          2.76793e-08
evaluation/env_infos/final/reward_angular Std           6.10374e-08
evaluation/env_infos/final/reward_angular Max           1.78293e-07
evaluation/env_infos/final/reward_angular Min          -9.69786e-08
evaluation/env_infos/initial/reward_angular Mean       -0.392281
evaluation/env_infos/initial/reward_angular Std         1.00346
evaluation/env_infos/initial/reward_angular Max         1.93882
evaluation/env_infos/initial/reward_angular Min        -1.51935
evaluation/env_infos/reward_angular Mean                0.000118965
evaluation/env_infos/reward_angular Std                 0.0556159
evaluation/env_infos/reward_angular Max                 2.02836
evaluation/env_infos/reward_angular Min                -1.57961
time/data storing (s)                                   0.013595
time/evaluation sampling (s)                           22.7306
time/exploration sampling (s)                           1.00052
time/logging (s)                                        0.241698
time/saving (s)                                         0.0270058
time/training (s)                                       3.32709
time/epoch (s)                                         27.3405
time/total (s)                                        165.928
Epoch                                                   5
-------------------------------------------------  ----------------
2021-05-25 09:51:41.383830 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 6 finished
-------------------------------------------------  ----------------
replay_buffer/size                                   8000
trainer/QF1 Loss                                        0.384308
trainer/QF2 Loss                                        0.44054
trainer/Policy Loss                                    -6.28119
trainer/Q1 Predictions Mean                             3.08096
trainer/Q1 Predictions Std                              0.895825
trainer/Q1 Predictions Max                              6.51077
trainer/Q1 Predictions Min                              0.826849
trainer/Q2 Predictions Mean                             3.16361
trainer/Q2 Predictions Std                              0.894146
trainer/Q2 Predictions Max                              6.5591
trainer/Q2 Predictions Min                              0.894752
trainer/Q Targets Mean                                  3.12619
trainer/Q Targets Std                                   1.08507
trainer/Q Targets Max                                   7.40082
trainer/Q Targets Min                                   0.060482
trainer/Log Pis Mean                                   -2.92459
trainer/Log Pis Std                                     1.40241
trainer/Log Pis Max                                     1.94657
trainer/Log Pis Min                                    -6.03568
trainer/Policy mu Mean                                  0.208444
trainer/Policy mu Std                                   0.452851
trainer/Policy mu Max                                   1.5342
trainer/Policy mu Min                                  -1.39052
trainer/Policy log std Mean                            -0.168483
trainer/Policy log std Std                              0.0606908
trainer/Policy log std Max                             -0.0724508
trainer/Policy log std Min                             -0.41085
trainer/Alpha                                           0.170119
trainer/Alpha Loss                                    -15.7828
exploration/num steps total                          8000
exploration/num paths total                             8
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.140781
exploration/Rewards Std                                 0.800922
exploration/Rewards Max                                 2.49723
exploration/Rewards Min                                -2.78159
exploration/Returns Mean                             -140.781
exploration/Returns Std                                 0
exploration/Returns Max                              -140.781
exploration/Returns Min                              -140.781
exploration/Actions Mean                                0.234729
exploration/Actions Std                                 0.579265
exploration/Actions Max                                 0.998671
exploration/Actions Min                                -0.989921
exploration/Num Paths                                   1
exploration/Average Returns                          -140.781
exploration/env_infos/final/reward_run Mean             0.157749
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.157749
exploration/env_infos/final/reward_run Min              0.157749
exploration/env_infos/initial/reward_run Mean           0.645462
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.645462
exploration/env_infos/initial/reward_run Min            0.645462
exploration/env_infos/reward_run Mean                   0.152278
exploration/env_infos/reward_run Std                    0.485185
exploration/env_infos/reward_run Max                    1.65423
exploration/env_infos/reward_run Min                   -1.34171
exploration/env_infos/final/reward_ctrl Mean           -0.306337
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.306337
exploration/env_infos/final/reward_ctrl Min            -0.306337
exploration/env_infos/initial/reward_ctrl Mean         -0.156038
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.156038
exploration/env_infos/initial/reward_ctrl Min          -0.156038
exploration/env_infos/reward_ctrl Mean                 -0.234387
exploration/env_infos/reward_ctrl Std                   0.0749873
exploration/env_infos/reward_ctrl Max                  -0.0106042
exploration/env_infos/reward_ctrl Min                  -0.448316
exploration/env_infos/final/height Mean                -0.149828
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.149828
exploration/env_infos/final/height Min                 -0.149828
exploration/env_infos/initial/height Mean              -0.105467
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.105467
exploration/env_infos/initial/height Min               -0.105467
exploration/env_infos/height Mean                      -0.121769
exploration/env_infos/height Std                        0.103772
exploration/env_infos/height Max                        0.218792
exploration/env_infos/height Min                       -0.416627
exploration/env_infos/final/reward_angular Mean        -4.61706
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -4.61706
exploration/env_infos/final/reward_angular Min         -4.61706
exploration/env_infos/initial/reward_angular Mean      -0.360852
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.360852
exploration/env_infos/initial/reward_angular Min       -0.360852
exploration/env_infos/reward_angular Mean              -0.00777145
exploration/env_infos/reward_angular Std                1.41691
exploration/env_infos/reward_angular Max                4.59079
exploration/env_infos/reward_angular Min               -4.73751
evaluation/num steps total                         175000
evaluation/num paths total                            175
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0998709
evaluation/Rewards Std                                  0.0686956
evaluation/Rewards Max                                  2.85088
evaluation/Rewards Min                                 -1.15315
evaluation/Returns Mean                               -99.8709
evaluation/Returns Std                                 43.5106
evaluation/Returns Max                                 -2.14124
evaluation/Returns Min                               -170.002
evaluation/Actions Mean                                 0.15689
evaluation/Actions Std                                  0.352173
evaluation/Actions Max                                  0.77863
evaluation/Actions Min                                 -0.81797
evaluation/Num Paths                                   25
evaluation/Average Returns                            -99.8709
evaluation/env_infos/final/reward_run Mean              1.93242e-09
evaluation/env_infos/final/reward_run Std               4.07842e-08
evaluation/env_infos/final/reward_run Max               1.44553e-07
evaluation/env_infos/final/reward_run Min              -5.82962e-08
evaluation/env_infos/initial/reward_run Mean            0.294372
evaluation/env_infos/initial/reward_run Std             0.334344
evaluation/env_infos/initial/reward_run Max             0.895529
evaluation/env_infos/initial/reward_run Min            -0.272448
evaluation/env_infos/reward_run Mean                    0.000357042
evaluation/env_infos/reward_run Std                     0.0312879
evaluation/env_infos/reward_run Max                     0.957355
evaluation/env_infos/reward_run Min                    -0.376556
evaluation/env_infos/final/reward_ctrl Mean            -0.0892194
evaluation/env_infos/final/reward_ctrl Std              0.0413485
evaluation/env_infos/final/reward_ctrl Max             -0.0181612
evaluation/env_infos/final/reward_ctrl Min             -0.166534
evaluation/env_infos/initial/reward_ctrl Mean          -0.113863
evaluation/env_infos/initial/reward_ctrl Std            0.0405462
evaluation/env_infos/initial/reward_ctrl Max           -0.0377743
evaluation/env_infos/initial/reward_ctrl Min           -0.180468
evaluation/env_infos/reward_ctrl Mean                  -0.0891843
evaluation/env_infos/reward_ctrl Std                    0.041216
evaluation/env_infos/reward_ctrl Max                   -0.014599
evaluation/env_infos/reward_ctrl Min                   -0.180468
evaluation/env_infos/final/height Mean                 -0.151478
evaluation/env_infos/final/height Std                   0.0260577
evaluation/env_infos/final/height Max                  -0.121093
evaluation/env_infos/final/height Min                  -0.246016
evaluation/env_infos/initial/height Mean               -0.0244623
evaluation/env_infos/initial/height Std                 0.0519585
evaluation/env_infos/initial/height Max                 0.0886208
evaluation/env_infos/initial/height Min                -0.0960234
evaluation/env_infos/height Mean                       -0.15126
evaluation/env_infos/height Std                         0.027149
evaluation/env_infos/height Max                         0.0886208
evaluation/env_infos/height Min                        -0.344186
evaluation/env_infos/final/reward_angular Mean          2.8933e-08
evaluation/env_infos/final/reward_angular Std           1.33006e-07
evaluation/env_infos/final/reward_angular Max           4.7775e-07
evaluation/env_infos/final/reward_angular Min          -2.7491e-07
evaluation/env_infos/initial/reward_angular Mean       -0.339141
evaluation/env_infos/initial/reward_angular Std         1.46041
evaluation/env_infos/initial/reward_angular Max         3.2826
evaluation/env_infos/initial/reward_angular Min        -2.02517
evaluation/env_infos/reward_angular Mean                0.000426462
evaluation/env_infos/reward_angular Std                 0.0783024
evaluation/env_infos/reward_angular Max                 3.2826
evaluation/env_infos/reward_angular Min                -2.02517
time/data storing (s)                                   0.0156753
time/evaluation sampling (s)                           22.9998
time/exploration sampling (s)                           1.18635
time/logging (s)                                        0.231132
time/saving (s)                                         0.0268259
time/training (s)                                       3.61279
time/epoch (s)                                         28.0726
time/total (s)                                        194.147
Epoch                                                   6
-------------------------------------------------  ----------------
2021-05-25 09:52:09.664865 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 7 finished
-------------------------------------------------  ----------------
replay_buffer/size                                   9000
trainer/QF1 Loss                                        0.407611
trainer/QF2 Loss                                        0.418717
trainer/Policy Loss                                    -5.83929
trainer/Q1 Predictions Mean                             3.23096
trainer/Q1 Predictions Std                              1.13229
trainer/Q1 Predictions Max                              8.2838
trainer/Q1 Predictions Min                              0.522407
trainer/Q2 Predictions Mean                             3.30985
trainer/Q2 Predictions Std                              1.10244
trainer/Q2 Predictions Max                              8.50654
trainer/Q2 Predictions Min                              0.563415
trainer/Q Targets Mean                                  3.14263
trainer/Q Targets Std                                   1.28166
trainer/Q Targets Max                                   8.7538
trainer/Q Targets Min                                  -0.468826
trainer/Log Pis Mean                                   -2.33388
trainer/Log Pis Std                                     2.011
trainer/Log Pis Max                                     3.7216
trainer/Log Pis Min                                    -7.42093
trainer/Policy mu Mean                                  0.321693
trainer/Policy mu Std                                   0.56787
trainer/Policy mu Max                                   2.01068
trainer/Policy mu Min                                  -1.06828
trainer/Policy log std Mean                            -0.209325
trainer/Policy log std Std                              0.100151
trainer/Policy log std Max                             -0.0489673
trainer/Policy log std Min                             -0.677832
trainer/Alpha                                           0.12877
trainer/Alpha Loss                                    -17.0596
exploration/num steps total                          9000
exploration/num paths total                             9
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.409177
exploration/Rewards Std                                 0.310862
exploration/Rewards Max                                 0.694999
exploration/Rewards Min                                -1.35182
exploration/Returns Mean                             -409.177
exploration/Returns Std                                 0
exploration/Returns Max                              -409.177
exploration/Returns Min                              -409.177
exploration/Actions Mean                                0.0142657
exploration/Actions Std                                 0.608727
exploration/Actions Max                                 0.998878
exploration/Actions Min                                -0.997658
exploration/Num Paths                                   1
exploration/Average Returns                          -409.177
exploration/env_infos/final/reward_run Mean             0.327817
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.327817
exploration/env_infos/final/reward_run Min              0.327817
exploration/env_infos/initial/reward_run Mean           0.329271
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.329271
exploration/env_infos/initial/reward_run Min            0.329271
exploration/env_infos/reward_run Mean                   0.00438123
exploration/env_infos/reward_run Std                    0.489793
exploration/env_infos/reward_run Max                    1.56566
exploration/env_infos/reward_run Min                   -1.59582
exploration/env_infos/final/reward_ctrl Mean           -0.385016
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.385016
exploration/env_infos/final/reward_ctrl Min            -0.385016
exploration/env_infos/initial/reward_ctrl Mean         -0.357853
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.357853
exploration/env_infos/initial/reward_ctrl Min          -0.357853
exploration/env_infos/reward_ctrl Mean                 -0.222452
exploration/env_infos/reward_ctrl Std                   0.0739904
exploration/env_infos/reward_ctrl Max                  -0.0454727
exploration/env_infos/reward_ctrl Min                  -0.488717
exploration/env_infos/final/height Mean                -0.571093
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.571093
exploration/env_infos/final/height Min                 -0.571093
exploration/env_infos/initial/height Mean               0.0722804
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max                0.0722804
exploration/env_infos/initial/height Min                0.0722804
exploration/env_infos/height Mean                      -0.49924
exploration/env_infos/height Std                        0.154184
exploration/env_infos/height Max                        0.116541
exploration/env_infos/height Min                       -0.592427
exploration/env_infos/final/reward_angular Mean         1.52798
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          1.52798
exploration/env_infos/final/reward_angular Min          1.52798
exploration/env_infos/initial/reward_angular Mean      -1.96915
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -1.96915
exploration/env_infos/initial/reward_angular Min       -1.96915
exploration/env_infos/reward_angular Mean               0.0630643
exploration/env_infos/reward_angular Std                0.994211
exploration/env_infos/reward_angular Max                3.84599
exploration/env_infos/reward_angular Min               -3.73946
evaluation/num steps total                         200000
evaluation/num paths total                            200
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.122875
evaluation/Rewards Std                                  0.0945728
evaluation/Rewards Max                                  2.74563
evaluation/Rewards Min                                 -0.85955
evaluation/Returns Mean                              -122.875
evaluation/Returns Std                                 55.8418
evaluation/Returns Max                                -31.0055
evaluation/Returns Min                               -233.879
evaluation/Actions Mean                                 0.209302
evaluation/Actions Std                                  0.437009
evaluation/Actions Max                                  0.92478
evaluation/Actions Min                                 -0.779145
evaluation/Num Paths                                   25
evaluation/Average Returns                           -122.875
evaluation/env_infos/final/reward_run Mean             -9.14622e-07
evaluation/env_infos/final/reward_run Std               4.45991e-06
evaluation/env_infos/final/reward_run Max               1.70157e-07
evaluation/env_infos/final/reward_run Min              -2.27614e-05
evaluation/env_infos/initial/reward_run Mean            0.148545
evaluation/env_infos/initial/reward_run Std             0.34276
evaluation/env_infos/initial/reward_run Max             0.734132
evaluation/env_infos/initial/reward_run Min            -0.385645
evaluation/env_infos/reward_run Mean                    0.00127644
evaluation/env_infos/reward_run Std                     0.0539425
evaluation/env_infos/reward_run Max                     0.943595
evaluation/env_infos/reward_run Min                    -0.808941
evaluation/env_infos/final/reward_ctrl Mean            -0.140736
evaluation/env_infos/final/reward_ctrl Std              0.0772377
evaluation/env_infos/final/reward_ctrl Max             -0.0107062
evaluation/env_infos/final/reward_ctrl Min             -0.281053
evaluation/env_infos/initial/reward_ctrl Mean          -0.155164
evaluation/env_infos/initial/reward_ctrl Std            0.0581823
evaluation/env_infos/initial/reward_ctrl Max           -0.0473397
evaluation/env_infos/initial/reward_ctrl Min           -0.25841
evaluation/env_infos/reward_ctrl Mean                  -0.140871
evaluation/env_infos/reward_ctrl Std                    0.0771353
evaluation/env_infos/reward_ctrl Max                   -0.0104654
evaluation/env_infos/reward_ctrl Min                   -0.296905
evaluation/env_infos/final/height Mean                 -0.171127
evaluation/env_infos/final/height Std                   0.0520856
evaluation/env_infos/final/height Max                  -0.0848976
evaluation/env_infos/final/height Min                  -0.383097
evaluation/env_infos/initial/height Mean               -0.00615813
evaluation/env_infos/initial/height Std                 0.0458331
evaluation/env_infos/initial/height Max                 0.0784195
evaluation/env_infos/initial/height Min                -0.0765005
evaluation/env_infos/height Mean                       -0.170808
evaluation/env_infos/height Std                         0.0536565
evaluation/env_infos/height Max                         0.0792107
evaluation/env_infos/height Min                        -0.435124
evaluation/env_infos/final/reward_angular Mean         -1.7424e-06
evaluation/env_infos/final/reward_angular Std           8.79181e-06
evaluation/env_infos/final/reward_angular Max           6.61359e-07
evaluation/env_infos/final/reward_angular Min          -4.48071e-05
evaluation/env_infos/initial/reward_angular Mean       -0.698735
evaluation/env_infos/initial/reward_angular Std         1.36561
evaluation/env_infos/initial/reward_angular Max         2.59532
evaluation/env_infos/initial/reward_angular Min        -2.9459
evaluation/env_infos/reward_angular Mean                0.00139992
evaluation/env_infos/reward_angular Std                 0.147251
evaluation/env_infos/reward_angular Max                 2.92476
evaluation/env_infos/reward_angular Min                -2.9459
time/data storing (s)                                   0.0157095
time/evaluation sampling (s)                           22.4353
time/exploration sampling (s)                           1.09504
time/logging (s)                                        0.239408
time/saving (s)                                         0.0333826
time/training (s)                                       4.31688
time/epoch (s)                                         28.1357
time/total (s)                                        222.436
Epoch                                                   7
-------------------------------------------------  ----------------
2021-05-25 09:52:37.902823 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 8 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  10000
trainer/QF1 Loss                                        0.335557
trainer/QF2 Loss                                        0.378134
trainer/Policy Loss                                    -6.06696
trainer/Q1 Predictions Mean                             3.00234
trainer/Q1 Predictions Std                              1.02699
trainer/Q1 Predictions Max                              6.98008
trainer/Q1 Predictions Min                              0.467989
trainer/Q2 Predictions Mean                             2.84171
trainer/Q2 Predictions Std                              0.993679
trainer/Q2 Predictions Max                              6.43974
trainer/Q2 Predictions Min                              0.452873
trainer/Q Targets Mean                                  3.02682
trainer/Q Targets Std                                   1.17703
trainer/Q Targets Max                                   7.85685
trainer/Q Targets Min                                  -0.423063
trainer/Log Pis Mean                                   -3.03589
trainer/Log Pis Std                                     1.6082
trainer/Log Pis Max                                     2.14173
trainer/Log Pis Min                                    -6.63515
trainer/Policy mu Mean                                  0.0824587
trainer/Policy mu Std                                   0.53343
trainer/Policy mu Max                                   1.59956
trainer/Policy mu Min                                  -1.85533
trainer/Policy log std Mean                            -0.183573
trainer/Policy log std Std                              0.0738382
trainer/Policy log std Max                              0.044068
trainer/Policy log std Min                             -0.510759
trainer/Alpha                                           0.09784
trainer/Alpha Loss                                    -20.9785
exploration/num steps total                         10000
exploration/num paths total                            10
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.250325
exploration/Rewards Std                                 0.538092
exploration/Rewards Max                                 1.92164
exploration/Rewards Min                                -2.21202
exploration/Returns Mean                             -250.325
exploration/Returns Std                                 0
exploration/Returns Max                              -250.325
exploration/Returns Min                              -250.325
exploration/Actions Mean                               -0.156206
exploration/Actions Std                                 0.589309
exploration/Actions Max                                 0.997395
exploration/Actions Min                                -0.995907
exploration/Num Paths                                   1
exploration/Average Returns                          -250.325
exploration/env_infos/final/reward_run Mean            -0.553659
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.553659
exploration/env_infos/final/reward_run Min             -0.553659
exploration/env_infos/initial/reward_run Mean           0.885651
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.885651
exploration/env_infos/initial/reward_run Min            0.885651
exploration/env_infos/reward_run Mean                   0.0177774
exploration/env_infos/reward_run Std                    0.55675
exploration/env_infos/reward_run Max                    1.83863
exploration/env_infos/reward_run Min                   -1.57393
exploration/env_infos/final/reward_ctrl Mean           -0.150166
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.150166
exploration/env_infos/final/reward_ctrl Min            -0.150166
exploration/env_infos/initial/reward_ctrl Mean         -0.364045
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.364045
exploration/env_infos/initial/reward_ctrl Min          -0.364045
exploration/env_infos/reward_ctrl Mean                 -0.223011
exploration/env_infos/reward_ctrl Std                   0.0744909
exploration/env_infos/reward_ctrl Max                  -0.0385627
exploration/env_infos/reward_ctrl Min                  -0.498261
exploration/env_infos/final/height Mean                -0.558192
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.558192
exploration/env_infos/final/height Min                 -0.558192
exploration/env_infos/initial/height Mean               0.0133971
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max                0.0133971
exploration/env_infos/initial/height Min                0.0133971
exploration/env_infos/height Mean                      -0.448793
exploration/env_infos/height Std                        0.217394
exploration/env_infos/height Max                        0.268403
exploration/env_infos/height Min                       -0.582994
exploration/env_infos/final/reward_angular Mean         0.88556
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          0.88556
exploration/env_infos/final/reward_angular Min          0.88556
exploration/env_infos/initial/reward_angular Mean      -0.562495
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.562495
exploration/env_infos/initial/reward_angular Min       -0.562495
exploration/env_infos/reward_angular Mean               0.0610207
exploration/env_infos/reward_angular Std                1.24464
exploration/env_infos/reward_angular Max                5.20797
exploration/env_infos/reward_angular Min               -4.24906
evaluation/num steps total                         225000
evaluation/num paths total                            225
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.130318
evaluation/Rewards Std                                  0.0765158
evaluation/Rewards Max                                  1.97604
evaluation/Rewards Min                                 -1.0214
evaluation/Returns Mean                              -130.318
evaluation/Returns Std                                 51.7849
evaluation/Returns Max                                -16.253
evaluation/Returns Min                               -205.182
evaluation/Actions Mean                                 0.124633
evaluation/Actions Std                                  0.472903
evaluation/Actions Max                                  0.919875
evaluation/Actions Min                                 -0.872154
evaluation/Num Paths                                   25
evaluation/Average Returns                           -130.318
evaluation/env_infos/final/reward_run Mean              3.65881e-09
evaluation/env_infos/final/reward_run Std               4.10973e-08
evaluation/env_infos/final/reward_run Max               1.10372e-07
evaluation/env_infos/final/reward_run Min              -8.44168e-08
evaluation/env_infos/initial/reward_run Mean            0.0281034
evaluation/env_infos/initial/reward_run Std             0.401316
evaluation/env_infos/initial/reward_run Max             0.833645
evaluation/env_infos/initial/reward_run Min            -0.610449
evaluation/env_infos/reward_run Mean                    0.000594007
evaluation/env_infos/reward_run Std                     0.0340662
evaluation/env_infos/reward_run Max                     1.18496
evaluation/env_infos/reward_run Min                    -0.673622
evaluation/env_infos/final/reward_ctrl Mean            -0.143568
evaluation/env_infos/final/reward_ctrl Std              0.0540181
evaluation/env_infos/final/reward_ctrl Max             -0.0639057
evaluation/env_infos/final/reward_ctrl Min             -0.260611
evaluation/env_infos/initial/reward_ctrl Mean          -0.145303
evaluation/env_infos/initial/reward_ctrl Std            0.0471588
evaluation/env_infos/initial/reward_ctrl Max           -0.0553918
evaluation/env_infos/initial/reward_ctrl Min           -0.222468
evaluation/env_infos/reward_ctrl Mean                  -0.143502
evaluation/env_infos/reward_ctrl Std                    0.0541066
evaluation/env_infos/reward_ctrl Max                   -0.0269642
evaluation/env_infos/reward_ctrl Min                   -0.266783
evaluation/env_infos/final/height Mean                 -0.174924
evaluation/env_infos/final/height Std                   0.0410278
evaluation/env_infos/final/height Max                  -0.114312
evaluation/env_infos/final/height Min                  -0.295429
evaluation/env_infos/initial/height Mean               -0.0180978
evaluation/env_infos/initial/height Std                 0.0511822
evaluation/env_infos/initial/height Max                 0.0740085
evaluation/env_infos/initial/height Min                -0.0928938
evaluation/env_infos/height Mean                       -0.174622
evaluation/env_infos/height Std                         0.0418956
evaluation/env_infos/height Max                         0.0740085
evaluation/env_infos/height Min                        -0.42318
evaluation/env_infos/final/reward_angular Mean         -6.21871e-09
evaluation/env_infos/final/reward_angular Std           7.47019e-08
evaluation/env_infos/final/reward_angular Max           2.01767e-07
evaluation/env_infos/final/reward_angular Min          -2.35602e-07
evaluation/env_infos/initial/reward_angular Mean       -0.27251
evaluation/env_infos/initial/reward_angular Std         1.21458
evaluation/env_infos/initial/reward_angular Max         2.15187
evaluation/env_infos/initial/reward_angular Min        -2.37682
evaluation/env_infos/reward_angular Mean                0.00114874
evaluation/env_infos/reward_angular Std                 0.0910334
evaluation/env_infos/reward_angular Max                 2.39663
evaluation/env_infos/reward_angular Min                -2.37682
time/data storing (s)                                   0.0148615
time/evaluation sampling (s)                           22.7025
time/exploration sampling (s)                           1.05699
time/logging (s)                                        0.231833
time/saving (s)                                         0.0259941
time/training (s)                                       4.03878
time/epoch (s)                                         28.0709
time/total (s)                                        250.665
Epoch                                                   8
-------------------------------------------------  ----------------
2021-05-25 09:53:05.788974 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_48_29_0000--s-10] Epoch 9 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  11000
trainer/QF1 Loss                                        0.418886
trainer/QF2 Loss                                        0.489847
trainer/Policy Loss                                    -5.20177
trainer/Q1 Predictions Mean                             2.8631
trainer/Q1 Predictions Std                              1.31603
trainer/Q1 Predictions Max                             12.1345
trainer/Q1 Predictions Min                              0.482715
trainer/Q2 Predictions Mean                             2.89767
trainer/Q2 Predictions Std                              1.26039
trainer/Q2 Predictions Max                             11.64
trainer/Q2 Predictions Min                              0.71042
trainer/Q Targets Mean                                  2.92802
trainer/Q Targets Std                                   1.48082
trainer/Q Targets Max                                  12.6618
trainer/Q Targets Min                                  -1.14523
trainer/Log Pis Mean                                   -2.1144
trainer/Log Pis Std                                     2.07853
trainer/Log Pis Max                                     3.78041
trainer/Log Pis Min                                    -7.17368
trainer/Policy mu Mean                                  0.159658
trainer/Policy mu Std                                   0.633432
trainer/Policy mu Max                                   2.66242
trainer/Policy mu Min                                  -1.93672
trainer/Policy log std Mean                            -0.235249
trainer/Policy log std Std                              0.098399
trainer/Policy log std Max                             -0.0402486
trainer/Policy log std Min                             -0.572462
trainer/Alpha                                           0.0745987
trainer/Alpha Loss                                    -21.0403
exploration/num steps total                         11000
exploration/num paths total                            11
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.219752
exploration/Rewards Std                                 0.436294
exploration/Rewards Max                                 1.65647
exploration/Rewards Min                                -1.95596
exploration/Returns Mean                             -219.752
exploration/Returns Std                                 0
exploration/Returns Max                              -219.752
exploration/Returns Min                              -219.752
exploration/Actions Mean                               -0.257596
exploration/Actions Std                                 0.577627
exploration/Actions Max                                 0.995799
exploration/Actions Min                                -0.997455
exploration/Num Paths                                   1
exploration/Average Returns                          -219.752
exploration/env_infos/final/reward_run Mean            -0.196676
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.196676
exploration/env_infos/final/reward_run Min             -0.196676
exploration/env_infos/initial/reward_run Mean          -0.00521741
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max           -0.00521741
exploration/env_infos/initial/reward_run Min           -0.00521741
exploration/env_infos/reward_run Mean                   0.0277202
exploration/env_infos/reward_run Std                    0.567311
exploration/env_infos/reward_run Max                    2.32785
exploration/env_infos/reward_run Min                   -1.69049
exploration/env_infos/final/reward_ctrl Mean           -0.227073
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.227073
exploration/env_infos/final/reward_ctrl Min            -0.227073
exploration/env_infos/initial/reward_ctrl Mean         -0.188533
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.188533
exploration/env_infos/initial/reward_ctrl Min          -0.188533
exploration/env_infos/reward_ctrl Mean                 -0.240005
exploration/env_infos/reward_ctrl Std                   0.0724019
exploration/env_infos/reward_ctrl Max                  -0.0339268
exploration/env_infos/reward_ctrl Min                  -0.487459
exploration/env_infos/final/height Mean                -0.549259
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.549259
exploration/env_infos/final/height Min                 -0.549259
exploration/env_infos/initial/height Mean              -0.0926412
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0926412
exploration/env_infos/initial/height Min               -0.0926412
exploration/env_infos/height Mean                      -0.423416
exploration/env_infos/height Std                        0.236293
exploration/env_infos/height Max                        0.327014
exploration/env_infos/height Min                       -0.582928
exploration/env_infos/final/reward_angular Mean        -1.62211
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -1.62211
exploration/env_infos/final/reward_angular Min         -1.62211
exploration/env_infos/initial/reward_angular Mean      -0.816247
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.816247
exploration/env_infos/initial/reward_angular Min       -0.816247
exploration/env_infos/reward_angular Mean               0.0637283
exploration/env_infos/reward_angular Std                1.22026
exploration/env_infos/reward_angular Max                6.19961
exploration/env_infos/reward_angular Min               -5.12252
evaluation/num steps total                         250000
evaluation/num paths total                            250
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.162014
evaluation/Rewards Std                                  0.12149
evaluation/Rewards Max                                  2.66842
evaluation/Rewards Min                                 -0.79439
evaluation/Returns Mean                              -162.014
evaluation/Returns Std                                 91.6884
evaluation/Returns Max                                -31.9516
evaluation/Returns Min                               -412.79
evaluation/Actions Mean                                 0.0998169
evaluation/Actions Std                                  0.52294
evaluation/Actions Max                                  0.981638
evaluation/Actions Min                                 -0.893939
evaluation/Num Paths                                   25
evaluation/Average Returns                           -162.014
evaluation/env_infos/final/reward_run Mean             -9.88978e-09
evaluation/env_infos/final/reward_run Std               2.66393e-08
evaluation/env_infos/final/reward_run Max               1.80812e-08
evaluation/env_infos/final/reward_run Min              -1.16754e-07
evaluation/env_infos/initial/reward_run Mean            0.0330491
evaluation/env_infos/initial/reward_run Std             0.47449
evaluation/env_infos/initial/reward_run Max             0.789888
evaluation/env_infos/initial/reward_run Min            -0.757174
evaluation/env_infos/reward_run Mean                    0.00221882
evaluation/env_infos/reward_run Std                     0.0480824
evaluation/env_infos/reward_run Max                     0.911886
evaluation/env_infos/reward_run Min                    -0.974309
evaluation/env_infos/final/reward_ctrl Mean            -0.170048
evaluation/env_infos/final/reward_ctrl Std              0.0686745
evaluation/env_infos/final/reward_ctrl Max             -0.0561197
evaluation/env_infos/final/reward_ctrl Min             -0.311249
evaluation/env_infos/initial/reward_ctrl Mean          -0.168228
evaluation/env_infos/initial/reward_ctrl Std            0.0558438
evaluation/env_infos/initial/reward_ctrl Max           -0.0568607
evaluation/env_infos/initial/reward_ctrl Min           -0.270398
evaluation/env_infos/reward_ctrl Mean                  -0.170058
evaluation/env_infos/reward_ctrl Std                    0.0688879
evaluation/env_infos/reward_ctrl Max                   -0.00658634
evaluation/env_infos/reward_ctrl Min                   -0.328225
evaluation/env_infos/final/height Mean                 -0.21846
evaluation/env_infos/final/height Std                   0.117136
evaluation/env_infos/final/height Max                  -0.125714
evaluation/env_infos/final/height Min                  -0.57728
evaluation/env_infos/initial/height Mean               -0.0206918
evaluation/env_infos/initial/height Std                 0.0558884
evaluation/env_infos/initial/height Max                 0.0775088
evaluation/env_infos/initial/height Min                -0.0971916
evaluation/env_infos/height Mean                       -0.216026
evaluation/env_infos/height Std                         0.115658
evaluation/env_infos/height Max                         0.203694
evaluation/env_infos/height Min                        -0.577281
evaluation/env_infos/final/reward_angular Mean         -1.79322e-08
evaluation/env_infos/final/reward_angular Std           8.13701e-08
evaluation/env_infos/final/reward_angular Max           8.86631e-08
evaluation/env_infos/final/reward_angular Min          -3.37619e-07
evaluation/env_infos/initial/reward_angular Mean       -0.429139
evaluation/env_infos/initial/reward_angular Std         1.3853
evaluation/env_infos/initial/reward_angular Max         2.04396
evaluation/env_infos/initial/reward_angular Min        -2.9611
evaluation/env_infos/reward_angular Mean                0.00581947
evaluation/env_infos/reward_angular Std                 0.145912
evaluation/env_infos/reward_angular Max                 4.20658
evaluation/env_infos/reward_angular Min                -2.9611
time/data storing (s)                                   0.0148977
time/evaluation sampling (s)                           22.5408
time/exploration sampling (s)                           1.05203
time/logging (s)                                        0.23694
time/saving (s)                                         0.0527276
time/training (s)                                       3.82316
time/epoch (s)                                         27.7205
time/total (s)                                        278.556
Epoch                                                   9
-------------------------------------------------  ----------------
