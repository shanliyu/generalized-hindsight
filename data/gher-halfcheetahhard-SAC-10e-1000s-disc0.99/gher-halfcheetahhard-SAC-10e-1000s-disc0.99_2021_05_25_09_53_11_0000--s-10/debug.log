2021-05-25 09:53:40.593437 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 0 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  4000
trainer/QF1 Loss                                      15.3269
trainer/QF2 Loss                                      15.238
trainer/Policy Loss                                   -4.03366
trainer/Q1 Predictions Mean                           -0.00783563
trainer/Q1 Predictions Std                             0.0058065
trainer/Q1 Predictions Max                             0.00421082
trainer/Q1 Predictions Min                            -0.0316749
trainer/Q2 Predictions Mean                            0.00402962
trainer/Q2 Predictions Std                             0.00446795
trainer/Q2 Predictions Max                             0.0150868
trainer/Q2 Predictions Min                            -0.00713501
trainer/Q Targets Mean                                 3.71426
trainer/Q Targets Std                                  1.21357
trainer/Q Targets Max                                  7.32799
trainer/Q Targets Min                                  0.547262
trainer/Log Pis Mean                                  -4.04152
trainer/Log Pis Std                                    0.506937
trainer/Log Pis Max                                   -2.35869
trainer/Log Pis Min                                   -5.48474
trainer/Policy mu Mean                                -0.000865881
trainer/Policy mu Std                                  0.00238213
trainer/Policy mu Max                                  0.00771935
trainer/Policy mu Min                                 -0.00766312
trainer/Policy log std Mean                           -0.00131967
trainer/Policy log std Std                             0.00164469
trainer/Policy log std Max                             0.0035715
trainer/Policy log std Min                            -0.00800097
trainer/Alpha                                          0.997005
trainer/Alpha Loss                                    -0
exploration/num steps total                         2000
exploration/num paths total                            2
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.0272778
exploration/Rewards Std                                1.57289
exploration/Rewards Max                                5.23244
exploration/Rewards Min                               -4.92095
exploration/Returns Mean                             -27.2778
exploration/Returns Std                                0
exploration/Returns Max                              -27.2778
exploration/Returns Min                              -27.2778
exploration/Actions Mean                               0.00116263
exploration/Actions Std                                0.627096
exploration/Actions Max                                0.999106
exploration/Actions Min                               -0.999803
exploration/Num Paths                                  1
exploration/Average Returns                          -27.2778
exploration/env_infos/final/reward_run Mean            1.25983
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max             1.25983
exploration/env_infos/final/reward_run Min             1.25983
exploration/env_infos/initial/reward_run Mean         -0.12297
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max          -0.12297
exploration/env_infos/initial/reward_run Min          -0.12297
exploration/env_infos/reward_run Mean                  0.054153
exploration/env_infos/reward_run Std                   0.642465
exploration/env_infos/reward_run Max                   3.08463
exploration/env_infos/reward_run Min                  -1.66697
exploration/env_infos/final/reward_ctrl Mean          -0.11265
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.11265
exploration/env_infos/final/reward_ctrl Min           -0.11265
exploration/env_infos/initial/reward_ctrl Mean        -0.144553
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.144553
exploration/env_infos/initial/reward_ctrl Min         -0.144553
exploration/env_infos/reward_ctrl Mean                -0.23595
exploration/env_infos/reward_ctrl Std                  0.0750464
exploration/env_infos/reward_ctrl Max                 -0.0181959
exploration/env_infos/reward_ctrl Min                 -0.475779
exploration/env_infos/final/height Mean               -0.53631
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                -0.53631
exploration/env_infos/final/height Min                -0.53631
exploration/env_infos/initial/height Mean             -0.0590837
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max              -0.0590837
exploration/env_infos/initial/height Min              -0.0590837
exploration/env_infos/height Mean                     -0.0654237
exploration/env_infos/height Std                       0.100538
exploration/env_infos/height Max                       0.216356
exploration/env_infos/height Min                      -0.549681
exploration/env_infos/final/reward_angular Mean        0.930011
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max         0.930011
exploration/env_infos/final/reward_angular Min         0.930011
exploration/env_infos/initial/reward_angular Mean      0.00791141
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max       0.00791141
exploration/env_infos/initial/reward_angular Min       0.00791141
exploration/env_infos/reward_angular Mean              0.0484033
exploration/env_infos/reward_angular Std               1.64769
exploration/env_infos/reward_angular Max               5.71955
exploration/env_infos/reward_angular Min              -5.0347
evaluation/num steps total                         25000
evaluation/num paths total                            25
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.0614858
evaluation/Rewards Std                                 0.0499058
evaluation/Rewards Max                                 1.26813
evaluation/Rewards Min                                -1.51007
evaluation/Returns Mean                              -61.4858
evaluation/Returns Std                                38.0789
evaluation/Returns Max                                -0.892261
evaluation/Returns Min                              -127.423
evaluation/Actions Mean                               -0.000323142
evaluation/Actions Std                                 0.00121869
evaluation/Actions Max                                 0.00422043
evaluation/Actions Min                                -0.00371634
evaluation/Num Paths                                  25
evaluation/Average Returns                           -61.4858
evaluation/env_infos/final/reward_run Mean             1.11022e-17
evaluation/env_infos/final/reward_run Std              2.63078e-16
evaluation/env_infos/final/reward_run Max              8.32667e-16
evaluation/env_infos/final/reward_run Min             -6.93889e-16
evaluation/env_infos/initial/reward_run Mean           0.00372491
evaluation/env_infos/initial/reward_run Std            0.131693
evaluation/env_infos/initial/reward_run Max            0.29157
evaluation/env_infos/initial/reward_run Min           -0.289685
evaluation/env_infos/reward_run Mean                   7.65262e-05
evaluation/env_infos/reward_run Std                    0.0157641
evaluation/env_infos/reward_run Max                    0.502553
evaluation/env_infos/reward_run Min                   -0.377546
evaluation/env_infos/final/reward_ctrl Mean           -9.52177e-07
evaluation/env_infos/final/reward_ctrl Std             9.0322e-08
evaluation/env_infos/final/reward_ctrl Max            -8.07404e-07
evaluation/env_infos/final/reward_ctrl Min            -1.10654e-06
evaluation/env_infos/initial/reward_ctrl Mean         -1.00922e-06
evaluation/env_infos/initial/reward_ctrl Std           9.1095e-08
evaluation/env_infos/initial/reward_ctrl Max          -8.72219e-07
evaluation/env_infos/initial/reward_ctrl Min          -1.16497e-06
evaluation/env_infos/reward_ctrl Mean                 -9.53778e-07
evaluation/env_infos/reward_ctrl Std                   1.02105e-07
evaluation/env_infos/reward_ctrl Max                  -5.583e-07
evaluation/env_infos/reward_ctrl Min                  -4.30826e-06
evaluation/env_infos/final/height Mean                -0.132891
evaluation/env_infos/final/height Std                  3.5865e-05
evaluation/env_infos/final/height Max                 -0.132829
evaluation/env_infos/final/height Min                 -0.132952
evaluation/env_infos/initial/height Mean              -0.00354426
evaluation/env_infos/initial/height Std                0.0473749
evaluation/env_infos/initial/height Max                0.0927329
evaluation/env_infos/initial/height Min               -0.0890003
evaluation/env_infos/height Mean                      -0.132402
evaluation/env_infos/height Std                        0.00598139
evaluation/env_infos/height Max                        0.0927329
evaluation/env_infos/height Min                       -0.149142
evaluation/env_infos/final/reward_angular Mean        -4.21006e-16
evaluation/env_infos/final/reward_angular Std          1.81736e-15
evaluation/env_infos/final/reward_angular Max          2.8216e-15
evaluation/env_infos/final/reward_angular Min         -4.18099e-15
evaluation/env_infos/initial/reward_angular Mean      -0.00717915
evaluation/env_infos/initial/reward_angular Std        0.188434
evaluation/env_infos/initial/reward_angular Max        0.426623
evaluation/env_infos/initial/reward_angular Min       -0.351699
evaluation/env_infos/reward_angular Mean               0.00151609
evaluation/env_infos/reward_angular Std                0.0500711
evaluation/env_infos/reward_angular Max                2.09357
evaluation/env_infos/reward_angular Min               -1.20257
time/data storing (s)                                  0.0289912
time/evaluation sampling (s)                          22.9433
time/exploration sampling (s)                          1.04285
time/logging (s)                                       0.238943
time/saving (s)                                        0.0691732
time/training (s)                                      3.37603
time/epoch (s)                                        27.6993
time/total (s)                                        32.1776
Epoch                                                  0
-------------------------------------------------  ---------------
2021-05-25 09:54:08.403952 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 1 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  6000
trainer/QF1 Loss                                       1.16347
trainer/QF2 Loss                                       1.15692
trainer/Policy Loss                                   -7.23342
trainer/Q1 Predictions Mean                            3.23425
trainer/Q1 Predictions Std                             0.806728
trainer/Q1 Predictions Max                             5.29649
trainer/Q1 Predictions Min                             1.42611
trainer/Q2 Predictions Mean                            3.23838
trainer/Q2 Predictions Std                             0.803661
trainer/Q2 Predictions Max                             5.32151
trainer/Q2 Predictions Min                             1.51808
trainer/Q Targets Mean                                 3.29322
trainer/Q Targets Std                                  1.2165
trainer/Q Targets Max                                  7.68043
trainer/Q Targets Min                                  0.322782
trainer/Log Pis Mean                                  -3.95007
trainer/Log Pis Std                                    0.652274
trainer/Log Pis Max                                   -2.00268
trainer/Log Pis Min                                   -6.93935
trainer/Policy mu Mean                                -0.153469
trainer/Policy mu Std                                  0.151768
trainer/Policy mu Max                                  0.0141714
trainer/Policy mu Min                                 -0.662057
trainer/Policy log std Mean                           -0.140578
trainer/Policy log std Std                             0.0306625
trainer/Policy log std Max                            -0.0819739
trainer/Policy log std Min                            -0.269909
trainer/Alpha                                          0.739143
trainer/Alpha Loss                                    -2.97784
exploration/num steps total                         3000
exploration/num paths total                            3
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.114296
exploration/Rewards Std                                0.776365
exploration/Rewards Max                                2.77903
exploration/Rewards Min                               -2.53234
exploration/Returns Mean                            -114.296
exploration/Returns Std                                0
exploration/Returns Max                             -114.296
exploration/Returns Min                             -114.296
exploration/Actions Mean                              -0.0961741
exploration/Actions Std                                0.591422
exploration/Actions Max                                0.994114
exploration/Actions Min                               -0.998861
exploration/Num Paths                                  1
exploration/Average Returns                         -114.296
exploration/env_infos/final/reward_run Mean           -0.927734
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max            -0.927734
exploration/env_infos/final/reward_run Min            -0.927734
exploration/env_infos/initial/reward_run Mean         -0.457034
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max          -0.457034
exploration/env_infos/initial/reward_run Min          -0.457034
exploration/env_infos/reward_run Mean                 -0.105857
exploration/env_infos/reward_run Std                   0.688417
exploration/env_infos/reward_run Max                   1.85912
exploration/env_infos/reward_run Min                  -2.21723
exploration/env_infos/final/reward_ctrl Mean          -0.204407
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.204407
exploration/env_infos/final/reward_ctrl Min           -0.204407
exploration/env_infos/initial/reward_ctrl Mean        -0.230009
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.230009
exploration/env_infos/initial/reward_ctrl Min         -0.230009
exploration/env_infos/reward_ctrl Mean                -0.215418
exploration/env_infos/reward_ctrl Std                  0.0714035
exploration/env_infos/reward_ctrl Max                 -0.0276139
exploration/env_infos/reward_ctrl Min                 -0.490209
exploration/env_infos/final/height Mean               -0.12623
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                -0.12623
exploration/env_infos/final/height Min                -0.12623
exploration/env_infos/initial/height Mean              0.0778134
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max               0.0778134
exploration/env_infos/initial/height Min               0.0778134
exploration/env_infos/height Mean                     -0.0820361
exploration/env_infos/height Std                       0.0686552
exploration/env_infos/height Max                       0.172241
exploration/env_infos/height Min                      -0.293578
exploration/env_infos/final/reward_angular Mean       -0.54264
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max        -0.54264
exploration/env_infos/final/reward_angular Min        -0.54264
exploration/env_infos/initial/reward_angular Mean      1.16658
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max       1.16658
exploration/env_infos/initial/reward_angular Min       1.16658
exploration/env_infos/reward_angular Mean             -0.00660536
exploration/env_infos/reward_angular Std               1.60173
exploration/env_infos/reward_angular Max               4.99544
exploration/env_infos/reward_angular Min              -5.59104
evaluation/num steps total                         50000
evaluation/num paths total                            50
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.0624549
evaluation/Rewards Std                                 0.0484406
evaluation/Rewards Max                                 1.18757
evaluation/Rewards Min                                -1.446
evaluation/Returns Mean                              -62.4549
evaluation/Returns Std                                35.3486
evaluation/Returns Max                                -4.33156
evaluation/Returns Min                              -119.335
evaluation/Actions Mean                               -0.109367
evaluation/Actions Std                                 0.106566
evaluation/Actions Max                                -0.00297282
evaluation/Actions Min                                -0.366371
evaluation/Num Paths                                  25
evaluation/Average Returns                           -62.4549
evaluation/env_infos/final/reward_run Mean            -5.85971e-10
evaluation/env_infos/final/reward_run Std              5.28556e-09
evaluation/env_infos/final/reward_run Max              8.04439e-09
evaluation/env_infos/final/reward_run Min             -2.52177e-08
evaluation/env_infos/initial/reward_run Mean          -0.0312346
evaluation/env_infos/initial/reward_run Std            0.116242
evaluation/env_infos/initial/reward_run Max            0.238434
evaluation/env_infos/initial/reward_run Min           -0.292928
evaluation/env_infos/reward_run Mean                   9.5306e-06
evaluation/env_infos/reward_run Std                    0.0164155
evaluation/env_infos/reward_run Max                    0.289341
evaluation/env_infos/reward_run Min                   -0.39162
evaluation/env_infos/final/reward_ctrl Mean           -0.0139847
evaluation/env_infos/final/reward_ctrl Std             0.00275023
evaluation/env_infos/final/reward_ctrl Max            -0.00846987
evaluation/env_infos/final/reward_ctrl Min            -0.0174207
evaluation/env_infos/initial/reward_ctrl Mean         -0.0147147
evaluation/env_infos/initial/reward_ctrl Std           0.00275806
evaluation/env_infos/initial/reward_ctrl Max          -0.00906524
evaluation/env_infos/initial/reward_ctrl Min          -0.0183114
evaluation/env_infos/reward_ctrl Mean                 -0.0139904
evaluation/env_infos/reward_ctrl Std                   0.00275101
evaluation/env_infos/reward_ctrl Max                  -0.0081657
evaluation/env_infos/reward_ctrl Min                  -0.0191002
evaluation/env_infos/final/height Mean                -0.123601
evaluation/env_infos/final/height Std                  0.000370321
evaluation/env_infos/final/height Max                 -0.123217
evaluation/env_infos/final/height Min                 -0.124481
evaluation/env_infos/initial/height Mean              -0.0173698
evaluation/env_infos/initial/height Std                0.0509982
evaluation/env_infos/initial/height Max                0.0774869
evaluation/env_infos/initial/height Min               -0.0915047
evaluation/env_infos/height Mean                      -0.123241
evaluation/env_infos/height Std                        0.00501719
evaluation/env_infos/height Max                        0.0774869
evaluation/env_infos/height Min                       -0.139368
evaluation/env_infos/final/reward_angular Mean        -2.99798e-09
evaluation/env_infos/final/reward_angular Std          1.43409e-08
evaluation/env_infos/final/reward_angular Max          3.30282e-15
evaluation/env_infos/final/reward_angular Min         -7.3238e-08
evaluation/env_infos/initial/reward_angular Mean       0.6265
evaluation/env_infos/initial/reward_angular Std        0.353308
evaluation/env_infos/initial/reward_angular Max        1.57092
evaluation/env_infos/initial/reward_angular Min        0.117176
evaluation/env_infos/reward_angular Mean               0.00247391
evaluation/env_infos/reward_angular Std                0.0567482
evaluation/env_infos/reward_angular Max                1.71319
evaluation/env_infos/reward_angular Min               -0.656419
time/data storing (s)                                  0.0285556
time/evaluation sampling (s)                          22.7944
time/exploration sampling (s)                          1.07017
time/logging (s)                                       0.232886
time/saving (s)                                        0.0314507
time/training (s)                                      3.40978
time/epoch (s)                                        27.5672
time/total (s)                                        59.9815
Epoch                                                  1
-------------------------------------------------  ---------------
2021-05-25 09:54:35.540695 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 2 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  8000
trainer/QF1 Loss                                       0.861604
trainer/QF2 Loss                                       0.88927
trainer/Policy Loss                                   -6.98633
trainer/Q1 Predictions Mean                            3.04814
trainer/Q1 Predictions Std                             0.729165
trainer/Q1 Predictions Max                             5.90395
trainer/Q1 Predictions Min                             1.59853
trainer/Q2 Predictions Mean                            3.05442
trainer/Q2 Predictions Std                             0.656126
trainer/Q2 Predictions Max                             5.5941
trainer/Q2 Predictions Min                             1.71106
trainer/Q Targets Mean                                 3.17953
trainer/Q Targets Std                                  1.03354
trainer/Q Targets Max                                  6.16944
trainer/Q Targets Min                                  0.161548
trainer/Log Pis Mean                                  -3.96173
trainer/Log Pis Std                                    0.573706
trainer/Log Pis Max                                   -2.43289
trainer/Log Pis Min                                   -5.64855
trainer/Policy mu Mean                                -0.0958589
trainer/Policy mu Std                                  0.141019
trainer/Policy mu Max                                  0.137192
trainer/Policy mu Min                                 -0.56499
trainer/Policy log std Mean                           -0.11578
trainer/Policy log std Std                             0.0240278
trainer/Policy log std Max                            -0.0627972
trainer/Policy log std Min                            -0.224525
trainer/Alpha                                          0.548046
trainer/Alpha Loss                                    -5.96111
exploration/num steps total                         4000
exploration/num paths total                            4
exploration/path length Mean                        1000
exploration/path length Std                            0
exploration/path length Max                         1000
exploration/path length Min                         1000
exploration/Rewards Mean                              -0.0745154
exploration/Rewards Std                                0.739179
exploration/Rewards Max                                2.14627
exploration/Rewards Min                               -2.53215
exploration/Returns Mean                             -74.5154
exploration/Returns Std                                0
exploration/Returns Max                              -74.5154
exploration/Returns Min                              -74.5154
exploration/Actions Mean                              -0.0729242
exploration/Actions Std                                0.597195
exploration/Actions Max                                0.997958
exploration/Actions Min                               -0.997576
exploration/Num Paths                                  1
exploration/Average Returns                          -74.5154
exploration/env_infos/final/reward_run Mean            0.341971
exploration/env_infos/final/reward_run Std             0
exploration/env_infos/final/reward_run Max             0.341971
exploration/env_infos/final/reward_run Min             0.341971
exploration/env_infos/initial/reward_run Mean         -0.232355
exploration/env_infos/initial/reward_run Std           0
exploration/env_infos/initial/reward_run Max          -0.232355
exploration/env_infos/initial/reward_run Min          -0.232355
exploration/env_infos/reward_run Mean                 -0.104553
exploration/env_infos/reward_run Std                   0.682127
exploration/env_infos/reward_run Max                   2.0714
exploration/env_infos/reward_run Min                  -2.25643
exploration/env_infos/final/reward_ctrl Mean          -0.160351
exploration/env_infos/final/reward_ctrl Std            0
exploration/env_infos/final/reward_ctrl Max           -0.160351
exploration/env_infos/final/reward_ctrl Min           -0.160351
exploration/env_infos/initial/reward_ctrl Mean        -0.206376
exploration/env_infos/initial/reward_ctrl Std          0
exploration/env_infos/initial/reward_ctrl Max         -0.206376
exploration/env_infos/initial/reward_ctrl Min         -0.206376
exploration/env_infos/reward_ctrl Mean                -0.217176
exploration/env_infos/reward_ctrl Std                  0.0746391
exploration/env_infos/reward_ctrl Max                 -0.0294259
exploration/env_infos/reward_ctrl Min                 -0.448791
exploration/env_infos/final/height Mean               -0.00437659
exploration/env_infos/final/height Std                 0
exploration/env_infos/final/height Max                -0.00437659
exploration/env_infos/final/height Min                -0.00437659
exploration/env_infos/initial/height Mean             -0.0426057
exploration/env_infos/initial/height Std               0
exploration/env_infos/initial/height Max              -0.0426057
exploration/env_infos/initial/height Min              -0.0426057
exploration/env_infos/height Mean                     -0.0720375
exploration/env_infos/height Std                       0.0747466
exploration/env_infos/height Max                       0.255081
exploration/env_infos/height Min                      -0.269326
exploration/env_infos/final/reward_angular Mean       -0.231004
exploration/env_infos/final/reward_angular Std         0
exploration/env_infos/final/reward_angular Max        -0.231004
exploration/env_infos/final/reward_angular Min        -0.231004
exploration/env_infos/initial/reward_angular Mean      1.6158
exploration/env_infos/initial/reward_angular Std       0
exploration/env_infos/initial/reward_angular Max       1.6158
exploration/env_infos/initial/reward_angular Min       1.6158
exploration/env_infos/reward_angular Mean             -0.0136256
exploration/env_infos/reward_angular Std               1.61417
exploration/env_infos/reward_angular Max               5.03863
exploration/env_infos/reward_angular Min              -5.26493
evaluation/num steps total                         75000
evaluation/num paths total                            75
evaluation/path length Mean                         1000
evaluation/path length Std                             0
evaluation/path length Max                          1000
evaluation/path length Min                          1000
evaluation/Rewards Mean                               -0.0607008
evaluation/Rewards Std                                 0.0446304
evaluation/Rewards Max                                 1.04812
evaluation/Rewards Min                                -1.51211
evaluation/Returns Mean                              -60.7008
evaluation/Returns Std                                33.4753
evaluation/Returns Max                                -4.37191
evaluation/Returns Min                              -113.727
evaluation/Actions Mean                               -0.0931746
evaluation/Actions Std                                 0.131008
evaluation/Actions Max                                 0.0718513
evaluation/Actions Min                                -0.409571
evaluation/Num Paths                                  25
evaluation/Average Returns                           -60.7008
evaluation/env_infos/final/reward_run Mean             3.69524e-10
evaluation/env_infos/final/reward_run Std              5.70111e-09
evaluation/env_infos/final/reward_run Max              2.55106e-08
evaluation/env_infos/final/reward_run Min             -1.15782e-08
evaluation/env_infos/initial/reward_run Mean          -0.014498
evaluation/env_infos/initial/reward_run Std            0.116589
evaluation/env_infos/initial/reward_run Max            0.280736
evaluation/env_infos/initial/reward_run Min           -0.203485
evaluation/env_infos/reward_run Mean                  -0.00022858
evaluation/env_infos/reward_run Std                    0.0162064
evaluation/env_infos/reward_run Max                    0.371422
evaluation/env_infos/reward_run Min                   -0.398471
evaluation/env_infos/final/reward_ctrl Mean           -0.0155091
evaluation/env_infos/final/reward_ctrl Std             0.00533514
evaluation/env_infos/final/reward_ctrl Max            -0.00638621
evaluation/env_infos/final/reward_ctrl Min            -0.0226088
evaluation/env_infos/initial/reward_ctrl Mean         -0.0164106
evaluation/env_infos/initial/reward_ctrl Std           0.00542148
evaluation/env_infos/initial/reward_ctrl Max          -0.00666233
evaluation/env_infos/initial/reward_ctrl Min          -0.024384
evaluation/env_infos/reward_ctrl Mean                 -0.0155067
evaluation/env_infos/reward_ctrl Std                   0.00533372
evaluation/env_infos/reward_ctrl Max                  -0.0060797
evaluation/env_infos/reward_ctrl Min                  -0.0244445
evaluation/env_infos/final/height Mean                -0.117982
evaluation/env_infos/final/height Std                  0.0017881
evaluation/env_infos/final/height Max                 -0.11579
evaluation/env_infos/final/height Min                 -0.121401
evaluation/env_infos/initial/height Mean              -0.00129931
evaluation/env_infos/initial/height Std                0.0522147
evaluation/env_infos/initial/height Max                0.0930226
evaluation/env_infos/initial/height Min               -0.0908245
evaluation/env_infos/height Mean                      -0.117578
evaluation/env_infos/height Std                        0.00567728
evaluation/env_infos/height Max                        0.0930226
evaluation/env_infos/height Min                       -0.131078
evaluation/env_infos/final/reward_angular Mean         7.16573e-10
evaluation/env_infos/final/reward_angular Std          1.0781e-08
evaluation/env_infos/final/reward_angular Max          5.0348e-08
evaluation/env_infos/final/reward_angular Min         -1.40239e-08
evaluation/env_infos/initial/reward_angular Mean       0.522728
evaluation/env_infos/initial/reward_angular Std        0.372674
evaluation/env_infos/initial/reward_angular Max        1.80095
evaluation/env_infos/initial/reward_angular Min       -0.0158663
evaluation/env_infos/reward_angular Mean               0.00192798
evaluation/env_infos/reward_angular Std                0.0483175
evaluation/env_infos/reward_angular Max                1.80095
evaluation/env_infos/reward_angular Min               -0.572452
time/data storing (s)                                  0.0284062
time/evaluation sampling (s)                          22.3817
time/exploration sampling (s)                          1.04732
time/logging (s)                                       0.231601
time/saving (s)                                        0.0262327
time/training (s)                                      3.30298
time/epoch (s)                                        27.0182
time/total (s)                                        87.116
Epoch                                                  2
-------------------------------------------------  ---------------
2021-05-25 09:55:03.208782 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 3 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  10000
trainer/QF1 Loss                                        0.615121
trainer/QF2 Loss                                        0.623474
trainer/Policy Loss                                    -6.87211
trainer/Q1 Predictions Mean                             3.00974
trainer/Q1 Predictions Std                              0.834614
trainer/Q1 Predictions Max                              6.88281
trainer/Q1 Predictions Min                              1.18805
trainer/Q2 Predictions Mean                             2.96175
trainer/Q2 Predictions Std                              0.834242
trainer/Q2 Predictions Max                              6.96127
trainer/Q2 Predictions Min                              1.35025
trainer/Q Targets Mean                                  3.00746
trainer/Q Targets Std                                   1.11642
trainer/Q Targets Max                                   7.02875
trainer/Q Targets Min                                  -0.461315
trainer/Log Pis Mean                                   -3.64744
trainer/Log Pis Std                                     0.972519
trainer/Log Pis Max                                     0.832376
trainer/Log Pis Min                                    -6.10651
trainer/Policy mu Mean                                 -0.044373
trainer/Policy mu Std                                   0.325867
trainer/Policy mu Max                                   1.1117
trainer/Policy mu Min                                  -1.35822
trainer/Policy log std Mean                            -0.115537
trainer/Policy log std Std                              0.0480933
trainer/Policy log std Max                             -0.014284
trainer/Policy log std Min                             -0.308851
trainer/Alpha                                           0.407646
trainer/Alpha Loss                                     -8.62896
exploration/num steps total                          5000
exploration/num paths total                             5
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.320196
exploration/Rewards Std                                 0.450421
exploration/Rewards Max                                 1.57539
exploration/Rewards Min                                -2.01526
exploration/Returns Mean                             -320.196
exploration/Returns Std                                 0
exploration/Returns Max                              -320.196
exploration/Returns Min                              -320.196
exploration/Actions Mean                                0.047021
exploration/Actions Std                                 0.596677
exploration/Actions Max                                 0.999177
exploration/Actions Min                                -0.998142
exploration/Num Paths                                   1
exploration/Average Returns                          -320.196
exploration/env_infos/final/reward_run Mean             0.0116421
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.0116421
exploration/env_infos/final/reward_run Min              0.0116421
exploration/env_infos/initial/reward_run Mean           0.140128
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.140128
exploration/env_infos/initial/reward_run Min            0.140128
exploration/env_infos/reward_run Mean                  -0.0780987
exploration/env_infos/reward_run Std                    0.603118
exploration/env_infos/reward_run Max                    1.62113
exploration/env_infos/reward_run Min                   -2.20067
exploration/env_infos/final/reward_ctrl Mean           -0.110965
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.110965
exploration/env_infos/final/reward_ctrl Min            -0.110965
exploration/env_infos/initial/reward_ctrl Mean         -0.235929
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.235929
exploration/env_infos/initial/reward_ctrl Min          -0.235929
exploration/env_infos/reward_ctrl Mean                 -0.214941
exploration/env_infos/reward_ctrl Std                   0.0703415
exploration/env_infos/reward_ctrl Max                  -0.0300627
exploration/env_infos/reward_ctrl Min                  -0.463561
exploration/env_infos/final/height Mean                -0.541282
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.541282
exploration/env_infos/final/height Min                 -0.541282
exploration/env_infos/initial/height Mean              -0.0304385
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0304385
exploration/env_infos/initial/height Min               -0.0304385
exploration/env_infos/height Mean                      -0.396819
exploration/env_infos/height Std                        0.221558
exploration/env_infos/height Max                        0.244717
exploration/env_infos/height Min                       -0.58281
exploration/env_infos/final/reward_angular Mean        -0.533958
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -0.533958
exploration/env_infos/final/reward_angular Min         -0.533958
exploration/env_infos/initial/reward_angular Mean      -0.805993
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.805993
exploration/env_infos/initial/reward_angular Min       -0.805993
exploration/env_infos/reward_angular Mean               0.0494973
exploration/env_infos/reward_angular Std                1.45244
exploration/env_infos/reward_angular Max                5.82874
exploration/env_infos/reward_angular Min               -5.08299
evaluation/num steps total                         100000
evaluation/num paths total                            100
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0721732
evaluation/Rewards Std                                  0.0549156
evaluation/Rewards Max                                  2.23029
evaluation/Rewards Min                                 -1.15315
evaluation/Returns Mean                               -72.1732
evaluation/Returns Std                                 33.5406
evaluation/Returns Max                                 -2.80451
evaluation/Returns Min                               -132.27
evaluation/Actions Mean                                -0.00564848
evaluation/Actions Std                                  0.216188
evaluation/Actions Max                                  0.624586
evaluation/Actions Min                                 -0.698241
evaluation/Num Paths                                   25
evaluation/Average Returns                            -72.1732
evaluation/env_infos/final/reward_run Mean              2.37877e-09
evaluation/env_infos/final/reward_run Std               2.29825e-08
evaluation/env_infos/final/reward_run Max               6.37078e-08
evaluation/env_infos/final/reward_run Min              -6.44703e-08
evaluation/env_infos/initial/reward_run Mean            0.0201256
evaluation/env_infos/initial/reward_run Std             0.236632
evaluation/env_infos/initial/reward_run Max             0.413834
evaluation/env_infos/initial/reward_run Min            -0.446391
evaluation/env_infos/reward_run Mean                   -0.000602864
evaluation/env_infos/reward_run Std                     0.0220782
evaluation/env_infos/reward_run Max                     0.613636
evaluation/env_infos/reward_run Min                    -0.571742
evaluation/env_infos/final/reward_ctrl Mean            -0.0280348
evaluation/env_infos/final/reward_ctrl Std              0.0234701
evaluation/env_infos/final/reward_ctrl Max             -0.00116065
evaluation/env_infos/final/reward_ctrl Min             -0.0745849
evaluation/env_infos/initial/reward_ctrl Mean          -0.0470233
evaluation/env_infos/initial/reward_ctrl Std            0.0340578
evaluation/env_infos/initial/reward_ctrl Max           -0.000954478
evaluation/env_infos/initial/reward_ctrl Min           -0.112539
evaluation/env_infos/reward_ctrl Mean                  -0.0280614
evaluation/env_infos/reward_ctrl Std                    0.0234818
evaluation/env_infos/reward_ctrl Max                   -0.000350416
evaluation/env_infos/reward_ctrl Min                   -0.112539
evaluation/env_infos/final/height Mean                 -0.136275
evaluation/env_infos/final/height Std                   0.00494495
evaluation/env_infos/final/height Max                  -0.129729
evaluation/env_infos/final/height Min                  -0.143688
evaluation/env_infos/initial/height Mean               -0.0124556
evaluation/env_infos/initial/height Std                 0.0643072
evaluation/env_infos/initial/height Max                 0.0855688
evaluation/env_infos/initial/height Min                -0.108862
evaluation/env_infos/height Mean                       -0.135874
evaluation/env_infos/height Std                         0.00779947
evaluation/env_infos/height Max                         0.0855688
evaluation/env_infos/height Min                        -0.167234
evaluation/env_infos/final/reward_angular Mean         -8.38415e-09
evaluation/env_infos/final/reward_angular Std           1.41549e-07
evaluation/env_infos/final/reward_angular Max           2.92214e-07
evaluation/env_infos/final/reward_angular Min          -4.17491e-07
evaluation/env_infos/initial/reward_angular Mean        0.32081
evaluation/env_infos/initial/reward_angular Std         0.990875
evaluation/env_infos/initial/reward_angular Max         3.00527
evaluation/env_infos/initial/reward_angular Min        -1.32222
evaluation/env_infos/reward_angular Mean                0.000990563
evaluation/env_infos/reward_angular Std                 0.0797978
evaluation/env_infos/reward_angular Max                 3.00527
evaluation/env_infos/reward_angular Min                -1.73512
time/data storing (s)                                   0.0280484
time/evaluation sampling (s)                           22.9254
time/exploration sampling (s)                           1.04334
time/logging (s)                                        0.248212
time/saving (s)                                         0.0288302
time/training (s)                                       3.2852
time/epoch (s)                                         27.559
time/total (s)                                        114.8
Epoch                                                   3
-------------------------------------------------  ----------------
2021-05-25 09:55:31.488565 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 4 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  12000
trainer/QF1 Loss                                        0.637471
trainer/QF2 Loss                                        0.636004
trainer/Policy Loss                                    -6.86356
trainer/Q1 Predictions Mean                             3.15402
trainer/Q1 Predictions Std                              0.79944
trainer/Q1 Predictions Max                              6.43922
trainer/Q1 Predictions Min                              1.49698
trainer/Q2 Predictions Mean                             3.04824
trainer/Q2 Predictions Std                              0.825413
trainer/Q2 Predictions Max                              6.02284
trainer/Q2 Predictions Min                              1.49766
trainer/Q Targets Mean                                  3.11392
trainer/Q Targets Std                                   1.08899
trainer/Q Targets Max                                   7.41976
trainer/Q Targets Min                                   0.315072
trainer/Log Pis Mean                                   -3.4874
trainer/Log Pis Std                                     1.15368
trainer/Log Pis Max                                     0.741341
trainer/Log Pis Min                                    -7.42431
trainer/Policy mu Mean                                 -0.00800349
trainer/Policy mu Std                                   0.345037
trainer/Policy mu Max                                   0.954612
trainer/Policy mu Min                                  -1.14258
trainer/Policy log std Mean                            -0.120852
trainer/Policy log std Std                              0.0544201
trainer/Policy log std Max                             -0.0353873
trainer/Policy log std Min                             -0.37927
trainer/Alpha                                           0.30435
trainer/Alpha Loss                                    -11.2583
exploration/num steps total                          6000
exploration/num paths total                             6
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.122398
exploration/Rewards Std                                 0.963509
exploration/Rewards Max                                 2.79736
exploration/Rewards Min                                -3.46888
exploration/Returns Mean                             -122.398
exploration/Returns Std                                 0
exploration/Returns Max                              -122.398
exploration/Returns Min                              -122.398
exploration/Actions Mean                                0.161121
exploration/Actions Std                                 0.592336
exploration/Actions Max                                 0.997897
exploration/Actions Min                                -0.994122
exploration/Num Paths                                   1
exploration/Average Returns                          -122.398
exploration/env_infos/final/reward_run Mean             0.82197
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.82197
exploration/env_infos/final/reward_run Min              0.82197
exploration/env_infos/initial/reward_run Mean           0.776857
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.776857
exploration/env_infos/initial/reward_run Min            0.776857
exploration/env_infos/reward_run Mean                  -0.0826832
exploration/env_infos/reward_run Std                    0.613365
exploration/env_infos/reward_run Max                    2.2578
exploration/env_infos/reward_run Min                   -2.11423
exploration/env_infos/final/reward_ctrl Mean           -0.314968
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.314968
exploration/env_infos/final/reward_ctrl Min            -0.314968
exploration/env_infos/initial/reward_ctrl Mean         -0.320281
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.320281
exploration/env_infos/initial/reward_ctrl Min          -0.320281
exploration/env_infos/reward_ctrl Mean                 -0.226093
exploration/env_infos/reward_ctrl Std                   0.0733089
exploration/env_infos/reward_ctrl Max                  -0.0344251
exploration/env_infos/reward_ctrl Min                  -0.440474
exploration/env_infos/final/height Mean                -0.111669
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.111669
exploration/env_infos/final/height Min                 -0.111669
exploration/env_infos/initial/height Mean               0.0630666
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max                0.0630666
exploration/env_infos/initial/height Min                0.0630666
exploration/env_infos/height Mean                      -0.108144
exploration/env_infos/height Std                        0.0853486
exploration/env_infos/height Max                        0.187719
exploration/env_infos/height Min                       -0.354495
exploration/env_infos/final/reward_angular Mean        -0.210591
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -0.210591
exploration/env_infos/final/reward_angular Min         -0.210591
exploration/env_infos/initial/reward_angular Mean      -2.08727
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -2.08727
exploration/env_infos/initial/reward_angular Min       -2.08727
exploration/env_infos/reward_angular Mean              -0.0201499
exploration/env_infos/reward_angular Std                1.50664
exploration/env_infos/reward_angular Max                4.86963
exploration/env_infos/reward_angular Min               -4.84567
evaluation/num steps total                         125000
evaluation/num paths total                            125
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0774583
evaluation/Rewards Std                                  0.0560421
evaluation/Rewards Max                                  2.12653
evaluation/Rewards Min                                 -1.16299
evaluation/Returns Mean                               -77.4583
evaluation/Returns Std                                 33.2105
evaluation/Returns Max                                 -4.03266
evaluation/Returns Min                               -137.491
evaluation/Actions Mean                                 0.0391783
evaluation/Actions Std                                  0.255717
evaluation/Actions Max                                  0.626931
evaluation/Actions Min                                 -0.744666
evaluation/Num Paths                                   25
evaluation/Average Returns                            -77.4583
evaluation/env_infos/final/reward_run Mean              1.07557e-09
evaluation/env_infos/final/reward_run Std               1.44901e-08
evaluation/env_infos/final/reward_run Max               3.98795e-08
evaluation/env_infos/final/reward_run Min              -3.81557e-08
evaluation/env_infos/initial/reward_run Mean            0.0774974
evaluation/env_infos/initial/reward_run Std             0.256475
evaluation/env_infos/initial/reward_run Max             0.460078
evaluation/env_infos/initial/reward_run Min            -0.483976
evaluation/env_infos/reward_run Mean                   -0.000538932
evaluation/env_infos/reward_run Std                     0.0239729
evaluation/env_infos/reward_run Max                     0.534812
evaluation/env_infos/reward_run Min                    -0.633213
evaluation/env_infos/final/reward_ctrl Mean            -0.0401616
evaluation/env_infos/final/reward_ctrl Std              0.0302462
evaluation/env_infos/final/reward_ctrl Max             -0.0013265
evaluation/env_infos/final/reward_ctrl Min             -0.0977289
evaluation/env_infos/initial/reward_ctrl Mean          -0.0591961
evaluation/env_infos/initial/reward_ctrl Std            0.0416752
evaluation/env_infos/initial/reward_ctrl Max           -0.000916484
evaluation/env_infos/initial/reward_ctrl Min           -0.139948
evaluation/env_infos/reward_ctrl Mean                  -0.0401555
evaluation/env_infos/reward_ctrl Std                    0.0302491
evaluation/env_infos/reward_ctrl Max                   -0.000331367
evaluation/env_infos/reward_ctrl Min                   -0.139948
evaluation/env_infos/final/height Mean                 -0.137964
evaluation/env_infos/final/height Std                   0.00761805
evaluation/env_infos/final/height Max                  -0.123084
evaluation/env_infos/final/height Min                  -0.149836
evaluation/env_infos/initial/height Mean               -0.0165285
evaluation/env_infos/initial/height Std                 0.062448
evaluation/env_infos/initial/height Max                 0.0868966
evaluation/env_infos/initial/height Min                -0.108896
evaluation/env_infos/height Mean                       -0.137539
evaluation/env_infos/height Std                         0.00962099
evaluation/env_infos/height Max                         0.0868966
evaluation/env_infos/height Min                        -0.17396
evaluation/env_infos/final/reward_angular Mean          1.67296e-08
evaluation/env_infos/final/reward_angular Std           4.96276e-08
evaluation/env_infos/final/reward_angular Max           2.00465e-07
evaluation/env_infos/final/reward_angular Min          -4.59841e-08
evaluation/env_infos/initial/reward_angular Mean       -0.183863
evaluation/env_infos/initial/reward_angular Std         1.15057
evaluation/env_infos/initial/reward_angular Max         2.55191
evaluation/env_infos/initial/reward_angular Min        -2.09026
evaluation/env_infos/reward_angular Mean               -2.64613e-05
evaluation/env_infos/reward_angular Std                 0.0599437
evaluation/env_infos/reward_angular Max                 2.55191
evaluation/env_infos/reward_angular Min                -2.09026
time/data storing (s)                                   0.0328571
time/evaluation sampling (s)                           23.3474
time/exploration sampling (s)                           1.02048
time/logging (s)                                        0.238402
time/saving (s)                                         0.0278469
time/training (s)                                       3.4648
time/epoch (s)                                         28.1318
time/total (s)                                        143.069
Epoch                                                   4
-------------------------------------------------  ----------------
2021-05-25 09:56:00.075435 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 5 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  14000
trainer/QF1 Loss                                        0.436374
trainer/QF2 Loss                                        0.453915
trainer/Policy Loss                                    -6.56053
trainer/Q1 Predictions Mean                             3.08042
trainer/Q1 Predictions Std                              0.845518
trainer/Q1 Predictions Max                              6.62725
trainer/Q1 Predictions Min                              1.06732
trainer/Q2 Predictions Mean                             3.1471
trainer/Q2 Predictions Std                              0.843647
trainer/Q2 Predictions Max                              6.69535
trainer/Q2 Predictions Min                              1.35076
trainer/Q Targets Mean                                  3.07741
trainer/Q Targets Std                                   1.1143
trainer/Q Targets Max                                   9.03059
trainer/Q Targets Min                                   0.126627
trainer/Log Pis Mean                                   -3.18035
trainer/Log Pis Std                                     1.61031
trainer/Log Pis Max                                     3.91731
trainer/Log Pis Min                                   -10.5862
trainer/Policy mu Mean                                  0.0963475
trainer/Policy mu Std                                   0.468965
trainer/Policy mu Max                                   1.2309
trainer/Policy mu Min                                  -1.83919
trainer/Policy log std Mean                            -0.18269
trainer/Policy log std Std                              0.0736086
trainer/Policy log std Max                             -0.0726937
trainer/Policy log std Min                             -0.554472
trainer/Alpha                                           0.228302
trainer/Alpha Loss                                    -13.534
exploration/num steps total                          7000
exploration/num paths total                             7
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.123065
exploration/Rewards Std                                 0.709555
exploration/Rewards Max                                 2.71976
exploration/Rewards Min                                -2.38701
exploration/Returns Mean                             -123.065
exploration/Returns Std                                 0
exploration/Returns Max                              -123.065
exploration/Returns Min                              -123.065
exploration/Actions Mean                                0.233767
exploration/Actions Std                                 0.562732
exploration/Actions Max                                 0.998121
exploration/Actions Min                                -0.997235
exploration/Num Paths                                   1
exploration/Average Returns                          -123.065
exploration/env_infos/final/reward_run Mean             0.791662
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.791662
exploration/env_infos/final/reward_run Min              0.791662
exploration/env_infos/initial/reward_run Mean           0.404396
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.404396
exploration/env_infos/initial/reward_run Min            0.404396
exploration/env_infos/reward_run Mean                  -0.0940285
exploration/env_infos/reward_run Std                    0.6683
exploration/env_infos/reward_run Max                    1.74842
exploration/env_infos/reward_run Min                   -2.39395
exploration/env_infos/final/reward_ctrl Mean           -0.372815
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.372815
exploration/env_infos/final/reward_ctrl Min            -0.372815
exploration/env_infos/initial/reward_ctrl Mean         -0.157264
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.157264
exploration/env_infos/initial/reward_ctrl Min          -0.157264
exploration/env_infos/reward_ctrl Mean                 -0.222789
exploration/env_infos/reward_ctrl Std                   0.0740233
exploration/env_infos/reward_ctrl Max                  -0.0454037
exploration/env_infos/reward_ctrl Min                  -0.47362
exploration/env_infos/final/height Mean                -0.160636
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.160636
exploration/env_infos/final/height Min                 -0.160636
exploration/env_infos/initial/height Mean              -0.0667489
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0667489
exploration/env_infos/initial/height Min               -0.0667489
exploration/env_infos/height Mean                      -0.109853
exploration/env_infos/height Std                        0.082034
exploration/env_infos/height Max                        0.154443
exploration/env_infos/height Min                       -0.380596
exploration/env_infos/final/reward_angular Mean        -1.35949
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -1.35949
exploration/env_infos/final/reward_angular Min         -1.35949
exploration/env_infos/initial/reward_angular Mean       1.16907
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max        1.16907
exploration/env_infos/initial/reward_angular Min        1.16907
exploration/env_infos/reward_angular Mean              -0.0147039
exploration/env_infos/reward_angular Std                1.46172
exploration/env_infos/reward_angular Max                4.90829
exploration/env_infos/reward_angular Min               -6.41065
evaluation/num steps total                         150000
evaluation/num paths total                            150
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.0973034
evaluation/Rewards Std                                  0.0758937
evaluation/Rewards Max                                  2.10115
evaluation/Rewards Min                                 -1.39821
evaluation/Returns Mean                               -97.3034
evaluation/Returns Std                                 34.6976
evaluation/Returns Max                                -11.7539
evaluation/Returns Min                               -162.854
evaluation/Actions Mean                                 0.0835118
evaluation/Actions Std                                  0.353318
evaluation/Actions Max                                  0.818634
evaluation/Actions Min                                 -0.874053
evaluation/Num Paths                                   25
evaluation/Average Returns                            -97.3034
evaluation/env_infos/final/reward_run Mean              0.0075389
evaluation/env_infos/final/reward_run Std               0.0650528
evaluation/env_infos/final/reward_run Max               0.274481
evaluation/env_infos/final/reward_run Min              -0.161704
evaluation/env_infos/initial/reward_run Mean            0.145964
evaluation/env_infos/initial/reward_run Std             0.273031
evaluation/env_infos/initial/reward_run Max             0.585393
evaluation/env_infos/initial/reward_run Min            -0.368844
evaluation/env_infos/reward_run Mean                    0.00182883
evaluation/env_infos/reward_run Std                     0.0732415
evaluation/env_infos/reward_run Max                     0.735039
evaluation/env_infos/reward_run Min                    -0.715143
evaluation/env_infos/final/reward_ctrl Mean            -0.0790789
evaluation/env_infos/final/reward_ctrl Std              0.0512944
evaluation/env_infos/final/reward_ctrl Max             -0.00893994
evaluation/env_infos/final/reward_ctrl Min             -0.175969
evaluation/env_infos/initial/reward_ctrl Mean          -0.098949
evaluation/env_infos/initial/reward_ctrl Std            0.0616017
evaluation/env_infos/initial/reward_ctrl Max           -0.0102744
evaluation/env_infos/initial/reward_ctrl Min           -0.222314
evaluation/env_infos/reward_ctrl Mean                  -0.0790846
evaluation/env_infos/reward_ctrl Std                    0.0513032
evaluation/env_infos/reward_ctrl Max                   -0.00293882
evaluation/env_infos/reward_ctrl Min                   -0.222314
evaluation/env_infos/final/height Mean                 -0.148458
evaluation/env_infos/final/height Std                   0.0175694
evaluation/env_infos/final/height Max                  -0.115554
evaluation/env_infos/final/height Min                  -0.179734
evaluation/env_infos/initial/height Mean               -0.0113718
evaluation/env_infos/initial/height Std                 0.0553132
evaluation/env_infos/initial/height Max                 0.0906347
evaluation/env_infos/initial/height Min                -0.0952789
evaluation/env_infos/height Mean                       -0.148902
evaluation/env_infos/height Std                         0.0185141
evaluation/env_infos/height Max                         0.0906347
evaluation/env_infos/height Min                        -0.214579
evaluation/env_infos/final/reward_angular Mean          0.0165929
evaluation/env_infos/final/reward_angular Std           0.0921324
evaluation/env_infos/final/reward_angular Max           0.41005
evaluation/env_infos/final/reward_angular Min          -0.157207
evaluation/env_infos/initial/reward_angular Mean       -0.110189
evaluation/env_infos/initial/reward_angular Std         1.36044
evaluation/env_infos/initial/reward_angular Max         2.89778
evaluation/env_infos/initial/reward_angular Min        -1.9119
evaluation/env_infos/reward_angular Mean                0.000225143
evaluation/env_infos/reward_angular Std                 0.116177
evaluation/env_infos/reward_angular Max                 2.89778
evaluation/env_infos/reward_angular Min                -1.98608
time/data storing (s)                                   0.0311574
time/evaluation sampling (s)                           23.3361
time/exploration sampling (s)                           1.25883
time/logging (s)                                        0.22928
time/saving (s)                                         0.0281329
time/training (s)                                       3.54298
time/epoch (s)                                         28.4264
time/total (s)                                        171.646
Epoch                                                   5
-------------------------------------------------  ----------------
2021-05-25 09:56:28.070746 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 6 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  16000
trainer/QF1 Loss                                        0.519998
trainer/QF2 Loss                                        0.582024
trainer/Policy Loss                                    -6.22224
trainer/Q1 Predictions Mean                             3.11674
trainer/Q1 Predictions Std                              1.15703
trainer/Q1 Predictions Max                              7.25252
trainer/Q1 Predictions Min                              1.08608
trainer/Q2 Predictions Mean                             3.14922
trainer/Q2 Predictions Std                              1.13123
trainer/Q2 Predictions Max                              6.99562
trainer/Q2 Predictions Min                              1.17361
trainer/Q Targets Mean                                  3.15433
trainer/Q Targets Std                                   1.29413
trainer/Q Targets Max                                   8.56962
trainer/Q Targets Min                                  -0.772606
trainer/Log Pis Mean                                   -2.77802
trainer/Log Pis Std                                     1.77605
trainer/Log Pis Max                                     2.60474
trainer/Log Pis Min                                    -8.42073
trainer/Policy mu Mean                                  0.116364
trainer/Policy mu Std                                   0.576353
trainer/Policy mu Max                                   1.42148
trainer/Policy mu Min                                  -1.64645
trainer/Policy log std Mean                            -0.206473
trainer/Policy log std Std                              0.0972257
trainer/Policy log std Max                             -0.00426184
trainer/Policy log std Min                             -0.471339
trainer/Alpha                                           0.172858
trainer/Alpha Loss                                    -15.3839
exploration/num steps total                          8000
exploration/num paths total                             8
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.0922026
exploration/Rewards Std                                 1.00373
exploration/Rewards Max                                 3.20852
exploration/Rewards Min                                -3.42042
exploration/Returns Mean                              -92.2026
exploration/Returns Std                                 0
exploration/Returns Max                               -92.2026
exploration/Returns Min                               -92.2026
exploration/Actions Mean                                0.391198
exploration/Actions Std                                 0.548287
exploration/Actions Max                                 0.998686
exploration/Actions Min                                -0.984407
exploration/Num Paths                                   1
exploration/Average Returns                           -92.2026
exploration/env_infos/final/reward_run Mean            -0.167623
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.167623
exploration/env_infos/final/reward_run Min             -0.167623
exploration/env_infos/initial/reward_run Mean           0.218324
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.218324
exploration/env_infos/initial/reward_run Min            0.218324
exploration/env_infos/reward_run Mean                  -0.0456324
exploration/env_infos/reward_run Std                    0.443611
exploration/env_infos/reward_run Max                    1.37514
exploration/env_infos/reward_run Min                   -1.59531
exploration/env_infos/final/reward_ctrl Mean           -0.303342
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.303342
exploration/env_infos/final/reward_ctrl Min            -0.303342
exploration/env_infos/initial/reward_ctrl Mean         -0.144693
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.144693
exploration/env_infos/initial/reward_ctrl Min          -0.144693
exploration/env_infos/reward_ctrl Mean                 -0.272193
exploration/env_infos/reward_ctrl Std                   0.0745709
exploration/env_infos/reward_ctrl Max                  -0.0474698
exploration/env_infos/reward_ctrl Min                  -0.490725
exploration/env_infos/final/height Mean                -0.251261
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.251261
exploration/env_infos/final/height Min                 -0.251261
exploration/env_infos/initial/height Mean              -0.0690564
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0690564
exploration/env_infos/initial/height Min               -0.0690564
exploration/env_infos/height Mean                      -0.184197
exploration/env_infos/height Std                        0.0771391
exploration/env_infos/height Max                        0.0183199
exploration/env_infos/height Min                       -0.429121
exploration/env_infos/final/reward_angular Mean        -1.21857
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -1.21857
exploration/env_infos/final/reward_angular Min         -1.21857
exploration/env_infos/initial/reward_angular Mean      -1.27611
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -1.27611
exploration/env_infos/initial/reward_angular Min       -1.27611
exploration/env_infos/reward_angular Mean              -0.00732463
exploration/env_infos/reward_angular Std                1.07178
exploration/env_infos/reward_angular Max                3.61907
exploration/env_infos/reward_angular Min               -3.44595
evaluation/num steps total                         175000
evaluation/num paths total                            175
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.115497
evaluation/Rewards Std                                  0.0797829
evaluation/Rewards Max                                  2.86577
evaluation/Rewards Min                                 -0.823058
evaluation/Returns Mean                              -115.497
evaluation/Returns Std                                 44.7576
evaluation/Returns Max                                -31.733
evaluation/Returns Min                               -205.872
evaluation/Actions Mean                                 0.152449
evaluation/Actions Std                                  0.426116
evaluation/Actions Max                                  0.873049
evaluation/Actions Min                                 -0.840488
evaluation/Num Paths                                   25
evaluation/Average Returns                           -115.497
evaluation/env_infos/final/reward_run Mean             -0.00936607
evaluation/env_infos/final/reward_run Std               0.0459125
evaluation/env_infos/final/reward_run Max               9.19454e-05
evaluation/env_infos/final/reward_run Min              -0.23429
evaluation/env_infos/initial/reward_run Mean            0.172792
evaluation/env_infos/initial/reward_run Std             0.391682
evaluation/env_infos/initial/reward_run Max             0.765095
evaluation/env_infos/initial/reward_run Min            -0.653593
evaluation/env_infos/reward_run Mean                    0.000123428
evaluation/env_infos/reward_run Std                     0.0500193
evaluation/env_infos/reward_run Max                     0.886876
evaluation/env_infos/reward_run Min                    -0.787383
evaluation/env_infos/final/reward_ctrl Mean            -0.123116
evaluation/env_infos/final/reward_ctrl Std              0.0627097
evaluation/env_infos/final/reward_ctrl Max             -0.0104075
evaluation/env_infos/final/reward_ctrl Min             -0.230465
evaluation/env_infos/initial/reward_ctrl Mean          -0.126281
evaluation/env_infos/initial/reward_ctrl Std            0.0571603
evaluation/env_infos/initial/reward_ctrl Max           -0.0191099
evaluation/env_infos/initial/reward_ctrl Min           -0.214526
evaluation/env_infos/reward_ctrl Mean                  -0.122889
evaluation/env_infos/reward_ctrl Std                    0.0628883
evaluation/env_infos/reward_ctrl Max                   -0.0062355
evaluation/env_infos/reward_ctrl Min                   -0.236508
evaluation/env_infos/final/height Mean                 -0.159795
evaluation/env_infos/final/height Std                   0.0152839
evaluation/env_infos/final/height Max                  -0.129117
evaluation/env_infos/final/height Min                  -0.183226
evaluation/env_infos/initial/height Mean               -0.0198125
evaluation/env_infos/initial/height Std                 0.0570266
evaluation/env_infos/initial/height Max                 0.077624
evaluation/env_infos/initial/height Min                -0.101376
evaluation/env_infos/height Mean                       -0.159461
evaluation/env_infos/height Std                         0.0168246
evaluation/env_infos/height Max                         0.077624
evaluation/env_infos/height Min                        -0.225448
evaluation/env_infos/final/reward_angular Mean          0.0061414
evaluation/env_infos/final/reward_angular Std           0.0301368
evaluation/env_infos/final/reward_angular Max           0.153781
evaluation/env_infos/final/reward_angular Min          -0.000122843
evaluation/env_infos/initial/reward_angular Mean       -0.317415
evaluation/env_infos/initial/reward_angular Std         1.61398
evaluation/env_infos/initial/reward_angular Max         3.43035
evaluation/env_infos/initial/reward_angular Min        -2.15392
evaluation/env_infos/reward_angular Mean               -0.000121744
evaluation/env_infos/reward_angular Std                 0.102804
evaluation/env_infos/reward_angular Max                 3.43035
evaluation/env_infos/reward_angular Min                -2.15392
time/data storing (s)                                   0.0286554
time/evaluation sampling (s)                           23.1411
time/exploration sampling (s)                           1.01373
time/logging (s)                                        0.241005
time/saving (s)                                         0.0278743
time/training (s)                                       3.40344
time/epoch (s)                                         27.8558
time/total (s)                                        199.652
Epoch                                                   6
-------------------------------------------------  ----------------
2021-05-25 09:56:57.813239 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 7 finished
-------------------------------------------------  ---------------
replay_buffer/size                                  18000
trainer/QF1 Loss                                        0.656282
trainer/QF2 Loss                                        0.768053
trainer/Policy Loss                                    -6.0697
trainer/Q1 Predictions Mean                             3.1968
trainer/Q1 Predictions Std                              1.12377
trainer/Q1 Predictions Max                              9.12399
trainer/Q1 Predictions Min                              1.21287
trainer/Q2 Predictions Mean                             3.14261
trainer/Q2 Predictions Std                              1.15483
trainer/Q2 Predictions Max                              9.49885
trainer/Q2 Predictions Min                              1.05354
trainer/Q Targets Mean                                  3.24032
trainer/Q Targets Std                                   1.53054
trainer/Q Targets Max                                  11.3606
trainer/Q Targets Min                                  -0.617253
trainer/Log Pis Mean                                   -2.56937
trainer/Log Pis Std                                     2.00432
trainer/Log Pis Max                                     4.15586
trainer/Log Pis Min                                    -8.08714
trainer/Policy mu Mean                                  0.21702
trainer/Policy mu Std                                   0.587149
trainer/Policy mu Max                                   2.5408
trainer/Policy mu Min                                  -2.04933
trainer/Policy log std Mean                            -0.216859
trainer/Policy log std Std                              0.105988
trainer/Policy log std Max                              0.00890229
trainer/Policy log std Min                             -0.643069
trainer/Alpha                                           0.132142
trainer/Alpha Loss                                    -17.3207
exploration/num steps total                          9000
exploration/num paths total                             9
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.329716
exploration/Rewards Std                                 0.924999
exploration/Rewards Max                                 3.43165
exploration/Rewards Min                                -3.14463
exploration/Returns Mean                             -329.716
exploration/Returns Std                                 0
exploration/Returns Max                              -329.716
exploration/Returns Min                              -329.716
exploration/Actions Mean                               -0.0461077
exploration/Actions Std                                 0.605487
exploration/Actions Max                                 0.996356
exploration/Actions Min                                -0.996813
exploration/Num Paths                                   1
exploration/Average Returns                          -329.716
exploration/env_infos/final/reward_run Mean             0.211197
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.211197
exploration/env_infos/final/reward_run Min              0.211197
exploration/env_infos/initial/reward_run Mean          -0.00880407
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max           -0.00880407
exploration/env_infos/initial/reward_run Min           -0.00880407
exploration/env_infos/reward_run Mean                  -0.135969
exploration/env_infos/reward_run Std                    0.621936
exploration/env_infos/reward_run Max                    1.63567
exploration/env_infos/reward_run Min                   -2.14806
exploration/env_infos/final/reward_ctrl Mean           -0.298649
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.298649
exploration/env_infos/final/reward_ctrl Min            -0.298649
exploration/env_infos/initial/reward_ctrl Mean         -0.117748
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.117748
exploration/env_infos/initial/reward_ctrl Min          -0.117748
exploration/env_infos/reward_ctrl Mean                 -0.221244
exploration/env_infos/reward_ctrl Std                   0.0757463
exploration/env_infos/reward_ctrl Max                  -0.0351495
exploration/env_infos/reward_ctrl Min                  -0.445601
exploration/env_infos/final/height Mean                -0.538581
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.538581
exploration/env_infos/final/height Min                 -0.538581
exploration/env_infos/initial/height Mean               0.0806145
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max                0.0806145
exploration/env_infos/initial/height Min                0.0806145
exploration/env_infos/height Mean                      -0.371709
exploration/env_infos/height Std                        0.250813
exploration/env_infos/height Max                        0.323484
exploration/env_infos/height Min                       -0.585118
exploration/env_infos/final/reward_angular Mean         1.75871
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          1.75871
exploration/env_infos/final/reward_angular Min          1.75871
exploration/env_infos/initial/reward_angular Mean      -0.463005
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max       -0.463005
exploration/env_infos/initial/reward_angular Min       -0.463005
exploration/env_infos/reward_angular Mean               0.0411388
exploration/env_infos/reward_angular Std                1.57534
exploration/env_infos/reward_angular Max                6.17774
exploration/env_infos/reward_angular Min               -4.82282
evaluation/num steps total                         200000
evaluation/num paths total                            200
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.139393
evaluation/Rewards Std                                  0.22098
evaluation/Rewards Max                                  3.94529
evaluation/Rewards Min                                 -1.57726
evaluation/Returns Mean                              -139.393
evaluation/Returns Std                                 73.9585
evaluation/Returns Max                                 -5.59559
evaluation/Returns Min                               -333.342
evaluation/Actions Mean                                 0.209424
evaluation/Actions Std                                  0.407985
evaluation/Actions Max                                  0.953663
evaluation/Actions Min                                 -0.918337
evaluation/Num Paths                                   25
evaluation/Average Returns                           -139.393
evaluation/env_infos/final/reward_run Mean             -0.00951095
evaluation/env_infos/final/reward_run Std               0.18668
evaluation/env_infos/final/reward_run Max               0.418499
evaluation/env_infos/final/reward_run Min              -0.671277
evaluation/env_infos/initial/reward_run Mean            0.270129
evaluation/env_infos/initial/reward_run Std             0.338098
evaluation/env_infos/initial/reward_run Max             0.814799
evaluation/env_infos/initial/reward_run Min            -0.383696
evaluation/env_infos/reward_run Mean                    0.0122109
evaluation/env_infos/reward_run Std                     0.164731
evaluation/env_infos/reward_run Max                     1.18312
evaluation/env_infos/reward_run Min                    -1.66609
evaluation/env_infos/final/reward_ctrl Mean            -0.126804
evaluation/env_infos/final/reward_ctrl Std              0.0633344
evaluation/env_infos/final/reward_ctrl Max             -0.00307788
evaluation/env_infos/final/reward_ctrl Min             -0.233009
evaluation/env_infos/initial/reward_ctrl Mean          -0.144674
evaluation/env_infos/initial/reward_ctrl Std            0.0497387
evaluation/env_infos/initial/reward_ctrl Max           -0.0343471
evaluation/env_infos/initial/reward_ctrl Min           -0.220012
evaluation/env_infos/reward_ctrl Mean                  -0.126186
evaluation/env_infos/reward_ctrl Std                    0.062696
evaluation/env_infos/reward_ctrl Max                   -0.00200721
evaluation/env_infos/reward_ctrl Min                   -0.30551
evaluation/env_infos/final/height Mean                 -0.223276
evaluation/env_infos/final/height Std                   0.14316
evaluation/env_infos/final/height Max                  -0.102799
evaluation/env_infos/final/height Min                  -0.577282
evaluation/env_infos/initial/height Mean               -0.00936038
evaluation/env_infos/initial/height Std                 0.054937
evaluation/env_infos/initial/height Max                 0.0819984
evaluation/env_infos/initial/height Min                -0.0995274
evaluation/env_infos/height Mean                       -0.22058
evaluation/env_infos/height Std                         0.139622
evaluation/env_infos/height Max                         0.289454
evaluation/env_infos/height Min                        -0.586124
evaluation/env_infos/final/reward_angular Mean         -0.113453
evaluation/env_infos/final/reward_angular Std           0.581444
evaluation/env_infos/final/reward_angular Max           0.492126
evaluation/env_infos/final/reward_angular Min          -2.72839
evaluation/env_infos/initial/reward_angular Mean       -0.433023
evaluation/env_infos/initial/reward_angular Std         1.34152
evaluation/env_infos/initial/reward_angular Max         2.786
evaluation/env_infos/initial/reward_angular Min        -1.83347
evaluation/env_infos/reward_angular Mean                0.00913997
evaluation/env_infos/reward_angular Std                 0.483017
evaluation/env_infos/reward_angular Max                 4.39015
evaluation/env_infos/reward_angular Min                -3.43343
time/data storing (s)                                   0.0320901
time/evaluation sampling (s)                           23.7527
time/exploration sampling (s)                           1.09108
time/logging (s)                                        0.240035
time/saving (s)                                         0.0276975
time/training (s)                                       4.42975
time/epoch (s)                                         29.5733
time/total (s)                                        229.393
Epoch                                                   7
-------------------------------------------------  ---------------
2021-05-25 09:57:25.651645 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 8 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  20000
trainer/QF1 Loss                                        0.535525
trainer/QF2 Loss                                        0.591329
trainer/Policy Loss                                    -5.5509
trainer/Q1 Predictions Mean                             3.21789
trainer/Q1 Predictions Std                              1.44796
trainer/Q1 Predictions Max                              9.24395
trainer/Q1 Predictions Min                              0.393115
trainer/Q2 Predictions Mean                             3.24091
trainer/Q2 Predictions Std                              1.49067
trainer/Q2 Predictions Max                             10.1086
trainer/Q2 Predictions Min                              0.327907
trainer/Q Targets Mean                                  3.32276
trainer/Q Targets Std                                   1.69661
trainer/Q Targets Max                                   9.17699
trainer/Q Targets Min                                  -1.0701
trainer/Log Pis Mean                                   -2.03721
trainer/Log Pis Std                                     2.23536
trainer/Log Pis Max                                     7.14745
trainer/Log Pis Min                                    -7.24488
trainer/Policy mu Mean                                  0.181471
trainer/Policy mu Std                                   0.660782
trainer/Policy mu Max                                   3.04155
trainer/Policy mu Min                                  -2.04848
trainer/Policy log std Mean                            -0.240139
trainer/Policy log std Std                              0.111577
trainer/Policy log std Max                              0.0544966
trainer/Policy log std Min                             -0.600691
trainer/Alpha                                           0.101136
trainer/Alpha Loss                                    -18.3941
exploration/num steps total                         10000
exploration/num paths total                            10
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.459925
exploration/Rewards Std                                 0.362179
exploration/Rewards Max                                 1.20304
exploration/Rewards Min                                -1.71892
exploration/Returns Mean                             -459.925
exploration/Returns Std                                 0
exploration/Returns Max                              -459.925
exploration/Returns Min                              -459.925
exploration/Actions Mean                                0.0307236
exploration/Actions Std                                 0.601817
exploration/Actions Max                                 0.997951
exploration/Actions Min                                -0.998531
exploration/Num Paths                                   1
exploration/Average Returns                          -459.925
exploration/env_infos/final/reward_run Mean            -0.707363
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max             -0.707363
exploration/env_infos/final/reward_run Min             -0.707363
exploration/env_infos/initial/reward_run Mean           0.927682
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.927682
exploration/env_infos/initial/reward_run Min            0.927682
exploration/env_infos/reward_run Mean                  -0.0675631
exploration/env_infos/reward_run Std                    0.574301
exploration/env_infos/reward_run Max                    2.18542
exploration/env_infos/reward_run Min                   -1.88061
exploration/env_infos/final/reward_ctrl Mean           -0.179215
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.179215
exploration/env_infos/final/reward_ctrl Min            -0.179215
exploration/env_infos/initial/reward_ctrl Mean         -0.27624
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.27624
exploration/env_infos/initial/reward_ctrl Min          -0.27624
exploration/env_infos/reward_ctrl Mean                 -0.217877
exploration/env_infos/reward_ctrl Std                   0.073786
exploration/env_infos/reward_ctrl Max                  -0.029139
exploration/env_infos/reward_ctrl Min                  -0.450647
exploration/env_infos/final/height Mean                -0.533057
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.533057
exploration/env_infos/final/height Min                 -0.533057
exploration/env_infos/initial/height Mean              -0.0328815
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max               -0.0328815
exploration/env_infos/initial/height Min               -0.0328815
exploration/env_infos/height Mean                      -0.469089
exploration/env_infos/height Std                        0.178685
exploration/env_infos/height Max                        0.318771
exploration/env_infos/height Min                       -0.586103
exploration/env_infos/final/reward_angular Mean        -0.505344
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max         -0.505344
exploration/env_infos/final/reward_angular Min         -0.505344
exploration/env_infos/initial/reward_angular Mean       1.65628
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max        1.65628
exploration/env_infos/initial/reward_angular Min        1.65628
exploration/env_infos/reward_angular Mean               0.0401901
exploration/env_infos/reward_angular Std                1.34083
exploration/env_infos/reward_angular Max                6.15586
exploration/env_infos/reward_angular Min               -5.063
evaluation/num steps total                         225000
evaluation/num paths total                            225
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.149642
evaluation/Rewards Std                                  0.236788
evaluation/Rewards Max                                  2.91164
evaluation/Rewards Min                                 -4.17869
evaluation/Returns Mean                              -149.642
evaluation/Returns Std                                 74.8189
evaluation/Returns Max                                -15.0182
evaluation/Returns Min                               -350.691
evaluation/Actions Mean                                 0.222124
evaluation/Actions Std                                  0.447814
evaluation/Actions Max                                  0.996018
evaluation/Actions Min                                 -0.979624
evaluation/Num Paths                                   25
evaluation/Average Returns                           -149.642
evaluation/env_infos/final/reward_run Mean              0.0119837
evaluation/env_infos/final/reward_run Std               0.058612
evaluation/env_infos/final/reward_run Max               0.299123
evaluation/env_infos/final/reward_run Min              -1.44056e-07
evaluation/env_infos/initial/reward_run Mean            0.172573
evaluation/env_infos/initial/reward_run Std             0.371222
evaluation/env_infos/initial/reward_run Max             0.67715
evaluation/env_infos/initial/reward_run Min            -0.572052
evaluation/env_infos/reward_run Mean                   -0.0269154
evaluation/env_infos/reward_run Std                     0.229638
evaluation/env_infos/reward_run Max                     1.49933
evaluation/env_infos/reward_run Min                    -3.1031
evaluation/env_infos/final/reward_ctrl Mean            -0.146432
evaluation/env_infos/final/reward_ctrl Std              0.0864689
evaluation/env_infos/final/reward_ctrl Max             -0.0217932
evaluation/env_infos/final/reward_ctrl Min             -0.397346
evaluation/env_infos/initial/reward_ctrl Mean          -0.170843
evaluation/env_infos/initial/reward_ctrl Std            0.0667293
evaluation/env_infos/initial/reward_ctrl Max           -0.0363674
evaluation/env_infos/initial/reward_ctrl Min           -0.285599
evaluation/env_infos/reward_ctrl Mean                  -0.149926
evaluation/env_infos/reward_ctrl Std                    0.0854835
evaluation/env_infos/reward_ctrl Max                   -0.00683301
evaluation/env_infos/reward_ctrl Min                   -0.418051
evaluation/env_infos/final/height Mean                 -0.208689
evaluation/env_infos/final/height Std                   0.154067
evaluation/env_infos/final/height Max                   0.079541
evaluation/env_infos/final/height Min                  -0.577282
evaluation/env_infos/initial/height Mean               -0.0305602
evaluation/env_infos/initial/height Std                 0.0383933
evaluation/env_infos/initial/height Max                 0.048797
evaluation/env_infos/initial/height Min                -0.0863675
evaluation/env_infos/height Mean                       -0.20447
evaluation/env_infos/height Std                         0.15112
evaluation/env_infos/height Max                         0.383101
evaluation/env_infos/height Min                        -0.582914
evaluation/env_infos/final/reward_angular Mean          0.000320647
evaluation/env_infos/final/reward_angular Std           0.00283386
evaluation/env_infos/final/reward_angular Max           0.01326
evaluation/env_infos/final/reward_angular Min          -0.00524515
evaluation/env_infos/initial/reward_angular Mean       -0.376187
evaluation/env_infos/initial/reward_angular Std         1.70369
evaluation/env_infos/initial/reward_angular Max         3.40581
evaluation/env_infos/initial/reward_angular Min        -2.2893
evaluation/env_infos/reward_angular Mean                0.00995911
evaluation/env_infos/reward_angular Std                 0.295458
evaluation/env_infos/reward_angular Max                 5.86887
evaluation/env_infos/reward_angular Min                -4.06232
time/data storing (s)                                   0.029389
time/evaluation sampling (s)                           22.3322
time/exploration sampling (s)                           1.04966
time/logging (s)                                        0.235793
time/saving (s)                                         0.0315111
time/training (s)                                       3.98863
time/epoch (s)                                         27.6671
time/total (s)                                        257.226
Epoch                                                   8
-------------------------------------------------  ----------------
2021-05-25 09:57:53.245693 PDT | [gher-halfcheetahhard-SAC-10e-1000s-disc0.99_2021_05_25_09_53_11_0000--s-10] Epoch 9 finished
-------------------------------------------------  ----------------
replay_buffer/size                                  22000
trainer/QF1 Loss                                        0.587825
trainer/QF2 Loss                                        0.657973
trainer/Policy Loss                                    -4.80865
trainer/Q1 Predictions Mean                             3.1652
trainer/Q1 Predictions Std                              1.40976
trainer/Q1 Predictions Max                              8.60939
trainer/Q1 Predictions Min                              0.279964
trainer/Q2 Predictions Mean                             3.11256
trainer/Q2 Predictions Std                              1.40854
trainer/Q2 Predictions Max                              8.1646
trainer/Q2 Predictions Min                              0.480346
trainer/Q Targets Mean                                  3.06475
trainer/Q Targets Std                                   1.6122
trainer/Q Targets Max                                   7.89965
trainer/Q Targets Min                                  -1.74136
trainer/Log Pis Mean                                   -1.33771
trainer/Log Pis Std                                     2.81695
trainer/Log Pis Max                                    11.0419
trainer/Log Pis Min                                    -8.07828
trainer/Policy mu Mean                                  0.0963795
trainer/Policy mu Std                                   0.796898
trainer/Policy mu Max                                   2.84164
trainer/Policy mu Min                                  -3.78032
trainer/Policy log std Mean                            -0.289994
trainer/Policy log std Std                              0.140415
trainer/Policy log std Max                              0.0152031
trainer/Policy log std Min                             -0.803131
trainer/Alpha                                           0.0777442
trainer/Alpha Loss                                    -18.7241
exploration/num steps total                         11000
exploration/num paths total                            11
exploration/path length Mean                         1000
exploration/path length Std                             0
exploration/path length Max                          1000
exploration/path length Min                          1000
exploration/Rewards Mean                               -0.336346
exploration/Rewards Std                                 1.01894
exploration/Rewards Max                                 3.09086
exploration/Rewards Min                                -3.96911
exploration/Returns Mean                             -336.346
exploration/Returns Std                                 0
exploration/Returns Max                              -336.346
exploration/Returns Min                              -336.346
exploration/Actions Mean                               -0.102477
exploration/Actions Std                                 0.642018
exploration/Actions Max                                 0.998491
exploration/Actions Min                                -0.999916
exploration/Num Paths                                   1
exploration/Average Returns                          -336.346
exploration/env_infos/final/reward_run Mean             0.183367
exploration/env_infos/final/reward_run Std              0
exploration/env_infos/final/reward_run Max              0.183367
exploration/env_infos/final/reward_run Min              0.183367
exploration/env_infos/initial/reward_run Mean           0.400525
exploration/env_infos/initial/reward_run Std            0
exploration/env_infos/initial/reward_run Max            0.400525
exploration/env_infos/initial/reward_run Min            0.400525
exploration/env_infos/reward_run Mean                  -0.0726847
exploration/env_infos/reward_run Std                    0.739994
exploration/env_infos/reward_run Max                    2.12668
exploration/env_infos/reward_run Min                   -2.14916
exploration/env_infos/final/reward_ctrl Mean           -0.318291
exploration/env_infos/final/reward_ctrl Std             0
exploration/env_infos/final/reward_ctrl Max            -0.318291
exploration/env_infos/final/reward_ctrl Min            -0.318291
exploration/env_infos/initial/reward_ctrl Mean         -0.211834
exploration/env_infos/initial/reward_ctrl Std           0
exploration/env_infos/initial/reward_ctrl Max          -0.211834
exploration/env_infos/initial/reward_ctrl Min          -0.211834
exploration/env_infos/reward_ctrl Mean                 -0.253613
exploration/env_infos/reward_ctrl Std                   0.0927475
exploration/env_infos/reward_ctrl Max                  -0.0483661
exploration/env_infos/reward_ctrl Min                  -0.530523
exploration/env_infos/final/height Mean                -0.516758
exploration/env_infos/final/height Std                  0
exploration/env_infos/final/height Max                 -0.516758
exploration/env_infos/final/height Min                 -0.516758
exploration/env_infos/initial/height Mean               0.0258082
exploration/env_infos/initial/height Std                0
exploration/env_infos/initial/height Max                0.0258082
exploration/env_infos/initial/height Min                0.0258082
exploration/env_infos/height Mean                      -0.474996
exploration/env_infos/height Std                        0.169148
exploration/env_infos/height Max                        0.392361
exploration/env_infos/height Min                       -0.584605
exploration/env_infos/final/reward_angular Mean         0.509825
exploration/env_infos/final/reward_angular Std          0
exploration/env_infos/final/reward_angular Max          0.509825
exploration/env_infos/final/reward_angular Min          0.509825
exploration/env_infos/initial/reward_angular Mean       0.243747
exploration/env_infos/initial/reward_angular Std        0
exploration/env_infos/initial/reward_angular Max        0.243747
exploration/env_infos/initial/reward_angular Min        0.243747
exploration/env_infos/reward_angular Mean               0.099761
exploration/env_infos/reward_angular Std                1.54018
exploration/env_infos/reward_angular Max                4.89841
exploration/env_infos/reward_angular Min               -5.51368
evaluation/num steps total                         250000
evaluation/num paths total                            250
evaluation/path length Mean                          1000
evaluation/path length Std                              0
evaluation/path length Max                           1000
evaluation/path length Min                           1000
evaluation/Rewards Mean                                -0.165623
evaluation/Rewards Std                                  0.192629
evaluation/Rewards Max                                  3.46726
evaluation/Rewards Min                                 -2.33887
evaluation/Returns Mean                              -165.623
evaluation/Returns Std                                 69.1665
evaluation/Returns Max                                -24.2011
evaluation/Returns Min                               -325.344
evaluation/Actions Mean                                 0.259898
evaluation/Actions Std                                  0.51091
evaluation/Actions Max                                  0.986213
evaluation/Actions Min                                 -0.998097
evaluation/Num Paths                                   25
evaluation/Average Returns                           -165.623
evaluation/env_infos/final/reward_run Mean             -0.0425428
evaluation/env_infos/final/reward_run Std               0.189211
evaluation/env_infos/final/reward_run Max               1.10758e-05
evaluation/env_infos/final/reward_run Min              -0.964611
evaluation/env_infos/initial/reward_run Mean            0.062451
evaluation/env_infos/initial/reward_run Std             0.38772
evaluation/env_infos/initial/reward_run Max             0.846279
evaluation/env_infos/initial/reward_run Min            -0.688425
evaluation/env_infos/reward_run Mean                   -0.012644
evaluation/env_infos/reward_run Std                     0.159617
evaluation/env_infos/reward_run Max                     1.57256
evaluation/env_infos/reward_run Min                    -2.01201
evaluation/env_infos/final/reward_ctrl Mean            -0.194054
evaluation/env_infos/final/reward_ctrl Std              0.0842325
evaluation/env_infos/final/reward_ctrl Max             -0.034116
evaluation/env_infos/final/reward_ctrl Min             -0.322983
evaluation/env_infos/initial/reward_ctrl Mean          -0.180888
evaluation/env_infos/initial/reward_ctrl Std            0.0691269
evaluation/env_infos/initial/reward_ctrl Max           -0.0720111
evaluation/env_infos/initial/reward_ctrl Min           -0.341913
evaluation/env_infos/reward_ctrl Mean                  -0.197146
evaluation/env_infos/reward_ctrl Std                    0.0840693
evaluation/env_infos/reward_ctrl Max                   -0.0193592
evaluation/env_infos/reward_ctrl Min                   -0.48254
evaluation/env_infos/final/height Mean                 -0.228405
evaluation/env_infos/final/height Std                   0.140204
evaluation/env_infos/final/height Max                   0.0825902
evaluation/env_infos/final/height Min                  -0.577277
evaluation/env_infos/initial/height Mean               -0.0162938
evaluation/env_infos/initial/height Std                 0.0593911
evaluation/env_infos/initial/height Max                 0.0781191
evaluation/env_infos/initial/height Min                -0.118176
evaluation/env_infos/height Mean                       -0.221584
evaluation/env_infos/height Std                         0.140052
evaluation/env_infos/height Max                         0.408082
evaluation/env_infos/height Min                        -0.582705
evaluation/env_infos/final/reward_angular Mean         -0.0108694
evaluation/env_infos/final/reward_angular Std           0.133997
evaluation/env_infos/final/reward_angular Max           0.319666
evaluation/env_infos/final/reward_angular Min          -0.59131
evaluation/env_infos/initial/reward_angular Mean       -0.290335
evaluation/env_infos/initial/reward_angular Std         1.42222
evaluation/env_infos/initial/reward_angular Max         2.74404
evaluation/env_infos/initial/reward_angular Min        -2.56022
evaluation/env_infos/reward_angular Mean                0.00889732
evaluation/env_infos/reward_angular Std                 0.3087
evaluation/env_infos/reward_angular Max                 4.65827
evaluation/env_infos/reward_angular Min                -4.76906
time/data storing (s)                                   0.0323648
time/evaluation sampling (s)                           22.3249
time/exploration sampling (s)                           1.07951
time/logging (s)                                        0.22887
time/saving (s)                                         0.0532366
time/training (s)                                       3.69588
time/epoch (s)                                         27.4148
time/total (s)                                        284.812
Epoch                                                   9
-------------------------------------------------  ----------------
